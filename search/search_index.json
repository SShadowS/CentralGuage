{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"CentralGauge Documentation","text":"<p>Modern LLM benchmark for Microsoft Dynamics 365 Business Central AL code</p> <p>CentralGauge is an open-source benchmark suite for evaluating large language models (LLMs) on their ability to generate, debug, and refactor AL (Application Language) code for Microsoft Dynamics 365 Business Central.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Overview - What CentralGauge is and why it exists</li> <li>Installation - System requirements and setup</li> <li>Quick Start - Run your first benchmark in minutes</li> </ul>"},{"location":"#user-guides","title":"User Guides","text":"<ul> <li>Running Benchmarks - LLM and Agent benchmark execution</li> <li>Understanding Results - Interpreting benchmark output</li> <li>Configuration - Customizing CentralGauge behavior</li> <li>Model Variants - Comparing models with different settings</li> </ul>"},{"location":"#task-authoring","title":"Task Authoring","text":"<ul> <li>Task Format - YAML manifest structure</li> <li>Writing Tests - Creating AL test codeunits</li> <li>Task Categories - Easy, Medium, Hard classifications</li> <li>Task Creation Guide - Comprehensive guide for authoring new tasks</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<ul> <li>System Architecture - Component design and data flow</li> <li>LLM Adapters - Provider integrations</li> <li>Container Providers - BC container management</li> <li>Agent System - Autonomous agent execution</li> </ul>"},{"location":"#cli-reference","title":"CLI Reference","text":"<ul> <li>Command Reference - All CLI commands and options</li> <li>bench Command - Running benchmarks</li> <li>report Command - Generating reports</li> <li>config Command - Configuration management</li> <li>rules Command - Generating rules from shortcomings</li> </ul>"},{"location":"#api-reference","title":"API Reference","text":"<ul> <li>Module Index - Code organization</li> <li>Core Types - TypeScript interfaces</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<ul> <li>Development Setup - Local environment</li> <li>Testing Patterns - Writing tests</li> <li>Code Style - Conventions and practices</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"Resource Description GitHub Repository Source code and issues Example Tasks Benchmark task definitions Benchmark Results Sample benchmark outputs"},{"location":"#license","title":"License","text":"<p>CentralGauge is released under the MIT License. See LICENSE for details.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#system-requirements","title":"System Requirements","text":""},{"location":"installation/#required","title":"Required","text":"Requirement Version Notes Deno 1.44+ Runtime for CentralGauge Windows 10/11 or Server Required for BC containers Docker Desktop Latest For container management bccontainerhelper Latest PowerShell module for BC"},{"location":"installation/#optional","title":"Optional","text":"Requirement Notes Git Bash Recommended shell on Windows jq For inspecting JSON files Visual Studio Code For AL development"},{"location":"installation/#step-1-install-deno","title":"Step 1: Install Deno","text":""},{"location":"installation/#windows-powershell","title":"Windows (PowerShell)","text":"<pre><code>irm https://deno.land/install.ps1 | iex\n</code></pre>"},{"location":"installation/#windows-scoop","title":"Windows (Scoop)","text":"<pre><code>scoop install deno\n</code></pre>"},{"location":"installation/#linuxmacos","title":"Linux/macOS","text":"<pre><code>curl -fsSL https://deno.land/x/install/install.sh | sh\n</code></pre> <p>Verify installation:</p> <pre><code>deno --version\n# deno 1.44.0 (release, x86_64-pc-windows-msvc)\n# v8 12.4.254.13\n# typescript 5.4.5\n</code></pre>"},{"location":"installation/#step-2-install-docker-desktop","title":"Step 2: Install Docker Desktop","text":"<p>Download and install Docker Desktop from docker.com.</p> <p>After installation, ensure Windows containers are enabled:</p> <ol> <li>Right-click the Docker icon in the system tray</li> <li>Select \"Switch to Windows containers...\"</li> <li>Wait for Docker to restart</li> </ol> <p>Verify Docker is running:</p> <pre><code>docker --version\n# Docker version 24.0.0, build ...\n</code></pre>"},{"location":"installation/#step-3-install-bccontainerhelper","title":"Step 3: Install bccontainerhelper","text":"<p>Open PowerShell as Administrator and run:</p> <pre><code>Install-Module -Name bccontainerhelper -Force\n</code></pre> <p>Verify installation:</p> <pre><code>Get-Module -ListAvailable bccontainerhelper\n</code></pre>"},{"location":"installation/#step-4-clone-centralgauge","title":"Step 4: Clone CentralGauge","text":"<pre><code>git clone https://github.com/SShadowS/CentralGuage.git\ncd CentralGuage\n</code></pre>"},{"location":"installation/#step-5-configure-api-keys","title":"Step 5: Configure API Keys","text":"<p>Copy the example environment file:</p> <pre><code>cp .env.example .env\n</code></pre> <p>Edit <code>.env</code> and add your API keys:</p> <pre><code># Anthropic (Claude)\nANTHROPIC_API_KEY=sk-ant-api03-...\n\n# OpenAI (GPT)\nOPENAI_API_KEY=sk-proj-...\n\n# Google (Gemini)\nGOOGLE_API_KEY=AIzaSy...\n\n# OpenRouter (optional, for 200+ models)\nOPENROUTER_API_KEY=sk-or-v1-...\n\n# Azure OpenAI (optional)\nAZURE_OPENAI_API_KEY=...\nAZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/\n</code></pre> <p>You only need to configure the providers you plan to use.</p>"},{"location":"installation/#step-6-create-a-bc-container","title":"Step 6: Create a BC Container","text":"<p>CentralGauge requires a Business Central container with the Test Toolkit installed. Create one using bccontainerhelper:</p> <pre><code># Create credential for container access\n$cred = New-Object PSCredential 'admin', (ConvertTo-SecureString 'admin' -AsPlainText -Force)\n\n# Create BC27 container with test toolkit\nNew-BcContainer `\n    -containerName Cronus27 `\n    -credential $cred `\n    -artifactUrl (Get-BCArtifactUrl -country us -version 27) `\n    -includeTestToolkit\n</code></pre> <p>This process takes 10-30 minutes depending on your internet connection and hardware.</p> <p>Verify the container is running:</p> <pre><code>docker ps\n# CONTAINER ID   IMAGE                    STATUS         NAMES\n# abc123...      mcr.microsoft.com/...    Up 2 hours     Cronus27\n</code></pre>"},{"location":"installation/#step-7-configure-centralgauge","title":"Step 7: Configure CentralGauge","text":"<p>Create a configuration file (optional but recommended):</p> <pre><code>deno run --allow-all cli/centralgauge.ts config init\n</code></pre> <p>This creates <code>.centralgauge.yml</code> with sensible defaults. Edit it to match your container:</p> <pre><code>container:\n  provider: bccontainer\n  name: Cronus27\n  credentials:\n    username: admin\n    password: admin\n</code></pre>"},{"location":"installation/#step-8-verify-installation","title":"Step 8: Verify Installation","text":"<p>Run the built-in verification:</p> <pre><code>deno task start\n</code></pre> <p>You should see a splash screen showing:</p> <ul> <li>Environment variables loaded</li> <li>Configuration file found</li> <li>Available providers listed</li> <li>Container connection status</li> </ul> <p>Run a quick test with the mock provider (no LLM API required):</p> <pre><code>deno task bench --llms mock --tasks tasks/easy/CG-AL-E001*.yml\n</code></pre>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/#container-not-found-errors","title":"\"Container not found\" Errors","text":"<p>Ensure your container is running:</p> <pre><code>docker ps\ndocker start Cronus27\n</code></pre>"},{"location":"installation/#api-key-not-set-errors","title":"\"API key not set\" Errors","text":"<p>Verify your <code>.env</code> file is loaded:</p> <pre><code>source .env  # Git Bash\necho $ANTHROPIC_API_KEY\n</code></pre>"},{"location":"installation/#docker-permission-errors","title":"Docker Permission Errors","text":"<p>On Windows, ensure Docker Desktop is running and you have Windows containers enabled.</p>"},{"location":"installation/#bccontainerhelper-not-found","title":"bccontainerhelper Not Found","text":"<p>Ensure you installed it in an Administrator PowerShell session:</p> <pre><code>Import-Module bccontainerhelper\n</code></pre>"},{"location":"installation/#rate-limit-errors","title":"Rate Limit Errors","text":"<p>Add rate limiting configuration:</p> <pre><code># .centralgauge.yml\nllm:\n  timeout: 60000 # Increase timeout to 60s\n</code></pre>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start - Run your first benchmark</li> <li>Configuration - Customize settings</li> <li>Running Benchmarks - Full benchmark guide</li> </ul>"},{"location":"overview/","title":"Overview","text":""},{"location":"overview/#what-is-centralgauge","title":"What is CentralGauge?","text":"<p>CentralGauge is a comprehensive benchmark suite designed to evaluate how well large language models (LLMs) can generate, debug, and refactor code written in AL (Application Language), the programming language for Microsoft Dynamics 365 Business Central.</p> <p>Unlike generic coding benchmarks, CentralGauge focuses specifically on the unique challenges of Business Central development:</p> <ul> <li>Domain-specific syntax - AL has unique constructs like tables, pages, reports, and codeunits</li> <li>Platform conventions - Business Central has strict naming conventions, captions, and data classification requirements</li> <li>Integration patterns - Real-world BC development involves events, interfaces, and extension patterns</li> <li>Compilation verification - Generated code must compile against the BC compiler</li> <li>Runtime testing - Code is executed against actual test codeunits in BC containers</li> </ul>"},{"location":"overview/#key-features","title":"Key Features","text":""},{"location":"overview/#two-pass-evaluation","title":"Two-Pass Evaluation","text":"<p>Models get a second chance to fix compilation errors, simulating real-world development workflows where developers iterate on code based on compiler feedback.</p> <pre><code>First Attempt \u2500\u2500\u2500\u2500\u2500\u25ba Compile \u2500\u2500\u2500\u2500\u2500\u25ba Pass \u2500\u2500\u2500\u2500\u2500\u25ba Success!\n                         \u2502\n                         \u25bc\n                    Errors Found\n                         \u2502\n                         \u25bc\nSecond Attempt \u2500\u2500\u2500\u2500\u25ba Compile \u2500\u2500\u2500\u2500\u2500\u25ba Pass \u2500\u2500\u2500\u2500\u2500\u25ba Success!\n                         \u2502\n                         \u25bc\n                       Fail\n</code></pre>"},{"location":"overview/#containerized-testing","title":"Containerized Testing","text":"<p>All code is compiled and tested in isolated Business Central Docker containers, ensuring reproducible results and preventing test pollution.</p>"},{"location":"overview/#parallel-execution","title":"Parallel Execution","text":"<p>Run multiple models and tasks concurrently for faster benchmark completion. The orchestrator handles rate limiting, retries, and resource management.</p>"},{"location":"overview/#model-agnostic","title":"Model Agnostic","text":"<p>Works with any LLM provider:</p> Provider Models Anthropic Claude 4.5 Opus, Claude 4 Sonnet OpenAI GPT-5, GPT-4o, o3, o1 Google Gemini 3 Pro, Gemini 2 Flash Azure Azure OpenAI deployments OpenRouter 200+ models via unified API Local Ollama, vLLM, any OpenAI-compatible"},{"location":"overview/#agent-benchmarking","title":"Agent Benchmarking","text":"<p>Beyond single API calls, CentralGauge can benchmark autonomous agents (like Claude Code) that iteratively generate, compile, and fix code until success.</p>"},{"location":"overview/#how-it-works","title":"How It Works","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         CentralGauge CLI                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                     \u2502\n\u2502   Task Loader      Parallel Orchestrator      Result Aggregator    \u2502\n\u2502       \u25b2                     \u2502                        \u25b2              \u2502\n\u2502       \u2502                     \u25bc                        \u2502              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n\u2502   \u2502                  Task Executor                     \u2502            \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502            \u2502\n\u2502   \u2502  \u2502 LLM Adapter \u2502\u2192\u2502 Code Extractor\u2502\u2192\u2502 Container \u2502 \u2502            \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502 Provider \u2502 \u2502            \u2502\n\u2502   \u2502                                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502            \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2502                              \u2502                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u25bc\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502  BC Container     \u2502\n                    \u2502  - AL Compiler    \u2502\n                    \u2502  - Test Runner    \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ol> <li>Task Loading - YAML task manifests define what the LLM should generate</li> <li>Prompt Generation - Templates transform task descriptions into LLM prompts</li> <li>Code Generation - LLM produces AL code based on the prompt</li> <li>Code Extraction - Parser extracts AL code from model response</li> <li>Compilation - BC container compiles the generated code</li> <li>Testing - Optional test codeunits verify the code works correctly</li> <li>Scoring - Results are aggregated into pass/fail metrics</li> </ol>"},{"location":"overview/#use-cases","title":"Use Cases","text":""},{"location":"overview/#model-evaluation","title":"Model Evaluation","text":"<p>Compare how different LLMs perform on BC-specific coding tasks:</p> <pre><code>deno task bench --llms opus,gpt-5,gemini-3-pro --tasks tasks/**/*.yml\n</code></pre>"},{"location":"overview/#model-comparison","title":"Model Comparison","text":"<p>Evaluate the same model with different configurations:</p> <pre><code>deno task bench --llms \"opus@temp=0.1,opus@temp=0.5,opus@temp=0.9\"\n</code></pre>"},{"location":"overview/#regression-testing","title":"Regression Testing","text":"<p>Track model performance over time with historical stats:</p> <pre><code>deno run --allow-all cli/centralgauge.ts stats-regression --threshold 10\n</code></pre>"},{"location":"overview/#agent-development","title":"Agent Development","text":"<p>Test autonomous agents that can iterate on code:</p> <pre><code>deno task bench --agents my-agent --tasks tasks/easy/*.yml\n</code></pre>"},{"location":"overview/#technology-stack","title":"Technology Stack","text":"Component Technology Runtime Deno 1.44+ Language TypeScript 5 CLI Framework Cliffy Command Containers bccontainerhelper + Docker Task Format YAML 1.2 Reports JSON + HTML (SvelteKit) Database SQLite (for stats)"},{"location":"overview/#project-structure","title":"Project Structure","text":"<pre><code>CentralGauge/\n\u251c\u2500\u2500 cli/                    # CLI commands and helpers\n\u2502   \u251c\u2500\u2500 commands/           # Individual command implementations\n\u2502   \u251c\u2500\u2500 helpers/            # Shared utilities\n\u2502   \u2514\u2500\u2500 tui/                # Terminal UI components\n\u251c\u2500\u2500 src/                    # Core library\n\u2502   \u251c\u2500\u2500 llm/                # LLM adapters and registry\n\u2502   \u251c\u2500\u2500 container/          # Container providers\n\u2502   \u251c\u2500\u2500 tasks/              # Task execution\n\u2502   \u251c\u2500\u2500 parallel/           # Parallel orchestration\n\u2502   \u251c\u2500\u2500 agents/             # Agent system\n\u2502   \u2514\u2500\u2500 config/             # Configuration management\n\u251c\u2500\u2500 tasks/                  # Task definitions\n\u2502   \u251c\u2500\u2500 easy/               # Basic AL tasks\n\u2502   \u251c\u2500\u2500 medium/             # Complex multi-object tasks\n\u2502   \u2514\u2500\u2500 hard/               # Advanced patterns and edge cases\n\u251c\u2500\u2500 tests/                  # Test suite\n\u2502   \u251c\u2500\u2500 unit/               # Unit tests\n\u2502   \u251c\u2500\u2500 integration/        # Integration tests\n\u2502   \u2514\u2500\u2500 al/                 # AL test codeunits\n\u251c\u2500\u2500 templates/              # Prompt templates\n\u251c\u2500\u2500 agents/                 # Agent configurations\n\u2514\u2500\u2500 docs/                   # Documentation\n</code></pre>"},{"location":"overview/#getting-started","title":"Getting Started","text":"<p>See the Installation Guide to set up CentralGauge, or jump straight to the Quick Start if you already have Deno and Docker installed.</p>"},{"location":"quick-start/","title":"Quick Start","text":"<p>This guide gets you running your first benchmark in under 5 minutes (assuming you have completed the installation).</p>"},{"location":"quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>Deno installed</li> <li>BC container running (e.g., <code>Cronus27</code>)</li> <li>At least one LLM API key configured in <code>.env</code></li> </ul>"},{"location":"quick-start/#your-first-benchmark","title":"Your First Benchmark","text":""},{"location":"quick-start/#1-run-a-simple-benchmark","title":"1. Run a Simple Benchmark","text":"<p>Compare Claude and GPT on easy tasks:</p> <pre><code>deno task bench --llms sonnet,gpt-4o --tasks \"tasks/easy/CG-AL-E001*.yml\"\n</code></pre> <p>This will:</p> <ol> <li>Load the task manifest</li> <li>Send prompts to both models</li> <li>Extract AL code from responses</li> <li>Compile the code in your BC container</li> <li>Run tests to verify correctness</li> <li>Display results</li> </ol>"},{"location":"quick-start/#2-understanding-the-output","title":"2. Understanding the Output","text":"<p>During execution, you'll see real-time progress:</p> <pre><code>[Summary] Starting CentralGauge benchmark (parallel mode)...\n[Info] Models: anthropic/claude-sonnet-4-20250514, openai/gpt-4o\n[Info] Tasks: tasks/easy/CG-AL-E001-basic-table.yml\n[Info] Attempts: 2\n\n[Task] CG-AL-E001: Starting with 2 models\n[LLM] anthropic/claude-sonnet-4-20250514: attempt 1: success\n[LLM] openai/gpt-4o: attempt 1: success\n[Compile] anthropic/claude-sonnet-4-20250514: success\n[Compile] openai/gpt-4o: success\n[LLM] anthropic/claude-sonnet-4-20250514: pass (score: 1.0, tests: 4/4)\n[LLM] openai/gpt-4o: pass (score: 1.0, tests: 4/4)\n[Task] Complete - Winner: TIE (1.0)\n\n[Summary] Benchmark Summary:\n   Total results: 2\n   Pass rate: 100.0%\n   Average score: 1.0\n   Total tokens: 2,847\n   Total cost: $0.0142\n   Results: results/benchmark-results-1704067200000.json\n</code></pre>"},{"location":"quick-start/#3-view-the-results-file","title":"3. View the Results File","text":"<p>Open the JSON results file:</p> <pre><code>cat results/benchmark-results-*.json | jq '.stats'\n</code></pre> <pre><code>{\n  \"totalTokens\": 2847,\n  \"totalCost\": 0.0142,\n  \"overallPassRate\": 1.0,\n  \"averageScore\": 1.0,\n  \"passRate1\": 1.0,\n  \"passRate2\": 0\n}\n</code></pre>"},{"location":"quick-start/#4-generate-an-html-report","title":"4. Generate an HTML Report","text":"<p>Create a visual report from your results:</p> <pre><code>deno task report results/ --html --output reports/\n</code></pre> <p>Open <code>reports/index.html</code> in your browser to see:</p> <ul> <li>Model comparison charts</li> <li>Task-by-task breakdown</li> <li>Cost analysis</li> <li>Score distributions</li> </ul>"},{"location":"quick-start/#quick-commands-reference","title":"Quick Commands Reference","text":""},{"location":"quick-start/#model-aliases","title":"Model Aliases","text":"<p>Use short aliases instead of full model names:</p> <pre><code># These are equivalent:\ndeno task bench --llms sonnet\ndeno task bench --llms anthropic/claude-sonnet-4-20250514\n\n# Available aliases:\n#   opus     -&gt; claude-4.5-opus\n#   sonnet   -&gt; claude-sonnet-4\n#   gpt-5    -&gt; gpt-5.2\n#   gpt-4o   -&gt; gpt-4o\n#   gemini   -&gt; gemini-3-pro-preview\n#   o3       -&gt; o3\n</code></pre>"},{"location":"quick-start/#model-groups","title":"Model Groups","text":"<p>Compare predefined groups of models:</p> <pre><code># Flagship models from each provider\ndeno task bench --llms flagship\n\n# Best models for coding tasks\ndeno task bench --llms coding\n\n# Budget-friendly options\ndeno task bench --llms budget\n</code></pre>"},{"location":"quick-start/#task-patterns","title":"Task Patterns","text":"<p>Use glob patterns to select tasks:</p> <pre><code># All easy tasks\ndeno task bench --llms sonnet --tasks \"tasks/easy/*.yml\"\n\n# All tasks\ndeno task bench --llms sonnet --tasks \"tasks/**/*.yml\"\n\n# Specific task\ndeno task bench --llms sonnet --tasks \"tasks/easy/CG-AL-E001-basic-table.yml\"\n</code></pre>"},{"location":"quick-start/#common-options","title":"Common Options","text":"<pre><code># Enable debug logging\ndeno task bench --llms sonnet --tasks tasks/easy/*.yml --debug\n\n# Customize temperature\ndeno task bench --llms sonnet --tasks tasks/easy/*.yml --temperature 0.2\n\n# Limit concurrent requests\ndeno task bench --llms sonnet --tasks tasks/easy/*.yml --max-concurrency 5\n\n# Sequential mode (disable parallelism)\ndeno task bench --llms sonnet --tasks tasks/easy/*.yml --sequential\n</code></pre>"},{"location":"quick-start/#example-workflows","title":"Example Workflows","text":""},{"location":"quick-start/#compare-model-temperatures","title":"Compare Model Temperatures","text":"<pre><code>deno task bench \\\n  --llms \"sonnet@temp=0.1,sonnet@temp=0.5,sonnet@temp=0.9\" \\\n  --tasks \"tasks/easy/*.yml\"\n</code></pre>"},{"location":"quick-start/#run-all-tasks-against-multiple-models","title":"Run All Tasks Against Multiple Models","text":"<pre><code>deno task bench \\\n  --llms opus,gpt-5,gemini-3-pro \\\n  --tasks \"tasks/**/*.yml\" \\\n  --output results/full-benchmark\n</code></pre>"},{"location":"quick-start/#retry-failed-tasks","title":"Retry Failed Tasks","text":"<p>If some tasks failed due to rate limits or network issues:</p> <pre><code>deno task bench \\\n  --llms sonnet \\\n  --retry results/benchmark-results-1704067200000.json\n</code></pre>"},{"location":"quick-start/#agent-benchmarks","title":"Agent Benchmarks","text":"<p>Test autonomous agents instead of single API calls:</p> <pre><code>deno task bench \\\n  --agents default \\\n  --tasks \"tasks/easy/*.yml\" \\\n  --container Cronus27\n</code></pre>"},{"location":"quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>Running Benchmarks - Detailed benchmark guide</li> <li>Model Variants - Advanced model configuration</li> <li>Configuration - Customize CentralGauge</li> <li>Task Format - Create your own tasks</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>This section documents the CentralGauge TypeScript API for developers who want to extend or integrate with the system.</p>"},{"location":"api/#module-organization","title":"Module Organization","text":"<p>CentralGauge is organized into these main modules:</p> <pre><code>src/\n\u251c\u2500\u2500 llm/           # LLM adapters and registry\n\u251c\u2500\u2500 container/     # Container providers\n\u251c\u2500\u2500 tasks/         # Task execution\n\u251c\u2500\u2500 parallel/      # Parallel orchestration\n\u251c\u2500\u2500 agents/        # Agent system\n\u251c\u2500\u2500 config/        # Configuration\n\u251c\u2500\u2500 prompts/       # Prompt templates\n\u251c\u2500\u2500 stats/         # Statistics and storage\n\u251c\u2500\u2500 verify/        # Failure analysis\n\u251c\u2500\u2500 rules/         # Rules generation from shortcomings\n\u2514\u2500\u2500 utils/         # Utilities\n</code></pre>"},{"location":"api/#core-modules","title":"Core Modules","text":""},{"location":"api/#llm-module-srcllm","title":"LLM Module (<code>src/llm/</code>)","text":"<p>LLM adapter interfaces and implementations.</p> <p>Exports:</p> <ul> <li><code>LLMAdapterRegistry</code> - Adapter management</li> <li><code>LLMAdapter</code> - Adapter interface</li> <li><code>LLMConfig</code>, <code>LLMRequest</code>, <code>LLMResponse</code> - Types</li> <li>Provider adapters: <code>AnthropicAdapter</code>, <code>OpenAIAdapter</code>, etc.</li> </ul> <pre><code>import { LLMAdapterRegistry } from \"./src/llm/registry.ts\";\nimport type { LLMConfig, LLMResponse } from \"./src/llm/types.ts\";\n</code></pre>"},{"location":"api/#container-module-srccontainer","title":"Container Module (<code>src/container/</code>)","text":"<p>Container provider interfaces and implementations.</p> <p>Exports:</p> <ul> <li><code>ContainerProviderRegistry</code> - Provider management</li> <li><code>ContainerProvider</code> - Provider interface</li> <li><code>CompilationResult</code>, <code>TestResult</code> - Types</li> </ul> <pre><code>import { ContainerProviderRegistry } from \"./src/container/registry.ts\";\nimport type { CompilationResult, TestResult } from \"./src/container/types.ts\";\n</code></pre>"},{"location":"api/#tasks-module-srctasks","title":"Tasks Module (<code>src/tasks/</code>)","text":"<p>Task loading and execution.</p> <p>Exports:</p> <ul> <li><code>loadTaskManifest</code> - Load YAML manifests</li> <li><code>TaskExecutorV2</code> - Execute tasks</li> <li><code>TaskTransformer</code> - Transform manifests to contexts</li> </ul> <pre><code>import { loadTaskManifest } from \"./src/tasks/loader.ts\";\nimport { TaskExecutorV2 } from \"./src/tasks/executor-v2.ts\";\nimport type {\n  TaskExecutionResult,\n  TaskManifest,\n} from \"./src/tasks/interfaces.ts\";\n</code></pre>"},{"location":"api/#parallel-module-srcparallel","title":"Parallel Module (<code>src/parallel/</code>)","text":"<p>Parallel benchmark orchestration.</p> <p>Exports:</p> <ul> <li><code>ParallelBenchmarkOrchestrator</code> - Orchestrate parallel runs</li> <li><code>createDefaultConfig</code> - Default configuration</li> <li>Event types for progress tracking</li> </ul> <pre><code>import {\n  createDefaultConfig,\n  ParallelBenchmarkOrchestrator,\n} from \"./src/parallel/mod.ts\";\nimport type { ParallelExecutionEvent } from \"./src/parallel/mod.ts\";\n</code></pre>"},{"location":"api/#agents-module-srcagents","title":"Agents Module (<code>src/agents/</code>)","text":"<p>Agent configuration and execution.</p> <p>Exports:</p> <ul> <li><code>AgentRegistry</code> - Agent management</li> <li><code>AgentTaskExecutor</code> - Execute agents</li> <li>Agent types</li> </ul> <pre><code>import { AgentRegistry } from \"./src/agents/registry.ts\";\nimport { AgentTaskExecutor } from \"./src/agents/executor.ts\";\nimport type { AgentConfig, AgentExecutionResult } from \"./src/agents/types.ts\";\n</code></pre>"},{"location":"api/#config-module-srcconfig","title":"Config Module (<code>src/config/</code>)","text":"<p>Configuration management.</p> <p>Exports:</p> <ul> <li><code>ConfigManager</code> - Load and merge configuration</li> </ul> <pre><code>import { ConfigManager } from \"./src/config/config.ts\";\nimport type { CentralGaugeConfig } from \"./src/config/config.ts\";\n</code></pre>"},{"location":"api/#rules-module-srcrules","title":"Rules Module (<code>src/rules/</code>)","text":"<p>Markdown rules generation from model shortcomings.</p> <p>Exports:</p> <ul> <li><code>generateRulesMarkdown</code> - Convert shortcomings to markdown</li> <li><code>loadShortcomingsFile</code> - Load JSON shortcomings file</li> <li><code>getDefaultOutputPath</code> - Compute default output path</li> <li><code>RulesGeneratorOptions</code> - Generation options type</li> </ul> <pre><code>import {\n  generateRulesMarkdown,\n  getDefaultOutputPath,\n  loadShortcomingsFile,\n} from \"./src/rules/mod.ts\";\nimport type { RulesGeneratorOptions } from \"./src/rules/mod.ts\";\n\n// Load shortcomings and generate rules\nconst data = await loadShortcomingsFile(\"model-shortcomings/gpt-5.2.json\");\nconst markdown = generateRulesMarkdown(data, { minOccurrences: 2 });\nawait Deno.writeTextFile(\"rules.md\", markdown);\n</code></pre>"},{"location":"api/#prompts-module-srcprompts","title":"Prompts Module (<code>src/prompts/</code>)","text":"<p>Prompt injection and knowledge bank management.</p> <p>Exports:</p> <ul> <li><code>PromptInjectionResolver</code> - Resolve and apply prompt injections</li> <li><code>loadKnowledgeFiles</code> - Load markdown files as knowledge bank</li> <li><code>hasKnowledgeOptions</code> - Check if knowledge options are provided</li> <li><code>CLIPromptOverrides</code> - CLI prompt override options type</li> </ul> <pre><code>import {\n  hasKnowledgeOptions,\n  loadKnowledgeFiles,\n} from \"./src/prompts/knowledge-loader.ts\";\nimport { PromptInjectionResolver } from \"./src/prompts/injection-resolver.ts\";\nimport type { CLIPromptOverrides } from \"./src/prompts/types.ts\";\n\n// Load knowledge files\nconst knowledge = await loadKnowledgeFiles({\n  files: [\"rules.md\", \"tips.md\"],\n  directory: \".claude/rules/\",\n});\n\n// Apply to prompt overrides\nconst overrides: CLIPromptOverrides = {\n  knowledgeContent: knowledge,\n  runLabel: \"guided\",\n};\n</code></pre>"},{"location":"api/#type-reference","title":"Type Reference","text":""},{"location":"api/#task-types","title":"Task Types","text":"<pre><code>// Task manifest (from YAML)\ninterface TaskManifest {\n  id: string;\n  description: string;\n  prompt_template: string;\n  fix_template: string;\n  max_attempts: number;\n  expected: {\n    compile: boolean;\n    testApp?: string;\n    testCodeunitId?: number;\n    mustContain?: string[];\n    mustNotContain?: string[];\n  };\n  metrics: string[];\n  metadata?: TaskMetadata;\n}\n\n// Execution result\ninterface TaskExecutionResult {\n  taskId: string;\n  executionId: string;\n  success: boolean;\n  finalScore: number;\n  passedAttemptNumber: number;\n  attempts: ExecutionAttempt[];\n  totalTokensUsed: number;\n  totalCost: number;\n  totalDuration: number;\n}\n</code></pre>"},{"location":"api/#llm-types","title":"LLM Types","text":"<pre><code>// LLM configuration\ninterface LLMConfig {\n  provider: string;\n  model: string;\n  apiKey?: string;\n  temperature?: number;\n  maxTokens?: number;\n  thinkingBudget?: number | string;\n}\n\n// LLM response\ninterface LLMResponse {\n  content: string;\n  model: string;\n  usage: TokenUsage;\n  duration: number;\n  finishReason: \"stop\" | \"length\" | \"content_filter\" | \"error\";\n}\n\n// Token usage\ninterface TokenUsage {\n  promptTokens: number;\n  completionTokens: number;\n  totalTokens: number;\n  estimatedCost?: number;\n}\n</code></pre>"},{"location":"api/#container-types","title":"Container Types","text":"<pre><code>// Compilation result\ninterface CompilationResult {\n  success: boolean;\n  errors: CompilationError[];\n  warnings: CompilationWarning[];\n  output: string;\n  duration: number;\n  artifactPath?: string;\n}\n\n// Test result\ninterface TestResult {\n  success: boolean;\n  totalTests: number;\n  passedTests: number;\n  failedTests: number;\n  duration: number;\n  results: TestCaseResult[];\n  output: string;\n}\n</code></pre>"},{"location":"api/#agent-types","title":"Agent Types","text":"<pre><code>// Agent configuration\ninterface AgentConfig {\n  id: string;\n  name: string;\n  model: string;\n  maxTurns: number;\n  allowedTools: string[];\n  systemPrompt?: SystemPromptConfig;\n  limits?: AgentLimits;\n}\n\n// Agent result\ninterface AgentExecutionResult {\n  taskId: string;\n  agentId: string;\n  success: boolean;\n  terminationReason: TerminationReason;\n  metrics: AgentCostMetrics;\n  testResult?: TestResult;\n}\n</code></pre>"},{"location":"api/#usage-examples","title":"Usage Examples","text":""},{"location":"api/#run-a-single-task","title":"Run a Single Task","text":"<pre><code>import { loadTaskManifest } from \"./src/tasks/loader.ts\";\nimport { TaskExecutorV2 } from \"./src/tasks/executor-v2.ts\";\n\nconst manifest = await loadTaskManifest(\n  \"tasks/easy/CG-AL-E001-basic-table.yml\",\n);\nconst executor = new TaskExecutorV2();\n\nconst result = await executor.executeTask({\n  taskManifest: manifest,\n  llmProvider: \"anthropic\",\n  llmModel: \"claude-sonnet-4-20250514\",\n  containerName: \"Cronus27\",\n  attemptLimit: 2,\n});\n\nconsole.log(`Success: ${result.success}, Score: ${result.finalScore}`);\n</code></pre>"},{"location":"api/#run-parallel-benchmark","title":"Run Parallel Benchmark","text":"<pre><code>import {\n  createDefaultConfig,\n  ParallelBenchmarkOrchestrator,\n} from \"./src/parallel/mod.ts\";\nimport { loadTaskManifest } from \"./src/tasks/loader.ts\";\n\nconst config = createDefaultConfig();\nconfig.maxGlobalConcurrency = 5;\n\nconst orchestrator = new ParallelBenchmarkOrchestrator(config);\n\norchestrator.on((event) =&gt; {\n  if (event.type === \"result\") {\n    console.log(\n      `${event.result.taskId}: ${event.result.success ? \"pass\" : \"fail\"}`,\n    );\n  }\n});\n\nconst manifests = [\n  await loadTaskManifest(\"tasks/easy/CG-AL-E001-basic-table.yml\"),\n];\n\nconst variants = [\n  {\n    provider: \"anthropic\",\n    model: \"claude-sonnet-4-20250514\",\n    variantId: \"sonnet\",\n  },\n];\n\nconst { results, summary } = await orchestrator.runParallel(\n  manifests,\n  variants,\n  {\n    containerName: \"Cronus27\",\n    attemptLimit: 2,\n  },\n);\n</code></pre>"},{"location":"api/#execute-an-agent","title":"Execute an Agent","text":"<pre><code>import { AgentRegistry } from \"./src/agents/registry.ts\";\nimport { AgentTaskExecutor } from \"./src/agents/executor.ts\";\nimport { loadTaskManifest } from \"./src/tasks/loader.ts\";\n\nawait AgentRegistry.load(\"agents\");\nconst agentConfig = AgentRegistry.get(\"default\");\nconst taskManifest = await loadTaskManifest(\n  \"tasks/easy/CG-AL-E001-basic-table.yml\",\n);\n\nconst executor = new AgentTaskExecutor();\nconst result = await executor.execute(agentConfig, taskManifest, {\n  projectDir: \"/path/to/workspace\",\n  containerName: \"Cronus27\",\n  containerProvider: \"bccontainer\",\n});\n\nconsole.log(\n  `Turns: ${result.metrics.turns}, Cost: $${result.metrics.estimatedCost}`,\n);\n</code></pre>"},{"location":"api/#create-custom-llm-adapter","title":"Create Custom LLM Adapter","text":"<pre><code>import type {\n  CodeGenerationResult,\n  LLMAdapter,\n  LLMConfig,\n  LLMRequest,\n} from \"./src/llm/types.ts\";\nimport { LLMAdapterRegistry } from \"./src/llm/registry.ts\";\n\nclass MyAdapter implements LLMAdapter {\n  readonly name = \"my-adapter\";\n  readonly supportedModels = [\"my-model\"];\n\n  configure(config: LLMConfig): void {/* ... */}\n\n  async generateCode(\n    request: LLMRequest,\n    context: GenerationContext,\n  ): Promise&lt;CodeGenerationResult&gt; {\n    // Implementation\n  }\n\n  // ... other methods\n}\n\nLLMAdapterRegistry.register(\"my-adapter\", () =&gt; new MyAdapter());\n</code></pre>"},{"location":"api/#error-handling","title":"Error Handling","text":"<pre><code>import {\n  CentralGaugeError,\n  ContainerError,\n  isRetryableError,\n  LLMProviderError,\n} from \"./src/errors.ts\";\n\ntry {\n  const result = await executor.executeTask(request);\n} catch (error) {\n  if (error instanceof LLMProviderError) {\n    console.log(`Provider error: ${error.provider}`);\n    if (isRetryableError(error)) {\n      // Retry logic\n    }\n  } else if (error instanceof ContainerError) {\n    console.log(`Container error: ${error.containerName} - ${error.operation}`);\n  }\n}\n</code></pre>"},{"location":"api/#see-also","title":"See Also","text":"<ul> <li>Core Types - Detailed type reference</li> <li>Architecture Overview - System design</li> <li>LLM Adapters - Adapter development</li> <li>Container Providers - Provider development</li> </ul>"},{"location":"api/types/","title":"Core Types Reference","text":"<p>This document provides a detailed reference for all core TypeScript types in CentralGauge.</p>"},{"location":"api/types/#task-types","title":"Task Types","text":""},{"location":"api/types/#taskmanifest","title":"TaskManifest","text":"<p>Defines a benchmark task loaded from YAML.</p> <pre><code>interface TaskManifest {\n  /** Unique task identifier (e.g., \"CG-AL-E001\") */\n  id: string;\n\n  /** Human-readable task description */\n  description: string;\n\n  /** Path to prompt template (relative to templates/) */\n  prompt_template: string;\n\n  /** Path to fix template for retry attempts */\n  fix_template: string;\n\n  /** Maximum attempts allowed */\n  max_attempts: number;\n\n  /** Expected outcomes for evaluation */\n  expected: {\n    /** Whether code should compile successfully */\n    compile: boolean;\n\n    /** Test app path (optional) */\n    testApp?: string;\n\n    /** Test codeunit ID for targeted execution */\n    testCodeunitId?: number;\n\n    /** Patterns that must appear in generated code */\n    mustContain?: string[];\n\n    /** Patterns that must NOT appear */\n    mustNotContain?: string[];\n  };\n\n  /** Metrics to collect */\n  metrics: string[];\n\n  /** Optional metadata */\n  metadata?: {\n    difficulty?: \"easy\" | \"medium\" | \"hard\";\n    category?: string;\n    tags?: string[];\n    estimatedTokens?: number;\n    target?: \"Cloud\" | \"OnPrem\";\n  };\n}\n</code></pre>"},{"location":"api/types/#taskexecutioncontext","title":"TaskExecutionContext","text":"<p>Internal execution context with enriched data.</p> <pre><code>interface TaskExecutionContext {\n  manifest: TaskManifest;\n  taskType: TaskType;\n  alProjectPath: string;\n  targetFile: string;\n  instructions: string;\n\n  llmProvider: string;\n  llmModel: string;\n  variantId: string;\n  variantConfig?: VariantConfig;\n  containerProvider: string;\n  containerName: string;\n\n  promptTemplatePath: string;\n  fixTemplatePath: string;\n\n  attemptLimit: number;\n  timeout: number;\n  temperature: number;\n  maxTokens: number;\n\n  outputDir: string;\n  debugMode: boolean;\n\n  expectedOutput: {\n    type: \"al_code\" | \"diff\" | \"test_code\";\n    validation: {\n      mustCompile: boolean;\n      mustPass?: boolean;\n      mustContain?: string[];\n      mustNotContain?: string[];\n    };\n  };\n\n  metadata: {\n    difficulty: \"easy\" | \"medium\" | \"hard\";\n    category: string;\n    tags: string[];\n    estimatedTokens: number;\n  };\n}\n</code></pre>"},{"location":"api/types/#taskexecutionresult","title":"TaskExecutionResult","text":"<p>Final execution result.</p> <pre><code>interface TaskExecutionResult {\n  taskId: string;\n  executionId: string;\n  context: TaskExecutionContext;\n  attempts: ExecutionAttempt[];\n  success: boolean;\n  finalCode?: string;\n  finalScore: number;\n  totalTokensUsed: number;\n  totalCost: number;\n  totalDuration: number;\n  passedAttemptNumber: number;\n  successRate: number;\n  executedAt: Date;\n  executedBy: string;\n  environment: Record&lt;string, string&gt;;\n}\n</code></pre>"},{"location":"api/types/#executionattempt","title":"ExecutionAttempt","text":"<p>Result of a single attempt.</p> <pre><code>interface ExecutionAttempt {\n  attemptNumber: number;\n  startTime: Date;\n  endTime: Date;\n  prompt: string;\n  llmResponse: LLMResponse;\n  extractedCode: string;\n  codeLanguage: \"al\" | \"diff\";\n  compilationResult?: CompilationResult;\n  testResult?: TestResult;\n  success: boolean;\n  score: number;\n  failureReasons: string[];\n  tokensUsed: number;\n  cost: number;\n  duration: number;\n  llmDuration?: number;\n  compileDuration?: number;\n  testDuration?: number;\n}\n</code></pre>"},{"location":"api/types/#llm-types","title":"LLM Types","text":""},{"location":"api/types/#llmconfig","title":"LLMConfig","text":"<p>LLM provider configuration.</p> <pre><code>interface LLMConfig {\n  provider: string;\n  model: string;\n  apiKey?: string;\n  baseUrl?: string;\n  temperature?: number;\n  maxTokens?: number;\n  timeout?: number;\n\n  // Azure OpenAI specific\n  deploymentName?: string;\n  apiVersion?: string;\n\n  // OpenRouter specific\n  siteUrl?: string;\n  siteName?: string;\n\n  // Extended thinking / reasoning\n  thinkingBudget?: number | string;\n\n  // Continuation settings\n  continuation?: ContinuationConfig;\n}\n</code></pre>"},{"location":"api/types/#llmrequest","title":"LLMRequest","text":"<p>Request to an LLM.</p> <pre><code>interface LLMRequest {\n  prompt: string;\n  systemPrompt?: string;\n  temperature?: number;\n  maxTokens?: number;\n  stop?: string[];\n}\n</code></pre>"},{"location":"api/types/#llmresponse","title":"LLMResponse","text":"<p>Response from an LLM.</p> <pre><code>interface LLMResponse {\n  content: string;\n  model: string;\n  usage: TokenUsage;\n  duration: number;\n  finishReason: \"stop\" | \"length\" | \"content_filter\" | \"error\";\n}\n</code></pre>"},{"location":"api/types/#tokenusage","title":"TokenUsage","text":"<p>Token usage statistics.</p> <pre><code>interface TokenUsage {\n  promptTokens: number;\n  completionTokens: number;\n  totalTokens: number;\n  estimatedCost?: number;\n}\n</code></pre>"},{"location":"api/types/#codegenerationresult","title":"CodeGenerationResult","text":"<p>Result of code generation.</p> <pre><code>interface CodeGenerationResult {\n  code: string;\n  language: \"al\" | \"diff\";\n  response: LLMResponse;\n  extractedFromDelimiters: boolean;\n}\n</code></pre>"},{"location":"api/types/#container-types","title":"Container Types","text":""},{"location":"api/types/#containerconfig","title":"ContainerConfig","text":"<p>Container configuration.</p> <pre><code>interface ContainerConfig {\n  name: string;\n  bcVersion: string;\n  memoryLimit: string;\n  acceptEula: boolean;\n  includeAL: boolean;\n  includeTestToolkit: boolean;\n  credentials?: ContainerCredentials;\n}\n\ninterface ContainerCredentials {\n  username: string;\n  password: string;\n}\n</code></pre>"},{"location":"api/types/#compilationresult","title":"CompilationResult","text":"<p>Result of AL compilation.</p> <pre><code>interface CompilationResult {\n  success: boolean;\n  errors: CompilationError[];\n  warnings: CompilationWarning[];\n  output: string;\n  duration: number;\n  artifactPath?: string;\n}\n\ninterface CompilationError {\n  code: string;\n  message: string;\n  file: string;\n  line: number;\n  column: number;\n  severity: \"error\" | \"warning\" | \"info\";\n}\n</code></pre>"},{"location":"api/types/#testresult","title":"TestResult","text":"<p>Result of test execution.</p> <pre><code>interface TestResult {\n  success: boolean;\n  totalTests: number;\n  passedTests: number;\n  failedTests: number;\n  duration: number;\n  results: TestCaseResult[];\n  output: string;\n}\n\ninterface TestCaseResult {\n  name: string;\n  passed: boolean;\n  duration: number;\n  error?: string;\n}\n</code></pre>"},{"location":"api/types/#containerstatus","title":"ContainerStatus","text":"<p>Container status information.</p> <pre><code>interface ContainerStatus {\n  name: string;\n  isRunning: boolean;\n  bcVersion?: string;\n  uptime?: number;\n  health: \"healthy\" | \"unhealthy\" | \"starting\" | \"stopped\";\n}\n</code></pre>"},{"location":"api/types/#agent-types","title":"Agent Types","text":""},{"location":"api/types/#agentconfig","title":"AgentConfig","text":"<p>Agent configuration.</p> <pre><code>interface AgentConfig {\n  id: string;\n  name: string;\n  description?: string;\n  model: string;\n  maxTurns: number;\n  maxTokens?: number;\n  workingDir?: string;\n  settingSources?: (\"user\" | \"project\")[];\n  allowedTools: string[];\n  mcpServers?: Record&lt;string, MCPServerConfig&gt;;\n  systemPrompt?: SystemPromptConfig;\n  promptTemplate?: \"universal\" | \"legacy\";\n  toolNaming?: \"generic\" | \"mcp\";\n  limits?: AgentLimits;\n  sandbox?: SandboxModeConfig;\n  extends?: string;\n  tags?: string[];\n}\n\ninterface AgentLimits {\n  maxCompileAttempts?: number;\n  timeoutMs?: number;\n}\n\ntype SystemPromptConfig =\n  | string\n  | { preset: \"claude_code\"; append?: string };\n</code></pre>"},{"location":"api/types/#agentexecutionresult","title":"AgentExecutionResult","text":"<p>Result of agent execution.</p> <pre><code>interface AgentExecutionResult {\n  taskId: string;\n  agentId: string;\n  executionId: string;\n  success: boolean;\n  finalCode?: string;\n  turns: AgentTurn[];\n  metrics: AgentCostMetrics;\n  terminationReason: TerminationReason;\n  duration: number;\n  executedAt: Date;\n  testResult?: TestResult;\n  resultSummary?: ParsedTaskResult;\n  failureDetails?: DetailedFailureReason;\n}\n\ntype TerminationReason =\n  | \"success\"\n  | \"max_turns\"\n  | \"max_tokens\"\n  | \"max_compile_attempts\"\n  | \"test_failure\"\n  | \"timeout\"\n  | \"error\";\n</code></pre>"},{"location":"api/types/#agentcostmetrics","title":"AgentCostMetrics","text":"<p>Cost metrics for agent execution.</p> <pre><code>interface AgentCostMetrics {\n  turns: number;\n  promptTokens: number;\n  completionTokens: number;\n  totalTokens: number;\n  estimatedCost: number;\n  compileAttempts: number;\n  testRuns: number;\n}\n</code></pre>"},{"location":"api/types/#configuration-types","title":"Configuration Types","text":""},{"location":"api/types/#centralgaugeconfig","title":"CentralGaugeConfig","text":"<p>Main configuration structure.</p> <pre><code>interface CentralGaugeConfig {\n  defaultModels?: {\n    benchmark?: string[];\n    development?: string[];\n    comparison?: string[];\n  };\n\n  llm?: {\n    temperature?: number;\n    maxTokens?: number;\n    timeout?: number;\n  };\n\n  benchmark?: {\n    attempts?: number;\n    outputDir?: string;\n    templateDir?: string;\n  };\n\n  container?: {\n    provider?: string;\n    name?: string;\n    bcVersion?: string;\n    memoryLimit?: string;\n    credentials?: {\n      username?: string;\n      password?: string;\n    };\n  };\n\n  debug?: {\n    enabled?: boolean;\n    outputDir?: string;\n    logLevel?: \"basic\" | \"detailed\" | \"verbose\";\n  };\n\n  systemPrompts?: Record&lt;string, SystemPromptDefinition&gt;;\n  variantProfiles?: Record&lt;string, VariantProfile&gt;;\n}\n</code></pre>"},{"location":"api/types/#variant-types","title":"Variant Types","text":""},{"location":"api/types/#modelvariant","title":"ModelVariant","text":"<p>Model with variant configuration.</p> <pre><code>interface ModelVariant {\n  provider: string;\n  model: string;\n  variantId: string;\n  config?: VariantConfig;\n}\n\ninterface VariantConfig {\n  temperature?: number;\n  maxTokens?: number;\n  systemPromptName?: string;\n  thinkingBudget?: number;\n  timeout?: number;\n  profile?: string;\n}\n</code></pre>"},{"location":"api/types/#error-types","title":"Error Types","text":""},{"location":"api/types/#error-hierarchy","title":"Error Hierarchy","text":"<pre><code>class CentralGaugeError extends Error {\n  constructor(\n    message: string,\n    public readonly code: string,\n    public readonly context?: Record&lt;string, unknown&gt;,\n  );\n}\n\nclass TaskExecutionError extends CentralGaugeError {\n  constructor(\n    message: string,\n    public readonly taskId: string,\n    public readonly attemptNumber?: number,\n    context?: Record&lt;string, unknown&gt;,\n  );\n}\n\nclass LLMProviderError extends CentralGaugeError {\n  constructor(\n    message: string,\n    public readonly provider: string,\n    public readonly isRetryable: boolean,\n    public readonly retryAfterMs?: number,\n    context?: Record&lt;string, unknown&gt;,\n  );\n}\n\nclass ContainerError extends CentralGaugeError {\n  constructor(\n    message: string,\n    public readonly containerName: string,\n    public readonly operation:\n      | \"setup\"\n      | \"start\"\n      | \"stop\"\n      | \"compile\"\n      | \"test\"\n      | \"health\",\n    context?: Record&lt;string, unknown&gt;,\n  );\n}\n</code></pre>"},{"location":"api/types/#prompt-types","title":"Prompt Types","text":""},{"location":"api/types/#clipromptoverrides","title":"CLIPromptOverrides","text":"<p>CLI options for prompt customization including knowledge bank.</p> <pre><code>interface CLIPromptOverrides {\n  /** System prompt override */\n  systemPrompt?: string;\n\n  /** Prefix override */\n  prefix?: string;\n\n  /** Suffix override */\n  suffix?: string;\n\n  /** Which stage these apply to (default: both) */\n  stage?: InjectionStage | \"both\";\n\n  /** Which provider these apply to (default: all) */\n  provider?: string;\n\n  /** Pre-loaded knowledge bank content to prepend to system prompt */\n  knowledgeContent?: string;\n\n  /** Custom run label for results/reports */\n  runLabel?: string;\n}\n\ntype InjectionStage = \"generation\" | \"fix\";\n</code></pre>"},{"location":"api/types/#knowledgeloadoptions","title":"KnowledgeLoadOptions","text":"<p>Options for loading knowledge files.</p> <pre><code>interface KnowledgeLoadOptions {\n  /** Specific files to load */\n  files?: string[];\n\n  /** Directory to load all .md files from */\n  directory?: string;\n}\n</code></pre>"},{"location":"api/types/#resolvedpromptinjection","title":"ResolvedPromptInjection","text":"<p>Result of resolving prompt injections from all config levels.</p> <pre><code>interface ResolvedPromptInjection {\n  /** Resolved system prompt */\n  system?: string;\n\n  /** Resolved prefix */\n  prefix?: string;\n\n  /** Resolved suffix */\n  suffix?: string;\n}\n</code></pre>"},{"location":"api/types/#see-also","title":"See Also","text":"<ul> <li>API Index - Module overview</li> <li>Architecture - System design</li> <li>LLM Adapters - LLM integration</li> <li>bench Command - Knowledge Bank - CLI usage</li> </ul>"},{"location":"architecture/agents/","title":"Agent System","text":"<p>The agent system enables autonomous LLM agents (like Claude Code) to iteratively generate, compile, and fix AL code until success. Unlike single-shot LLM benchmarks, agents can use tools to inspect errors and refine their solutions.</p>"},{"location":"architecture/agents/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       Agent Executor                                 \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502                    Agent Configuration                         \u2502 \u2502\n\u2502   \u2502  - Model selection                                             \u2502 \u2502\n\u2502   \u2502  - Tools allowed                                               \u2502 \u2502\n\u2502   \u2502  - System prompt                                               \u2502 \u2502\n\u2502   \u2502  - Execution limits                                            \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                              \u2502                                       \u2502\n\u2502                              \u25bc                                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502                    Execution Loop                              \u2502 \u2502\n\u2502   \u2502  1. Generate code                                              \u2502 \u2502\n\u2502   \u2502  2. Compile via MCP tool                                       \u2502 \u2502\n\u2502   \u2502  3. Read errors                                                \u2502 \u2502\n\u2502   \u2502  4. Fix code                                                   \u2502 \u2502\n\u2502   \u2502  5. Repeat until success or limit                              \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                              \u2502                                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u2502                \u2502                \u2502\n              \u25bc                \u25bc                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Claude Code     \u2502  \u2502  MCP Server  \u2502  \u2502   BC Container   \u2502\n\u2502  (Agent SDK)     \u2502  \u2502  (AL Tools)  \u2502  \u2502   (Compilation)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/agents/#agent-configuration","title":"Agent Configuration","text":"<p>Agents are configured in YAML files in the <code>agents/</code> directory:</p> <pre><code># agents/my-agent.yml\nid: my-agent\nname: \"My Custom Agent\"\ndescription: \"Optimized for BC development\"\n\n# Model selection\nmodel: claude-opus-4-5-20251101\n\n# Execution limits\nmaxTurns: 100\nmaxTokens: 500000\n\n# Project directory with CLAUDE.md, skills, etc.\nworkingDir: agents/al-project\n\n# Settings to load\nsettingSources:\n  - project\n\n# Tools the agent can use\nallowedTools:\n  - Read\n  - Write\n  - Edit\n  - Glob\n  - Grep\n  - Bash\n  - Skill\n\n# MCP servers for AL tools\nmcpServers:\n  al-tools:\n    command: deno\n    args:\n      - run\n      - --allow-all\n      - mcp/al-tools-server.ts\n\n# System prompt configuration\nsystemPrompt:\n  preset: claude_code\n  append: |\n    ## AL Code Generation Workflow\n    1. Read the task description\n    2. Write AL code to .al files\n    3. Use mcp__al-tools__al_compile to compile\n    4. Fix errors and recompile until success\n\n# Execution limits\nlimits:\n  maxCompileAttempts: 15\n  timeoutMs: 300000\n\n# Tags for filtering\ntags:\n  - baseline\n  - al-generation\n</code></pre>"},{"location":"architecture/agents/#configuration-schema","title":"Configuration Schema","text":""},{"location":"architecture/agents/#agentconfig","title":"AgentConfig","text":"<pre><code>interface AgentConfig {\n  // Identification\n  id: string;\n  name: string;\n  description?: string;\n\n  // Model\n  model: string; // Preset alias or provider/model\n\n  // Execution limits\n  maxTurns: number;\n  maxTokens?: number;\n\n  // Claude Code features\n  workingDir?: string;\n  settingSources?: (\"user\" | \"project\")[];\n  allowedTools: string[];\n  mcpServers?: Record&lt;string, MCPServerConfig&gt;;\n  systemPrompt?: SystemPromptConfig;\n\n  // Execution\n  limits?: AgentLimits;\n  sandbox?: SandboxModeConfig;\n\n  // Inheritance\n  extends?: string;\n  tags?: string[];\n}\n</code></pre>"},{"location":"architecture/agents/#mcpserverconfig","title":"MCPServerConfig","text":"<pre><code>interface MCPServerConfig {\n  command: string;\n  args?: string[];\n  env?: Record&lt;string, string&gt;;\n  cwd?: string;\n}\n</code></pre>"},{"location":"architecture/agents/#systempromptconfig","title":"SystemPromptConfig","text":"<pre><code>type SystemPromptConfig =\n  | string // Custom system prompt\n  | {\n    preset: \"claude_code\"; // Use Claude Code's built-in\n    append?: string; // Optional text to append\n  };\n</code></pre>"},{"location":"architecture/agents/#agentlimits","title":"AgentLimits","text":"<pre><code>interface AgentLimits {\n  maxCompileAttempts?: number; // Max compilation attempts\n  timeoutMs?: number; // Overall timeout\n}\n</code></pre>"},{"location":"architecture/agents/#agent-registry","title":"Agent Registry","text":"<p>The <code>AgentRegistry</code> manages agent configurations:</p> <pre><code>import { AgentRegistry } from \"../src/agents/registry.ts\";\n\n// Load agents from directory\nawait AgentRegistry.load(\"agents\");\n\n// Get a specific agent\nconst config = AgentRegistry.get(\"my-agent\");\n\n// List available agents\nconst agents = AgentRegistry.list();\n// [\"default\", \"my-agent\", ...]\n\n// Validate an agent config\nconst validation = AgentRegistry.validate(config);\n// { valid: true, errors: [], warnings: [] }\n</code></pre>"},{"location":"architecture/agents/#agent-executor","title":"Agent Executor","text":"<p>The <code>AgentTaskExecutor</code> runs agents on tasks:</p> <pre><code>import { AgentTaskExecutor } from \"../src/agents/executor.ts\";\n\nconst executor = new AgentTaskExecutor();\n\nconst result = await executor.execute(agentConfig, taskManifest, {\n  projectDir: \"/path/to/workspace\",\n  containerName: \"Cronus27\",\n  containerProvider: \"bccontainer\",\n  debug: true,\n  sandbox: false,\n});\n</code></pre>"},{"location":"architecture/agents/#execution-options","title":"Execution Options","text":"<pre><code>interface AgentExecutionOptions {\n  projectDir: string;\n  containerName: string;\n  containerProvider: string;\n  debug?: boolean;\n  abortSignal?: AbortSignal;\n  sandbox?: boolean;\n  mcpHttpPort?: number;\n}\n</code></pre>"},{"location":"architecture/agents/#execution-result","title":"Execution Result","text":"<pre><code>interface AgentExecutionResult {\n  // Identification\n  taskId: string;\n  agentId: string;\n  executionId: string;\n\n  // Outcome\n  success: boolean;\n  finalCode?: string;\n  terminationReason: TerminationReason;\n\n  // Metrics\n  turns: AgentTurn[];\n  metrics: AgentCostMetrics;\n  duration: number;\n\n  // Test results\n  testResult?: TestResult;\n  resultSummary?: ParsedTaskResult;\n\n  // Failure details (if failed)\n  failureDetails?: DetailedFailureReason;\n\n  executedAt: Date;\n}\n\ntype TerminationReason =\n  | \"success\"\n  | \"max_turns\"\n  | \"max_tokens\"\n  | \"max_compile_attempts\"\n  | \"test_failure\"\n  | \"timeout\"\n  | \"error\";\n</code></pre>"},{"location":"architecture/agents/#mcp-tools","title":"MCP Tools","text":"<p>Agents use MCP (Model Context Protocol) tools to interact with the AL compiler:</p>"},{"location":"architecture/agents/#al_compile","title":"al_compile","text":"<p>Compiles AL code in a project directory:</p> <pre><code>// Tool input\n{\n  projectDir: \"/path/to/project\",\n  containerName: \"Cronus27\"\n}\n\n// Tool output (success)\n\"Compilation: **Success**\\nNo errors found.\"\n\n// Tool output (failure)\n\"Compilation: **Failed**\\nErrors found:\\n- AL0001: Syntax error at line 10\"\n</code></pre>"},{"location":"architecture/agents/#al_verify","title":"al_verify","text":"<p>Compiles and runs tests:</p> <pre><code>// Tool input\n{\n  projectDir: \"/path/to/project\",\n  testFile: \"/path/to/test.al\",\n  testCodeunitId: 80001,\n  containerName: \"Cronus27\"\n}\n\n// Tool output\n\"Compilation: **Success**\\nTests: 4 passed, 0 failed\\nAll tests passed!\"\n</code></pre>"},{"location":"architecture/agents/#al_verify_task","title":"al_verify_task","text":"<p>Verifies a task by ID:</p> <pre><code>// Tool input\n{\n  projectDir: \"/path/to/project\",\n  taskId: \"CG-AL-E001\",\n  containerName: \"Cronus27\"\n}\n</code></pre>"},{"location":"architecture/agents/#sandbox-mode","title":"Sandbox Mode","text":"<p>Sandbox mode runs agents in isolated Windows containers:</p> <pre><code># Agent config with sandbox\nsandbox:\n  enabled: true\n  provider: windows\n  image: centralgauge/agent-sandbox:windows-latest\n</code></pre>"},{"location":"architecture/agents/#sandbox-architecture","title":"Sandbox Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          Host Machine                                \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502                    MCP HTTP Server                             \u2502 \u2502\n\u2502   \u2502                    (port 3100)                                 \u2502 \u2502\n\u2502   \u2502  - Path translation (C:\\workspace -&gt; host path)                \u2502 \u2502\n\u2502   \u2502  - AL compilation tools                                        \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                              \u2502 HTTP                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u2502\n                               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Docker Container (Sandbox)                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502  Windows Server Core 2025                                      \u2502 \u2502\n\u2502   \u2502  - Node.js                                                     \u2502 \u2502\n\u2502   \u2502  - Git Bash                                                    \u2502 \u2502\n\u2502   \u2502  - Claude Code CLI                                             \u2502 \u2502\n\u2502   \u2502                                                                \u2502 \u2502\n\u2502   \u2502  Workspace: C:\\workspace (mounted from host)                   \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/agents/#using-sandbox-mode","title":"Using Sandbox Mode","text":"<pre><code># Run with sandbox\ndeno task bench \\\n  --agents my-agent \\\n  --tasks tasks/easy/*.yml \\\n  --container Cronus27 \\\n  --sandbox\n</code></pre>"},{"location":"architecture/agents/#agent-inheritance","title":"Agent Inheritance","text":"<p>Agents can extend other agents:</p> <pre><code># agents/minimal.yml\nid: minimal\nextends: default\nname: \"Minimal Agent\"\ndescription: \"Extends default with fewer tools\"\n\n# Override tools\nallowedTools:\n  - Read\n  - Write\n  - Edit\n\n# Override limits\nlimits:\n  maxCompileAttempts: 5\n</code></pre> <p>Resolution order:</p> <ol> <li>Agent's own settings</li> <li>Parent agent's settings</li> <li>Default values</li> </ol>"},{"location":"architecture/agents/#cost-tracking","title":"Cost Tracking","text":"<p>Agent executions track costs:</p> <pre><code>interface AgentCostMetrics {\n  turns: number;\n  promptTokens: number;\n  completionTokens: number;\n  totalTokens: number;\n  estimatedCost: number; // USD\n  compileAttempts: number;\n  testRuns: number;\n}\n</code></pre>"},{"location":"architecture/agents/#failure-details","title":"Failure Details","text":"<p>When agents fail, detailed failure information is captured:</p> <pre><code>interface DetailedFailureReason {\n  terminationReason: TerminationReason;\n  phase: FailurePhase;\n  summary: string;\n\n  // Phase-specific details\n  compilation?: CompilationFailureDetails;\n  tests?: TestFailureDetails;\n  timeout?: TimeoutDetails;\n  container?: ContainerFailureDetails;\n\n  failedAt: Date;\n}\n\ntype FailurePhase =\n  | \"container_startup\"\n  | \"mcp_connection\"\n  | \"agent_execution\"\n  | \"compilation\"\n  | \"test_execution\"\n  | \"timeout\"\n  | \"unknown\";\n</code></pre>"},{"location":"architecture/agents/#running-agent-benchmarks","title":"Running Agent Benchmarks","text":""},{"location":"architecture/agents/#basic-usage","title":"Basic Usage","text":"<pre><code># Single agent\ndeno task bench --agents default --tasks tasks/easy/*.yml --container Cronus27\n\n# Multiple agents for comparison\ndeno task bench --agents default,minimal --tasks tasks/easy/*.yml --container Cronus27\n\n# With sandbox mode\ndeno task bench --agents default --tasks tasks/easy/*.yml --container Cronus27 --sandbox\n\n# With debug output\ndeno task bench --agents default --tasks tasks/easy/*.yml --debug\n</code></pre>"},{"location":"architecture/agents/#output","title":"Output","text":"<pre><code>[CentralGauge] Starting agent benchmark...\n[Info] Agents: default\n[Info] Tasks: tasks/easy/CG-AL-E001-basic-table.yml\n[Info] Container: Cronus27\n\n[Task] CG-AL-E001: Running with 1 agent(s)\n[default] Starting...\n[default] pass (tests: 4/4), turns: 12, cost: $0.0234\n\n[Summary]\nAgent        | Pass | Fail | Cost      | Turns\n-------------|------|------|-----------|-------\ndefault      | 1    | 0    | $0.0234   | 12\n</code></pre>"},{"location":"architecture/agents/#creating-custom-agents","title":"Creating Custom Agents","text":""},{"location":"architecture/agents/#1-define-configuration","title":"1. Define Configuration","text":"<p>Create <code>agents/my-agent.yml</code>:</p> <pre><code>id: my-agent\nname: \"My Custom Agent\"\nmodel: claude-opus-4-5-20251101\nmaxTurns: 100\n\nallowedTools:\n  - Read\n  - Write\n  - Edit\n  - Bash\n\nsystemPrompt:\n  preset: claude_code\n  append: |\n    Your custom instructions here.\n\nlimits:\n  maxCompileAttempts: 10\n  timeoutMs: 180000\n</code></pre>"},{"location":"architecture/agents/#2-create-working-directory-optional","title":"2. Create Working Directory (Optional)","text":"<p>Create <code>agents/my-project/CLAUDE.md</code>:</p> <pre><code># AL Development Guide\n\n## Code Style\n\n- Use PascalCase for all identifiers\n- Include proper captions\n- Add data classification\n</code></pre> <p>Reference in config:</p> <pre><code>workingDir: agents/my-project\nsettingSources:\n  - project\n</code></pre>"},{"location":"architecture/agents/#3-test-the-agent","title":"3. Test the Agent","text":"<pre><code>deno task bench --agents my-agent --tasks tasks/easy/CG-AL-E001*.yml\n</code></pre>"},{"location":"architecture/agents/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture Overview - System design</li> <li>LLM Adapters - LLM integration</li> <li>Running Benchmarks - Usage guide</li> </ul>"},{"location":"architecture/containers/","title":"Container Providers","text":"<p>Container providers manage Business Central containers for compilation and test execution. CentralGauge abstracts container operations through a provider interface.</p>"},{"location":"architecture/containers/#provider-registry","title":"Provider Registry","text":"<p>The <code>ContainerProviderRegistry</code> manages provider instances:</p> <pre><code>import { ContainerProviderRegistry } from \"../src/container/registry.ts\";\n\n// Get a specific provider\nconst provider = ContainerProviderRegistry.create(\"bccontainer\");\n\n// Auto-detect best available provider\nconst bestProvider = await ContainerProviderRegistry.getDefault();\n\n// List available providers\nconst providers = ContainerProviderRegistry.list();\n// [\"bccontainer\", \"docker\", \"mock\"]\n</code></pre>"},{"location":"architecture/containers/#available-providers","title":"Available Providers","text":"Provider Platform Description <code>bccontainer</code> Windows Uses bccontainerhelper PowerShell module <code>docker</code> All Direct Docker API calls <code>mock</code> All Testing mock (no real container)"},{"location":"architecture/containers/#auto-detection","title":"Auto-Detection","text":"<p><code>getDefault()</code> auto-detects the best provider:</p> <ol> <li>bccontainer - Windows only, checks for bccontainerhelper module</li> <li>docker - All platforms, checks <code>docker --version</code></li> <li>mock - Fallback when no real containers available</li> </ol>"},{"location":"architecture/containers/#provider-interface","title":"Provider Interface","text":"<p>All providers implement <code>ContainerProvider</code>:</p> <pre><code>interface ContainerProvider {\n  readonly name: string;\n\n  // Lifecycle\n  setup(config: ContainerConfig): Promise&lt;void&gt;;\n  start(name: string): Promise&lt;void&gt;;\n  stop(name: string): Promise&lt;void&gt;;\n  remove(name: string): Promise&lt;void&gt;;\n\n  // Operations\n  compile(name: string, projectPath: string): Promise&lt;CompilationResult&gt;;\n  runTests(\n    name: string,\n    extensionId: string,\n    testCodeunitId?: number,\n  ): Promise&lt;TestResult&gt;;\n\n  // Status\n  status(name: string): Promise&lt;ContainerStatus&gt;;\n  isHealthy(name: string): Promise&lt;boolean&gt;;\n}\n</code></pre>"},{"location":"architecture/containers/#configuration","title":"Configuration","text":""},{"location":"architecture/containers/#containerconfig","title":"ContainerConfig","text":"<pre><code>interface ContainerConfig {\n  name: string;\n  bcVersion: string;\n  memoryLimit: string;\n  acceptEula: boolean;\n  includeAL: boolean;\n  includeTestToolkit: boolean;\n  credentials?: ContainerCredentials;\n}\n\ninterface ContainerCredentials {\n  username: string;\n  password: string;\n}\n</code></pre>"},{"location":"architecture/containers/#example-configuration","title":"Example Configuration","text":"<pre><code># .centralgauge.yml\ncontainer:\n  provider: bccontainer\n  name: Cronus27\n  bcVersion: \"27.0\"\n  memoryLimit: 8G\n  credentials:\n    username: admin\n    password: admin\n</code></pre>"},{"location":"architecture/containers/#bccontainerhelper-provider","title":"bccontainerhelper Provider","text":"<p>The recommended provider for Windows. Uses the bccontainerhelper PowerShell module.</p>"},{"location":"architecture/containers/#prerequisites","title":"Prerequisites","text":"<pre><code># Install bccontainerhelper\nInstall-Module -Name bccontainerhelper -Force\n\n# Create a container\n$cred = New-Object PSCredential 'admin', (ConvertTo-SecureString 'admin' -AsPlainText -Force)\nNew-BcContainer -containerName Cronus27 -credential $cred -artifactUrl (Get-BCArtifactUrl -country us -version 27) -includeTestToolkit\n</code></pre>"},{"location":"architecture/containers/#operations","title":"Operations","text":"<pre><code>const provider = ContainerProviderRegistry.create(\"bccontainer\");\n\n// Check status\nconst status = await provider.status(\"Cronus27\");\nconsole.log(status.isRunning, status.health);\n\n// Compile AL project\nconst compileResult = await provider.compile(\"Cronus27\", \"U:/Git/MyProject\");\nconsole.log(compileResult.success, compileResult.errors);\n\n// Run tests\nconst testResult = await provider.runTests(\n  \"Cronus27\",\n  \"12345678-1234-1234-1234-123456789012\",\n);\nconsole.log(testResult.passedTests, testResult.failedTests);\n</code></pre>"},{"location":"architecture/containers/#credentials","title":"Credentials","text":"<p>Set container credentials:</p> <pre><code>const provider = ContainerProviderRegistry.create(\n  \"bccontainer\",\n) as BcContainerProvider;\nprovider.setCredentials(\"Cronus27\", {\n  username: \"admin\",\n  password: \"admin\",\n});\n</code></pre>"},{"location":"architecture/containers/#docker-provider","title":"Docker Provider","text":"<p>Direct Docker API integration for non-Windows platforms or custom setups.</p>"},{"location":"architecture/containers/#usage","title":"Usage","text":"<pre><code>const provider = ContainerProviderRegistry.create(\"docker\");\n\nawait provider.setup({\n  name: \"my-bc-container\",\n  bcVersion: \"24.0\",\n  memoryLimit: \"8G\",\n  acceptEula: true,\n  includeAL: true,\n  includeTestToolkit: true,\n});\n</code></pre>"},{"location":"architecture/containers/#mock-provider","title":"Mock Provider","text":"<p>For testing without real containers:</p> <pre><code>const provider = ContainerProviderRegistry.create(\"mock\");\n\n// Returns success by default\nconst result = await provider.compile(\"mock\", \"/path/to/project\");\n// result.success === true\n\n// Configure mock responses\n(provider as MockContainerProvider).setCompileResult({\n  success: false,\n  errors: [{ code: \"AL0001\", message: \"Syntax error\", ... }],\n});\n</code></pre>"},{"location":"architecture/containers/#result-types","title":"Result Types","text":""},{"location":"architecture/containers/#compilationresult","title":"CompilationResult","text":"<pre><code>interface CompilationResult {\n  success: boolean;\n  errors: CompilationError[];\n  warnings: CompilationWarning[];\n  output: string;\n  duration: number; // milliseconds\n  artifactPath?: string; // Path to compiled .app file\n}\n\ninterface CompilationError {\n  code: string; // e.g., \"AL0001\"\n  message: string;\n  file: string;\n  line: number;\n  column: number;\n  severity: \"error\" | \"warning\" | \"info\";\n}\n</code></pre>"},{"location":"architecture/containers/#testresult","title":"TestResult","text":"<pre><code>interface TestResult {\n  success: boolean;\n  totalTests: number;\n  passedTests: number;\n  failedTests: number;\n  duration: number; // milliseconds\n  results: TestCaseResult[];\n  output: string;\n}\n\ninterface TestCaseResult {\n  name: string;\n  passed: boolean;\n  duration: number;\n  error?: string;\n}\n</code></pre>"},{"location":"architecture/containers/#containerstatus","title":"ContainerStatus","text":"<pre><code>interface ContainerStatus {\n  name: string;\n  isRunning: boolean;\n  bcVersion?: string;\n  uptime?: number;\n  health: \"healthy\" | \"unhealthy\" | \"starting\" | \"stopped\";\n}\n</code></pre>"},{"location":"architecture/containers/#compilation-workflow","title":"Compilation Workflow","text":"<pre><code>1. Provider receives projectPath\n   \u2502\n   \u25bc\n2. Create app.json if missing\n   \u2502\n   \u25bc\n3. Copy source files to build directory\n   \u2502\n   \u25bc\n4. Invoke AL compiler in container\n   \u2502\n   \u25bc\n5. Parse compiler output\n   \u2502\n   \u25bc\n6. Return CompilationResult\n</code></pre>"},{"location":"architecture/containers/#powershell-commands-bccontainer","title":"PowerShell Commands (bccontainer)","text":"<pre><code># Compile\nCompile-AppInBcContainer -containerName Cronus27 -appProjectFolder $ProjectPath\n\n# Run tests\nRun-TestsInBcContainer -containerName Cronus27 -testCodeunitId $CodeunitId\n</code></pre>"},{"location":"architecture/containers/#test-execution-workflow","title":"Test Execution Workflow","text":"<pre><code>1. Provider receives extensionId and testCodeunitId\n   \u2502\n   \u25bc\n2. Publish compiled extension\n   \u2502\n   \u25bc\n3. Invoke test runner in container\n   \u2502\n   \u25bc\n4. Parse test output\n   \u2502\n   \u25bc\n5. Return TestResult\n</code></pre>"},{"location":"architecture/containers/#prereq-apps","title":"Prereq Apps","text":"<p>Some tasks require prerequisite apps. The provider handles:</p> <ol> <li>Detecting prereq dependencies</li> <li>Compiling prereqs first</li> <li>Publishing prereqs before main app</li> <li>Including prereqs in app.json dependencies</li> </ol> <p>See <code>.claude/rules/prereq-apps.md</code> for details.</p>"},{"location":"architecture/containers/#instance-caching","title":"Instance Caching","text":"<p>Providers are cached as singletons:</p> <pre><code>const p1 = ContainerProviderRegistry.create(\"bccontainer\");\nconst p2 = ContainerProviderRegistry.create(\"bccontainer\");\n// p1 === p2 (same instance)\n\n// Clear cache (for testing)\nContainerProviderRegistry.clearInstances();\n</code></pre>"},{"location":"architecture/containers/#creating-custom-providers","title":"Creating Custom Providers","text":"<p>To add a new container provider:</p>"},{"location":"architecture/containers/#1-create-provider-class","title":"1. Create Provider Class","text":"<pre><code>// src/container/my-provider.ts\nimport type {\n  CompilationResult,\n  ContainerConfig,\n  ContainerProvider,\n  TestResult,\n} from \"./types.ts\";\n\nexport class MyContainerProvider implements ContainerProvider {\n  readonly name = \"my-container\";\n\n  async setup(config: ContainerConfig): Promise&lt;void&gt; {\n    // Setup implementation\n  }\n\n  async start(name: string): Promise&lt;void&gt; {\n    // Start implementation\n  }\n\n  async stop(name: string): Promise&lt;void&gt; {\n    // Stop implementation\n  }\n\n  async remove(name: string): Promise&lt;void&gt; {\n    // Remove implementation\n  }\n\n  async compile(name: string, projectPath: string): Promise&lt;CompilationResult&gt; {\n    // Compile implementation\n  }\n\n  async runTests(\n    name: string,\n    extensionId: string,\n    testCodeunitId?: number,\n  ): Promise&lt;TestResult&gt; {\n    // Test implementation\n  }\n\n  async status(name: string): Promise&lt;ContainerStatus&gt; {\n    // Status implementation\n  }\n\n  async isHealthy(name: string): Promise&lt;boolean&gt; {\n    // Health check implementation\n  }\n}\n</code></pre>"},{"location":"architecture/containers/#2-register-provider","title":"2. Register Provider","text":"<pre><code>// src/container/registry.ts\nimport { MyContainerProvider } from \"./my-provider.ts\";\n\nstatic {\n  // ... existing registrations\n  this.register(\"my-container\", () =&gt; new MyContainerProvider());\n}\n</code></pre>"},{"location":"architecture/containers/#3-update-auto-detection-optional","title":"3. Update Auto-Detection (Optional)","text":"<pre><code>static async detectBestProvider(): Promise&lt;string&gt; {\n  // Add to detection chain\n  if (await this.isMyContainerAvailable()) {\n    return \"my-container\";\n  }\n  // ... existing checks\n}\n</code></pre>"},{"location":"architecture/containers/#error-handling","title":"Error Handling","text":"<p>Providers throw <code>ContainerError</code> for container-specific errors:</p> <pre><code>import { ContainerError } from \"../src/errors.ts\";\n\ntry {\n  await provider.compile(\"Cronus27\", projectPath);\n} catch (error) {\n  if (error instanceof ContainerError) {\n    console.log(`Container: ${error.containerName}`);\n    console.log(`Operation: ${error.operation}`); // \"compile\" | \"test\" | etc.\n  }\n}\n</code></pre>"},{"location":"architecture/containers/#next-steps","title":"Next Steps","text":"<ul> <li>LLM Adapters - LLM provider integration</li> <li>Agent System - Autonomous agent execution</li> <li>Architecture Overview - System design</li> </ul>"},{"location":"architecture/llm-adapters/","title":"LLM Adapters","text":"<p>LLM adapters provide a unified interface to different LLM providers. Each adapter handles provider-specific authentication, request formatting, and response parsing.</p>"},{"location":"architecture/llm-adapters/#adapter-registry","title":"Adapter Registry","text":"<p>The <code>LLMAdapterRegistry</code> manages adapter creation and pooling:</p> <pre><code>import { LLMAdapterRegistry } from \"../src/llm/registry.ts\";\n\n// Create an adapter\nconst adapter = LLMAdapterRegistry.create(\"anthropic\", {\n  provider: \"anthropic\",\n  model: \"claude-sonnet-4-20250514\",\n  apiKey: Deno.env.get(\"ANTHROPIC_API_KEY\"),\n});\n\n// List available adapters\nconst adapters = LLMAdapterRegistry.list();\n// [\"mock\", \"openai\", \"anthropic\", \"gemini\", \"azure-openai\", \"local\", \"openrouter\"]\n</code></pre>"},{"location":"architecture/llm-adapters/#available-adapters","title":"Available Adapters","text":"Adapter Provider Models <code>anthropic</code> Anthropic Claude 4.5 Opus, Claude 4 Sonnet <code>openai</code> OpenAI GPT-5, GPT-4o, o3, o1 <code>gemini</code> Google Gemini 3 Pro, Gemini 2 Flash <code>azure-openai</code> Azure Azure OpenAI deployments <code>openrouter</code> OpenRouter 200+ models <code>local</code> Local Ollama, vLLM, etc. <code>mock</code> Testing Deterministic mock responses"},{"location":"architecture/llm-adapters/#adapter-interface","title":"Adapter Interface","text":"<p>All adapters implement the <code>LLMAdapter</code> interface:</p> <pre><code>interface LLMAdapter {\n  // Identification\n  readonly name: string;\n  readonly supportedModels: string[];\n\n  // Configuration\n  configure(config: LLMConfig): void;\n  validateConfig(config: LLMConfig): string[];\n\n  // Code generation\n  generateCode(\n    request: LLMRequest,\n    context: GenerationContext,\n  ): Promise&lt;CodeGenerationResult&gt;;\n\n  // Fix generation (for retry attempts)\n  generateFix(\n    originalCode: string,\n    errors: string[],\n    request: LLMRequest,\n    context: GenerationContext,\n  ): Promise&lt;CodeGenerationResult&gt;;\n\n  // Utilities\n  estimateCost(promptTokens: number, completionTokens: number): number;\n  isHealthy(): Promise&lt;boolean&gt;;\n}\n</code></pre>"},{"location":"architecture/llm-adapters/#configuration","title":"Configuration","text":""},{"location":"architecture/llm-adapters/#llmconfig","title":"LLMConfig","text":"<pre><code>interface LLMConfig {\n  provider: string;\n  model: string;\n  apiKey?: string;\n  baseUrl?: string;\n  temperature?: number;\n  maxTokens?: number;\n  timeout?: number;\n\n  // Azure specific\n  deploymentName?: string;\n  apiVersion?: string;\n\n  // OpenRouter specific\n  siteUrl?: string;\n  siteName?: string;\n\n  // Extended thinking\n  thinkingBudget?: number | string;\n}\n</code></pre>"},{"location":"architecture/llm-adapters/#provider-specific-configuration","title":"Provider-Specific Configuration","text":""},{"location":"architecture/llm-adapters/#anthropic","title":"Anthropic","text":"<pre><code>const config: LLMConfig = {\n  provider: \"anthropic\",\n  model: \"claude-sonnet-4-20250514\",\n  apiKey: Deno.env.get(\"ANTHROPIC_API_KEY\"),\n  temperature: 0.1,\n  maxTokens: 4000,\n  thinkingBudget: 50000, // Extended thinking tokens\n};\n</code></pre>"},{"location":"architecture/llm-adapters/#openai","title":"OpenAI","text":"<pre><code>const config: LLMConfig = {\n  provider: \"openai\",\n  model: \"gpt-4o\",\n  apiKey: Deno.env.get(\"OPENAI_API_KEY\"),\n  temperature: 0.1,\n  maxTokens: 4000,\n};\n</code></pre>"},{"location":"architecture/llm-adapters/#azure-openai","title":"Azure OpenAI","text":"<pre><code>const config: LLMConfig = {\n  provider: \"azure-openai\",\n  model: \"gpt-4\",\n  apiKey: Deno.env.get(\"AZURE_OPENAI_API_KEY\"),\n  baseUrl: \"https://your-resource.openai.azure.com/\",\n  deploymentName: \"gpt-4-deployment\",\n  apiVersion: \"2024-02-01\",\n};\n</code></pre>"},{"location":"architecture/llm-adapters/#openrouter","title":"OpenRouter","text":"<pre><code>const config: LLMConfig = {\n  provider: \"openrouter\",\n  model: \"anthropic/claude-4.5-opus\",\n  apiKey: Deno.env.get(\"OPENROUTER_API_KEY\"),\n  siteUrl: \"https://your-site.com\",\n  siteName: \"Your App Name\",\n};\n</code></pre>"},{"location":"architecture/llm-adapters/#adapter-pooling","title":"Adapter Pooling","text":"<p>For parallel execution, adapters are pooled:</p> <pre><code>// Acquire adapter (creates or reuses from pool)\nconst adapter = LLMAdapterRegistry.acquire(\"anthropic\", config);\n\ntry {\n  const result = await adapter.generateCode(request, context);\n  return result;\n} finally {\n  // Return to pool for reuse\n  LLMAdapterRegistry.release(adapter);\n}\n</code></pre>"},{"location":"architecture/llm-adapters/#pool-management","title":"Pool Management","text":"<pre><code>// Get pool statistics\nconst stats = LLMAdapterRegistry.getPoolStats();\n// { total: 5, inUse: 2, available: 3, byProvider: Map }\n\n// Configure pool limits\nLLMAdapterRegistry.configurePool({\n  maxSize: 50, // Maximum pooled adapters\n  maxIdleMs: 300000, // 5 minute idle timeout\n});\n\n// Clear pool (for testing)\nLLMAdapterRegistry.clearPool();\n</code></pre>"},{"location":"architecture/llm-adapters/#requestresponse-types","title":"Request/Response Types","text":""},{"location":"architecture/llm-adapters/#llmrequest","title":"LLMRequest","text":"<pre><code>interface LLMRequest {\n  prompt: string;\n  systemPrompt?: string;\n  temperature?: number;\n  maxTokens?: number;\n  stop?: string[];\n}\n</code></pre>"},{"location":"architecture/llm-adapters/#llmresponse","title":"LLMResponse","text":"<pre><code>interface LLMResponse {\n  content: string;\n  model: string;\n  usage: TokenUsage;\n  duration: number; // milliseconds\n  finishReason: \"stop\" | \"length\" | \"content_filter\" | \"error\";\n}\n\ninterface TokenUsage {\n  promptTokens: number;\n  completionTokens: number;\n  totalTokens: number;\n  estimatedCost?: number; // USD\n}\n</code></pre>"},{"location":"architecture/llm-adapters/#codegenerationresult","title":"CodeGenerationResult","text":"<pre><code>interface CodeGenerationResult {\n  code: string;\n  language: \"al\" | \"diff\";\n  response: LLMResponse;\n  extractedFromDelimiters: boolean;\n}\n</code></pre>"},{"location":"architecture/llm-adapters/#code-extraction","title":"Code Extraction","text":"<p>The <code>CodeExtractor</code> parses AL code from LLM responses:</p> <pre><code>import { CodeExtractor } from \"../src/llm/code-extractor.ts\";\n\nconst result = CodeExtractor.extract(response.content);\n// Returns: { code: \"table 70000 ...\", language: \"al\", ... }\n</code></pre> <p>Extraction rules:</p> <ol> <li>Look for ```al code blocks</li> <li>Fall back to ``` generic code blocks</li> <li>Fall back to full response content</li> </ol>"},{"location":"architecture/llm-adapters/#streaming-support","title":"Streaming Support","text":"<p>Some adapters support streaming responses:</p> <pre><code>interface StreamingLLMAdapter extends LLMAdapter {\n  readonly supportsStreaming: boolean;\n\n  generateCodeStream(\n    request: LLMRequest,\n    context: GenerationContext,\n    options?: StreamOptions,\n  ): AsyncGenerator&lt;StreamChunk, StreamResult&gt;;\n}\n\n// Check if adapter supports streaming\nif (isStreamingAdapter(adapter)) {\n  for await (const chunk of adapter.generateCodeStream(request, context)) {\n    console.log(chunk.text);\n  }\n}\n</code></pre>"},{"location":"architecture/llm-adapters/#extended-thinking-reasoning","title":"Extended Thinking / Reasoning","text":"<p>For reasoning models, configure thinking budget:</p>"},{"location":"architecture/llm-adapters/#claude-extended-thinking","title":"Claude (Extended Thinking)","text":"<pre><code>const config: LLMConfig = {\n  provider: \"anthropic\",\n  model: \"claude-opus-4-5-20251101\",\n  thinkingBudget: 50000, // Token budget for thinking\n};\n</code></pre>"},{"location":"architecture/llm-adapters/#openai-reasoning-effort","title":"OpenAI (Reasoning Effort)","text":"<pre><code>const config: LLMConfig = {\n  provider: \"openai\",\n  model: \"o3\",\n  thinkingBudget: \"high\", // \"low\" | \"medium\" | \"high\"\n};\n</code></pre>"},{"location":"architecture/llm-adapters/#creating-custom-adapters","title":"Creating Custom Adapters","text":"<p>To add a new provider:</p>"},{"location":"architecture/llm-adapters/#1-create-adapter-class","title":"1. Create Adapter Class","text":"<pre><code>// src/llm/my-adapter.ts\nimport type {\n  LLMAdapter,\n  LLMConfig,\n  LLMRequest,\n  LLMResponse,\n} from \"./types.ts\";\n\nexport class MyAdapter implements LLMAdapter {\n  readonly name = \"my-provider\";\n  readonly supportedModels = [\"model-a\", \"model-b\"];\n\n  private config?: LLMConfig;\n\n  configure(config: LLMConfig): void {\n    this.config = config;\n  }\n\n  async generateCode(\n    request: LLMRequest,\n    context: GenerationContext,\n  ): Promise&lt;CodeGenerationResult&gt; {\n    // Implementation\n  }\n\n  async generateFix(\n    code: string,\n    errors: string[],\n    request: LLMRequest,\n    context: GenerationContext,\n  ): Promise&lt;CodeGenerationResult&gt; {\n    // Implementation\n  }\n\n  validateConfig(config: LLMConfig): string[] {\n    const errors: string[] = [];\n    if (!config.apiKey) {\n      errors.push(\"API key is required\");\n    }\n    return errors;\n  }\n\n  estimateCost(promptTokens: number, completionTokens: number): number {\n    // Pricing calculation\n    return (promptTokens * 0.001 + completionTokens * 0.002) / 1000;\n  }\n\n  async isHealthy(): Promise&lt;boolean&gt; {\n    // Health check\n    return true;\n  }\n}\n</code></pre>"},{"location":"architecture/llm-adapters/#2-register-adapter","title":"2. Register Adapter","text":"<pre><code>// src/llm/registry.ts\nimport { MyAdapter } from \"./my-adapter.ts\";\n\nstatic {\n  // ... existing registrations\n  this.register(\"my-provider\", () =&gt; new MyAdapter());\n}\n</code></pre>"},{"location":"architecture/llm-adapters/#3-add-tests","title":"3. Add Tests","text":"<pre><code>// tests/unit/llm/my-adapter.test.ts\nimport { assertEquals } from \"@std/assert\";\nimport { MyAdapter } from \"../../../src/llm/my-adapter.ts\";\n\nDeno.test(\"MyAdapter generates code\", async () =&gt; {\n  const adapter = new MyAdapter();\n  adapter.configure({\n    provider: \"my-provider\",\n    model: \"model-a\",\n    apiKey: \"test\",\n  });\n\n  const result = await adapter.generateCode(request, context);\n  assertEquals(result.language, \"al\");\n});\n</code></pre>"},{"location":"architecture/llm-adapters/#error-handling","title":"Error Handling","text":"<p>Adapters throw <code>LLMProviderError</code> for provider-specific errors:</p> <pre><code>import {\n  getRetryDelay,\n  isRetryableError,\n  LLMProviderError,\n} from \"../src/errors.ts\";\n\ntry {\n  const result = await adapter.generateCode(request, context);\n} catch (error) {\n  if (error instanceof LLMProviderError) {\n    console.log(`Provider: ${error.provider}`);\n    console.log(`Retryable: ${error.isRetryable}`);\n\n    if (isRetryableError(error)) {\n      const delay = getRetryDelay(error, 1000);\n      await sleep(delay);\n      // Retry\n    }\n  }\n}\n</code></pre>"},{"location":"architecture/llm-adapters/#next-steps","title":"Next Steps","text":"<ul> <li>Container Providers - BC container integration</li> <li>Architecture Overview - System design</li> <li>Running Benchmarks - Usage guide</li> </ul>"},{"location":"architecture/overview/","title":"Architecture Overview","text":"<p>CentralGauge is designed with a layered architecture that separates concerns and enables extensibility.</p>"},{"location":"architecture/overview/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              CLI Layer                                   \u2502\n\u2502                    (Cliffy Command Framework)                           \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502   \u2502  bench  \u2502  \u2502 report  \u2502  \u2502 config  \u2502  \u2502  stats  \u2502  \u2502 verify  \u2502     \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502            \u2502            \u2502            \u2502            \u2502\n         \u25bc            \u25bc            \u25bc            \u25bc            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           Core Library (src/)                            \u2502\n\u2502                                                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502   \u2502   Parallel    \u2502  \u2502     Tasks     \u2502  \u2502    Agents     \u2502              \u2502\n\u2502   \u2502  Orchestrator \u2502  \u2502   Executor    \u2502  \u2502   Executor    \u2502              \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502           \u2502                  \u2502                  \u2502                       \u2502\n\u2502           \u25bc                  \u25bc                  \u25bc                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502   \u2502                      Registries                            \u2502        \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502        \u2502\n\u2502   \u2502  \u2502  LLM Adapter   \u2502         \u2502 Container Provider \u2502        \u2502        \u2502\n\u2502   \u2502  \u2502   Registry     \u2502         \u2502     Registry       \u2502        \u2502        \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502        \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502              \u2502                            \u2502                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502                            \u2502\n               \u25bc                            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     LLM Providers        \u2502    \u2502    BC Container          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502OpenAI  \u2502 \u2502Anthropic\u2502  \u2502    \u2502  \u2502 bccontainerhelper\u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502Gemini  \u2502 \u2502OpenRouter\u2502 \u2502    \u2502  \u2502   Docker API    \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/overview/#layer-responsibilities","title":"Layer Responsibilities","text":""},{"location":"architecture/overview/#cli-layer-cli","title":"CLI Layer (<code>cli/</code>)","text":"<p>The CLI layer handles user interaction:</p> <ul> <li>Command parsing - Uses Cliffy Command framework</li> <li>Input validation - Validates arguments and options</li> <li>Output formatting - Formats results for display</li> <li>TUI - Terminal UI for progress visualization</li> </ul> <p>Key components:</p> <ul> <li><code>cli/centralgauge.ts</code> - Main entry point</li> <li><code>cli/commands/</code> - Individual command implementations</li> <li><code>cli/helpers/</code> - Shared utilities (logging, formatting)</li> <li><code>cli/tui/</code> - Terminal UI components</li> </ul>"},{"location":"architecture/overview/#core-library-src","title":"Core Library (<code>src/</code>)","text":"<p>The core library contains business logic:</p>"},{"location":"architecture/overview/#task-execution-srctasks","title":"Task Execution (<code>src/tasks/</code>)","text":"<ul> <li><code>loader.ts</code> - Loads and validates YAML manifests</li> <li><code>transformer.ts</code> - Transforms manifests to execution contexts</li> <li><code>executor-v2.ts</code> - Executes individual tasks</li> </ul>"},{"location":"architecture/overview/#llm-integration-srcllm","title":"LLM Integration (<code>src/llm/</code>)","text":"<ul> <li><code>registry.ts</code> - Adapter registration and pooling</li> <li><code>types.ts</code> - Core interfaces (LLMAdapter, LLMResponse)</li> <li>Provider adapters: <code>anthropic-adapter.ts</code>, <code>openai-adapter.ts</code>, etc.</li> <li><code>code-extractor.ts</code> - Extracts AL code from responses</li> </ul>"},{"location":"architecture/overview/#container-management-srccontainer","title":"Container Management (<code>src/container/</code>)","text":"<ul> <li><code>registry.ts</code> - Provider registration and auto-detection</li> <li><code>types.ts</code> - Core interfaces (ContainerProvider)</li> <li><code>bc-container-provider.ts</code> - bccontainerhelper integration</li> <li><code>docker-container-provider.ts</code> - Direct Docker API</li> </ul>"},{"location":"architecture/overview/#parallel-execution-srcparallel","title":"Parallel Execution (<code>src/parallel/</code>)","text":"<ul> <li><code>orchestrator.ts</code> - Coordinates parallel benchmark runs</li> <li><code>llm-work-pool.ts</code> - Manages LLM request queuing</li> <li><code>compile-queue.ts</code> - Serializes compilation requests</li> <li><code>rate-limiter.ts</code> - Provider rate limiting</li> </ul>"},{"location":"architecture/overview/#agent-system-srcagents","title":"Agent System (<code>src/agents/</code>)","text":"<ul> <li><code>executor.ts</code> - Executes autonomous agents</li> <li><code>registry.ts</code> - Agent configuration management</li> <li><code>loader.ts</code> - Loads agent YAML configs</li> <li><code>types.ts</code> - Agent interfaces</li> </ul>"},{"location":"architecture/overview/#configuration-srcconfig","title":"Configuration (<code>src/config/</code>)","text":"<ul> <li><code>config.ts</code> - Configuration loading and merging</li> </ul>"},{"location":"architecture/overview/#data-flow","title":"Data Flow","text":""},{"location":"architecture/overview/#llm-benchmark-flow","title":"LLM Benchmark Flow","text":"<pre><code>1. CLI parses arguments\n   \u2502\n   \u25bc\n2. Load task manifests from YAML\n   \u2502\n   \u25bc\n3. Transform to execution contexts\n   \u2502\n   \u25bc\n4. Orchestrator schedules work items\n   \u2502\n   \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u25bc                              \u25bc\n5. LLM Work Pool             6. Compile Queue\n   - Rate limiting               - Sequential execution\n   - Request batching            - Container management\n   \u2502                              \u2502\n   \u25bc                              \u25bc\n7. LLM Adapter generates    8. Container compiles\n   \u2502                              \u2502\n   \u25bc                              \u25bc\n9. Code extractor parses    10. Container runs tests\n   \u2502                              \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n                \u25bc\n11. Result aggregation\n                \u2502\n                \u25bc\n12. Output (JSON, console, reports)\n</code></pre>"},{"location":"architecture/overview/#agent-benchmark-flow","title":"Agent Benchmark Flow","text":"<pre><code>1. CLI parses arguments\n   \u2502\n   \u25bc\n2. Load agent configuration\n   \u2502\n   \u25bc\n3. Load task manifest\n   \u2502\n   \u25bc\n4. Agent executor starts\n   \u2502\n   \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502                               \u2502\n   \u25bc                               \u25bc\n5. MCP Server               6. Agent Container (sandbox)\n   - AL Tools                   - Claude Code CLI\n   - Compile/Test               - Workspace mapping\n   \u2502                               \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n                \u25bc\n7. Iterative loop:\n   - Agent generates code\n   - MCP tools compile\n   - Agent reads errors\n   - Agent fixes code\n   - Repeat until success/limit\n                \u2502\n                \u25bc\n8. Result capture\n                \u2502\n                \u25bc\n9. Output\n</code></pre>"},{"location":"architecture/overview/#key-interfaces","title":"Key Interfaces","text":""},{"location":"architecture/overview/#taskmanifest","title":"TaskManifest","text":"<p>Defines a benchmark task:</p> <pre><code>interface TaskManifest {\n  id: string;\n  description: string;\n  prompt_template: string;\n  fix_template: string;\n  max_attempts: number;\n  expected: {\n    compile: boolean;\n    testApp?: string;\n    testCodeunitId?: number;\n    mustContain?: string[];\n    mustNotContain?: string[];\n  };\n  metrics: string[];\n}\n</code></pre>"},{"location":"architecture/overview/#llmadapter","title":"LLMAdapter","text":"<p>Interface for LLM providers:</p> <pre><code>interface LLMAdapter {\n  readonly name: string;\n  readonly supportedModels: string[];\n\n  configure(config: LLMConfig): void;\n  generateCode(\n    request: LLMRequest,\n    context: GenerationContext,\n  ): Promise&lt;CodeGenerationResult&gt;;\n  generateFix(\n    code: string,\n    errors: string[],\n    request: LLMRequest,\n    context: GenerationContext,\n  ): Promise&lt;CodeGenerationResult&gt;;\n  validateConfig(config: LLMConfig): string[];\n  estimateCost(promptTokens: number, completionTokens: number): number;\n  isHealthy(): Promise&lt;boolean&gt;;\n}\n</code></pre>"},{"location":"architecture/overview/#containerprovider","title":"ContainerProvider","text":"<p>Interface for BC containers:</p> <pre><code>interface ContainerProvider {\n  readonly name: string;\n\n  setup(config: ContainerConfig): Promise&lt;void&gt;;\n  start(name: string): Promise&lt;void&gt;;\n  stop(name: string): Promise&lt;void&gt;;\n  remove(name: string): Promise&lt;void&gt;;\n  compile(name: string, projectPath: string): Promise&lt;CompilationResult&gt;;\n  runTests(name: string, extensionId: string): Promise&lt;TestResult&gt;;\n  status(name: string): Promise&lt;ContainerStatus&gt;;\n  isHealthy(name: string): Promise&lt;boolean&gt;;\n}\n</code></pre>"},{"location":"architecture/overview/#design-patterns","title":"Design Patterns","text":""},{"location":"architecture/overview/#registry-pattern","title":"Registry Pattern","text":"<p>Both LLM adapters and container providers use the registry pattern:</p> <pre><code>class Registry {\n  private static providers = new Map&lt;string, () =&gt; Provider&gt;();\n\n  static register(name: string, factory: () =&gt; Provider): void;\n  static create(name: string): Provider;\n  static list(): string[];\n  static isAvailable(name: string): boolean;\n}\n</code></pre> <p>Benefits:</p> <ul> <li>Pluggable providers</li> <li>Late binding</li> <li>Easy testing with mocks</li> </ul>"},{"location":"architecture/overview/#adapter-pool","title":"Adapter Pool","text":"<p>LLM adapters are pooled for parallel execution:</p> <pre><code>// Acquire from pool\nconst adapter = LLMAdapterRegistry.acquire(\"anthropic\", config);\ntry {\n  await adapter.generateCode(request, context);\n} finally {\n  // Return to pool\n  LLMAdapterRegistry.release(adapter);\n}\n</code></pre>"},{"location":"architecture/overview/#discriminated-unions","title":"Discriminated Unions","text":"<p>Results use discriminated unions for type safety:</p> <pre><code>type Result = SuccessResult | FailureResult;\n\nfunction isSuccess(r: Result): r is SuccessResult {\n  return r.outcome === \"success\";\n}\n</code></pre>"},{"location":"architecture/overview/#configuration-hierarchy","title":"Configuration Hierarchy","text":"<p>Configuration loads from multiple sources:</p> <ol> <li>CLI arguments (highest priority)</li> <li>Environment variables</li> <li>Local config file</li> <li>Home directory config</li> <li>Built-in defaults (lowest priority)</li> </ol>"},{"location":"architecture/overview/#module-organization","title":"Module Organization","text":""},{"location":"architecture/overview/#barrel-exports","title":"Barrel Exports","text":"<p>Each module has a <code>mod.ts</code> that exports public interface:</p> <pre><code>// src/llm/mod.ts\nexport type { LLMAdapter, LLMConfig, LLMResponse } from \"./types.ts\";\nexport { LLMAdapterRegistry } from \"./registry.ts\";\nexport { AnthropicAdapter } from \"./anthropic-adapter.ts\";\n</code></pre>"},{"location":"architecture/overview/#import-order","title":"Import Order","text":"<pre><code>// 1. Standard library\nimport { assertEquals } from \"@std/assert\";\n\n// 2. Type imports from project\nimport type { LLMConfig } from \"../llm/types.ts\";\n\n// 3. Implementation imports\nimport { LLMAdapterRegistry } from \"../llm/registry.ts\";\n\n// 4. Relative imports\nimport { helper } from \"./utils.ts\";\n</code></pre>"},{"location":"architecture/overview/#error-handling","title":"Error Handling","text":"<p>Errors form a hierarchy with structured context:</p> <pre><code>class CentralGaugeError extends Error {\n  constructor(\n    message: string,\n    public readonly code: string,\n    public readonly context?: Record&lt;string, unknown&gt;,\n  ) {}\n}\n\nclass TaskExecutionError extends CentralGaugeError {}\nclass LLMProviderError extends CentralGaugeError {}\nclass ContainerError extends CentralGaugeError {}\n</code></pre> <p>See Error Handling for details.</p>"},{"location":"architecture/overview/#next-steps","title":"Next Steps","text":"<ul> <li>LLM Adapters - Provider integrations</li> <li>Container Providers - Container management</li> <li>Agent System - Autonomous execution</li> </ul>"},{"location":"cli/bench/","title":"bench Command","text":"<p>The <code>bench</code> command runs benchmark evaluations on LLMs or agents.</p>"},{"location":"cli/bench/#synopsis","title":"Synopsis","text":"<pre><code>centralgauge bench [options]\n</code></pre> <p>Either <code>--llms</code> or <code>--agents</code> must be specified.</p>"},{"location":"cli/bench/#llm-benchmarks","title":"LLM Benchmarks","text":""},{"location":"cli/bench/#basic-usage","title":"Basic Usage","text":"<pre><code>centralgauge bench --llms &lt;models&gt; --tasks &lt;patterns&gt;\n</code></pre>"},{"location":"cli/bench/#model-specification","title":"Model Specification","text":""},{"location":"cli/bench/#aliases","title":"Aliases","text":"<pre><code>centralgauge bench --llms sonnet,opus,gpt-4o\n</code></pre> Alias Resolves To opus claude-4.5-opus sonnet claude-sonnet-4 gpt-5 gpt-5.2 gpt-4o gpt-4o o3 o3 gemini gemini-3-pro-preview"},{"location":"cli/bench/#groups","title":"Groups","text":"<pre><code>centralgauge bench --llms flagship\n</code></pre> Group Models flagship opus, gpt-5, gemini-3-pro coding sonnet, gpt-4o budget gpt-4o-mini, gemini-flash"},{"location":"cli/bench/#providermodel-format","title":"Provider/Model Format","text":"<pre><code>centralgauge bench --llms anthropic/claude-sonnet-4-20250514,openai/gpt-4o\n</code></pre>"},{"location":"cli/bench/#variants","title":"Variants","text":"<pre><code>centralgauge bench --llms \"opus@temp=0.5\"\ncentralgauge bench --llms \"opus@temp=0.1;tokens=8000\"\ncentralgauge bench --llms \"opus@profile=conservative\"\n</code></pre>"},{"location":"cli/bench/#task-patterns","title":"Task Patterns","text":"<pre><code># All tasks\ncentralgauge bench --llms sonnet --tasks \"tasks/**/*.yml\"\n\n# By difficulty\ncentralgauge bench --llms sonnet --tasks \"tasks/easy/*.yml\"\n\n# Specific task\ncentralgauge bench --llms sonnet --tasks \"tasks/easy/CG-AL-E001-basic-table.yml\"\n\n# Multiple patterns\ncentralgauge bench --llms sonnet --tasks \"tasks/easy/*.yml\" \"tasks/medium/*.yml\"\n</code></pre>"},{"location":"cli/bench/#agent-benchmarks","title":"Agent Benchmarks","text":""},{"location":"cli/bench/#basic-usage_1","title":"Basic Usage","text":"<pre><code>centralgauge bench --agents &lt;agent-ids&gt; --tasks &lt;patterns&gt; --container &lt;name&gt;\n</code></pre>"},{"location":"cli/bench/#agent-specification","title":"Agent Specification","text":"<pre><code># Single agent\ncentralgauge bench --agents default --tasks \"tasks/easy/*.yml\" --container Cronus27\n\n# Multiple agents\ncentralgauge bench --agents default,minimal --tasks \"tasks/**/*.yml\" --container Cronus27\n</code></pre>"},{"location":"cli/bench/#sandbox-mode","title":"Sandbox Mode","text":"<p>Run agents in isolated containers:</p> <pre><code>centralgauge bench --agents default --sandbox --container Cronus27\n</code></pre>"},{"location":"cli/bench/#options","title":"Options","text":""},{"location":"cli/bench/#model-options","title":"Model Options","text":"Option Type Default Description <code>-l, --llms</code> string[] - Models to benchmark <code>--temperature</code> number 0.1 Generation temperature <code>--max-tokens</code> number 4000 Max response tokens"},{"location":"cli/bench/#agent-options","title":"Agent Options","text":"Option Type Default Description <code>--agents</code> string[] - Agent configurations <code>--container</code> string Cronus27 BC container name <code>-s, --sandbox</code> boolean false Run in sandbox"},{"location":"cli/bench/#task-options","title":"Task Options","text":"Option Type Default Description <code>-t, --tasks</code> string[] tasks/*/.yml Task patterns <code>-a, --attempts</code> number 2 Attempts per task"},{"location":"cli/bench/#execution-options","title":"Execution Options","text":"Option Type Default Description <code>--sequential</code> boolean false Disable parallelism <code>--max-concurrency</code> number 10 Max concurrent calls <code>--no-continuation</code> boolean false Disable continuation <code>--stream</code> boolean false Enable streaming <code>--retry</code> string - Retry from results file"},{"location":"cli/bench/#output-options","title":"Output Options","text":"Option Type Default Description <code>-o, --output</code> string results/ Output directory <code>-f, --format</code> string verbose Output format <code>--json-events</code> boolean false JSON line output <code>--tui</code> boolean false Enable TUI <code>-q, --quiet</code> boolean false Minimal output"},{"location":"cli/bench/#debug-options","title":"Debug Options","text":"Option Type Default Description <code>--debug</code> boolean false Enable debug logging <code>--debug-output</code> string debug/ Debug directory <code>--debug-level</code> string basic Log level"},{"location":"cli/bench/#container-options","title":"Container Options","text":"Option Type Default Description <code>--container-provider</code> string auto Provider to use"},{"location":"cli/bench/#prompt-options","title":"Prompt Options","text":"Option Type Default Description <code>--system-prompt</code> string - Override system prompt <code>--prompt-prefix</code> string - Add prefix to prompt <code>--prompt-suffix</code> string - Add suffix to prompt <code>--prompt-stage</code> string both Stage to apply (generation, fix, both) <code>--prompt-provider</code> string - Provider to apply to"},{"location":"cli/bench/#knowledge-bank-options","title":"Knowledge Bank Options","text":"Option Type Default Description <code>--knowledge</code> string[] - Markdown files to inject as knowledge bank <code>--knowledge-dir</code> string - Directory of .md files to inject <code>--run-label</code> string auto Custom label for this run <p>Knowledge files are prepended to the system prompt to provide model-specific guidance. When knowledge is provided without a custom <code>--run-label</code>, the run is automatically labeled with \"(guided)\" suffix for easy comparison in reports.</p>"},{"location":"cli/bench/#output-formats","title":"Output Formats","text":""},{"location":"cli/bench/#verbose-default","title":"verbose (default)","text":"<p>Full details with progress and summary:</p> <pre><code>[Summary] Starting CentralGauge benchmark...\n[Info] Models: anthropic/claude-sonnet-4-20250514\n[Info] Tasks: tasks/easy/*.yml\n\n[Task] CG-AL-E001: Starting with 1 models\n[LLM] anthropic/claude-sonnet-4-20250514: attempt 1: success\n[LLM] anthropic/claude-sonnet-4-20250514: pass (score: 1.0, tests: 4/4)\n\n[Summary] Benchmark Summary:\n   Pass rate: 100.0%\n   Average score: 1.0\n</code></pre>"},{"location":"cli/bench/#leaderboard","title":"leaderboard","text":"<p>Ranked table format:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Rank\u2502 Model              \u2502 Pass Rate\u2502 Score \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1   \u2502 claude-sonnet-4    \u2502 90.0%    \u2502 0.92  \u2502\n\u2502 2   \u2502 gpt-4o             \u2502 85.0%    \u2502 0.87  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"cli/bench/#scorecard","title":"scorecard","text":"<p>Compact summary:</p> <pre><code>CentralGauge Benchmark Results\n==============================\nTasks: 10 | Attempts: 2\n\nModel                    PR1    PR2    Score   Cost\nclaude-sonnet-4          70%    90%    0.92    $0.12\ngpt-4o                   65%    85%    0.87    $0.15\n</code></pre>"},{"location":"cli/bench/#json","title":"json","text":"<p>Machine-readable JSON:</p> <pre><code>{\n  \"results\": [...],\n  \"stats\": {...},\n  \"comparisons\": [...]\n}\n</code></pre>"},{"location":"cli/bench/#tui-mode","title":"TUI Mode","text":"<p>The TUI provides real-time visualization:</p> <pre><code>centralgauge bench --llms sonnet --tasks \"tasks/**/*.yml\" --tui\n</code></pre> <p>Features:</p> <ul> <li>Progress bar</li> <li>Active LLM calls</li> <li>Compile queue status</li> <li>Per-model pass rates</li> <li>Error log</li> </ul>"},{"location":"cli/bench/#retry-mode","title":"Retry Mode","text":"<p>Resume failed benchmarks:</p> <pre><code># Initial run\ncentralgauge bench --llms sonnet,gpt-4o --tasks \"tasks/**/*.yml\" -o results/run1\n\n# Retry missing combinations\ncentralgauge bench --llms sonnet,gpt-4o --retry results/run1/benchmark-results-*.json\n</code></pre> <p>Only transient failures (timeouts, rate limits) are retried. Model output failures (compilation, tests) are not.</p>"},{"location":"cli/bench/#interactive-retry","title":"Interactive Retry","text":"<p>During execution, transient failures prompt for retry:</p> <pre><code>[Retry] 3 transient failures (timeout, API errors). Retry now? [y/N]\n</code></pre> <p>Press <code>y</code> to retry, <code>n</code> to continue.</p>"},{"location":"cli/bench/#output-files","title":"Output Files","text":"<p>After completion:</p> <pre><code>results/\n\u251c\u2500\u2500 benchmark-results-1704067200000.json    # Detailed results\n\u2514\u2500\u2500 scores-1704067200000.txt                # Quick summary\n</code></pre>"},{"location":"cli/bench/#examples","title":"Examples","text":""},{"location":"cli/bench/#compare-models","title":"Compare Models","text":"<pre><code>centralgauge bench --llms opus,gpt-5,gemini --tasks \"tasks/**/*.yml\"\n</code></pre>"},{"location":"cli/bench/#temperature-sweep","title":"Temperature Sweep","text":"<pre><code>centralgauge bench --llms \"sonnet@temp=0.1,sonnet@temp=0.3,sonnet@temp=0.5\" --tasks \"tasks/**/*.yml\"\n</code></pre>"},{"location":"cli/bench/#reasoning-comparison","title":"Reasoning Comparison","text":"<pre><code>centralgauge bench --llms \"opus@reasoning=10000,opus@reasoning=50000\" --tasks \"tasks/hard/*.yml\"\n</code></pre>"},{"location":"cli/bench/#quick-test","title":"Quick Test","text":"<pre><code>centralgauge bench --llms mock --tasks \"tasks/easy/CG-AL-E001*.yml\" -q\n</code></pre>"},{"location":"cli/bench/#full-benchmark","title":"Full Benchmark","text":"<pre><code>centralgauge bench \\\n  --llms flagship \\\n  --tasks \"tasks/**/*.yml\" \\\n  --attempts 2 \\\n  --max-concurrency 5 \\\n  --output results/full-benchmark \\\n  --debug \\\n  --debug-level verbose\n</code></pre>"},{"location":"cli/bench/#agent-comparison","title":"Agent Comparison","text":"<pre><code>centralgauge bench \\\n  --agents default,optimized \\\n  --tasks \"tasks/easy/*.yml\" \\\n  --container Cronus27 \\\n  --output results/agent-comparison\n</code></pre>"},{"location":"cli/bench/#knowledge-bank-injection","title":"Knowledge Bank Injection","text":"<p>Inject guidance from markdown files to help models avoid known mistakes:</p> <pre><code># Single knowledge file\ncentralgauge bench --llms gpt-5 --knowledge model-shortcomings/gpt-5.rules.md\n\n# Multiple files\ncentralgauge bench --llms gpt-5 --knowledge rules1.md rules2.md tips.md\n\n# Directory of .md files (loaded alphabetically)\ncentralgauge bench --llms gpt-5 --knowledge-dir .claude/rules/\n\n# Custom run label\ncentralgauge bench --llms gpt-5 --knowledge rules.md --run-label \"gpt-5-custom\"\n</code></pre>"},{"location":"cli/bench/#guided-vs-unguided-comparison","title":"Guided vs Unguided Comparison","text":"<p>Compare model performance with and without guidance:</p> <pre><code># Baseline run (no guidance)\ncentralgauge bench --llms gpt-5 --tasks \"tasks/**/*.yml\" -o results/baseline\n\n# Guided run (auto-labeled as \"gpt-5 (guided)\")\ncentralgauge bench --llms gpt-5 --knowledge model-shortcomings/gpt-5.rules.md \\\n  --tasks \"tasks/**/*.yml\" -o results/guided\n</code></pre> <p>The guided run automatically gets a \"(guided)\" suffix in reports, making it easy to compare results.</p>"},{"location":"cli/bench/#rules-knowledge-workflow","title":"Rules + Knowledge Workflow","text":"<p>Generate model-specific rules from shortcomings, then use them to guide benchmarks:</p> <pre><code># 1. Generate rules from benchmark shortcomings\ncentralgauge rules model-shortcomings/gpt-5.json\n\n# 2. Run guided benchmark with generated rules\ncentralgauge bench --llms gpt-5 --knowledge model-shortcomings/gpt-5.rules.md\n\n# 3. Compare results to measure improvement\n</code></pre>"},{"location":"cli/bench/#exit-codes","title":"Exit Codes","text":"Code Description 0 Success 1 Error (with results) 2 Invalid arguments"},{"location":"cli/bench/#see-also","title":"See Also","text":"<ul> <li>Running Benchmarks</li> <li>Model Variants</li> <li>Understanding Results</li> <li>rules Command - Generate knowledge files from model shortcomings</li> </ul>"},{"location":"cli/commands/","title":"CLI Command Reference","text":"<p>CentralGauge provides a comprehensive CLI for benchmarking, reporting, and analysis.</p>"},{"location":"cli/commands/#global-options","title":"Global Options","text":"<p>These options are available for all commands:</p> Option Description <code>-v, --verbose</code> Enable verbose output <code>-q, --quiet</code> Disable splash screen and minimize output <code>--help</code> Show help for command <code>--version</code> Show version"},{"location":"cli/commands/#commands-overview","title":"Commands Overview","text":"Command Description <code>bench</code> Run benchmark evaluation <code>report</code> Generate reports from results <code>report-from-db</code> Generate reports from stats database <code>verify</code> Analyze and fix failing benchmarks <code>rules</code> Generate rules from model shortcomings <code>models</code> List and test model resolution <code>config</code> Configuration management <code>stats-*</code> Historical statistics commands <code>container</code> Container management <code>compile</code> Compile AL code <code>test</code> Run AL tests"},{"location":"cli/commands/#bench","title":"bench","text":"<p>Run benchmark evaluation on LLMs or agents.</p>"},{"location":"cli/commands/#usage","title":"Usage","text":"<pre><code>centralgauge bench [options]\n</code></pre>"},{"location":"cli/commands/#options","title":"Options","text":"Option Type Default Description <code>--preset</code> string - Load benchmark preset from config <code>--list-presets</code> boolean false List available benchmark presets <code>-l, --llms</code> string[] - LLM models to test <code>--agents</code> string[] - Agent configurations to use <code>--container</code> string Cronus27 BC container name <code>-s, --sandbox</code> boolean false Run agents in isolated containers <code>-t, --tasks</code> string[] tasks/*/.yml Task file patterns <code>-a, --attempts</code> number 2 Number of attempts per task <code>-o, --output</code> string results/ Output directory <code>--temperature</code> number 0.1 LLM temperature <code>--max-tokens</code> number 4000 Maximum tokens per request <code>--debug</code> boolean false Enable debug logging <code>--debug-output</code> string debug/ Debug output directory <code>--debug-level</code> string basic Debug log level <code>--container-provider</code> string auto Container provider <code>--sequential</code> boolean false Disable parallel execution <code>--max-concurrency</code> number 10 Max concurrent LLM calls <code>-f, --format</code> string verbose Output format <code>--system-prompt</code> string - Override system prompt <code>--prompt-prefix</code> string - Prefix for user prompt <code>--prompt-suffix</code> string - Suffix for user prompt <code>--prompt-stage</code> string both Apply overrides to stage <code>--prompt-provider</code> string - Apply overrides to provider <code>--knowledge</code> string[] - Markdown files to inject as knowledge bank <code>--knowledge-dir</code> string - Directory of .md files to inject <code>--run-label</code> string auto Custom label for this run <code>--no-continuation</code> boolean false Disable continuation <code>--stream</code> boolean false Enable streaming mode <code>--json-events</code> boolean false Output JSON lines <code>--tui</code> boolean false Enable TUI mode <code>--retry</code> string - Retry from previous results"},{"location":"cli/commands/#examples","title":"Examples","text":"<pre><code># Basic LLM benchmark\ncentralgauge bench --llms sonnet,gpt-4o --tasks \"tasks/easy/*.yml\"\n\n# Model variants\ncentralgauge bench --llms \"opus@temp=0.1,opus@temp=0.5\"\n\n# Agent benchmark\ncentralgauge bench --agents default --tasks \"tasks/**/*.yml\" --container Cronus27\n\n# With sandbox\ncentralgauge bench --agents default --sandbox --container Cronus27\n\n# Retry failed tasks\ncentralgauge bench --llms sonnet --retry results/benchmark-results-*.json\n\n# TUI mode\ncentralgauge bench --llms sonnet --tasks \"tasks/**/*.yml\" --tui\n\n# Knowledge bank injection\ncentralgauge bench --llms gpt-5 --knowledge model-shortcomings/gpt-5.rules.md\n\n# Guided vs unguided comparison\ncentralgauge bench --llms gpt-5 --knowledge rules.md --run-label \"gpt-5 (guided)\"\n\n# List available presets\ncentralgauge bench --list-presets\n\n# Run with a preset\ncentralgauge bench --preset flagship-compare\n\n# Override preset values with CLI args\ncentralgauge bench --preset quick-test --attempts 2\n</code></pre>"},{"location":"cli/commands/#report","title":"report","text":"<p>Generate reports from benchmark results.</p>"},{"location":"cli/commands/#usage_1","title":"Usage","text":"<pre><code>centralgauge report &lt;results-dir&gt; [options]\n</code></pre>"},{"location":"cli/commands/#arguments","title":"Arguments","text":"Argument Description <code>results-dir</code> Directory containing benchmark results"},{"location":"cli/commands/#options_1","title":"Options","text":"Option Type Default Description <code>--html</code> boolean false Generate HTML report <code>-o, --output</code> string <code>reports-output/</code> Output directory <code>--save-as</code> string - Save file selection as a named dataset <code>--add-to</code> string - Add files to an existing dataset <code>--dataset</code> string - Generate report from a saved dataset <code>--list-datasets</code> boolean false List all saved datasets"},{"location":"cli/commands/#examples_1","title":"Examples","text":"<pre><code># Generate HTML report (interactive file selection)\ncentralgauge report results/ --html\n\n# Save selection as a dataset\ncentralgauge report results/ --html --save-as january-comparison\n\n# List all saved datasets\ncentralgauge report results/ --list-datasets\n\n# Generate from saved dataset\ncentralgauge report results/ --dataset january-comparison --html\n\n# Add new files to existing dataset\ncentralgauge report results/ --add-to january-comparison --html\n</code></pre>"},{"location":"cli/commands/#report-from-db","title":"report-from-db","text":"<p>Generate reports from the stats database.</p>"},{"location":"cli/commands/#usage_2","title":"Usage","text":"<pre><code>centralgauge report-from-db [options]\n</code></pre>"},{"location":"cli/commands/#options_2","title":"Options","text":"Option Type Default Description <code>--db</code> string results/centralgauge.db Database path <code>--html</code> boolean false Generate HTML report <code>--output</code> string - Output directory <code>--task-set</code> string - Filter by task set hash <code>--current-tasks</code> boolean false Filter by current task files <code>--tasks</code> string[] - Task patterns for current-tasks <code>--interactive</code> boolean false Interactive run selection <code>--list-sets</code> boolean false List available task sets"},{"location":"cli/commands/#examples_2","title":"Examples","text":"<pre><code># Interactive run selection\ncentralgauge report-from-db --interactive --html\n\n# Filter by current tasks\ncentralgauge report-from-db --current-tasks --tasks \"tasks/easy/*.yml\"\n\n# List available task sets\ncentralgauge report-from-db --list-sets\n</code></pre>"},{"location":"cli/commands/#verify","title":"verify","text":"<p>Analyze and fix failing benchmark tasks.</p>"},{"location":"cli/commands/#usage_3","title":"Usage","text":"<pre><code>centralgauge verify &lt;debug-dir&gt; [options]\n</code></pre>"},{"location":"cli/commands/#arguments_1","title":"Arguments","text":"Argument Description <code>debug-dir</code> Directory containing debug logs"},{"location":"cli/commands/#options_3","title":"Options","text":"Option Type Default Description <code>--session</code> string - Specific session ID <code>--filter</code> string - Filter by failure type (compile, test) <code>--dry-run</code> boolean false Show fixes without applying <code>--task</code> string - Analyze specific task"},{"location":"cli/commands/#examples_3","title":"Examples","text":"<pre><code># Analyze failures\ncentralgauge verify debug/\n\n# Specific session\ncentralgauge verify debug/ --session 1734567890123\n\n# Dry run\ncentralgauge verify debug/ --dry-run\n\n# Filter compilation failures\ncentralgauge verify debug/ --filter compile\n</code></pre>"},{"location":"cli/commands/#rules","title":"rules","text":"<p>Generate markdown rules from model shortcomings JSON files.</p>"},{"location":"cli/commands/#usage_4","title":"Usage","text":"<pre><code>centralgauge rules &lt;input&gt; [options]\n</code></pre>"},{"location":"cli/commands/#arguments_2","title":"Arguments","text":"Argument Description <code>input</code> Path to model shortcomings JSON file"},{"location":"cli/commands/#options_4","title":"Options","text":"Option Type Default Description <code>-o, --output</code> string {input}.rules.md Output file path <code>--min-occurrences</code> number 1 Only include shortcomings with N+ occurrences"},{"location":"cli/commands/#examples_4","title":"Examples","text":"<pre><code># Basic usage\ncentralgauge rules model-shortcomings/gpt-5.2-2025-12-11.json\n\n# Custom output path\ncentralgauge rules model-shortcomings/gpt-5.2.json -o .claude/rules/gpt-5.2.md\n\n# Only frequent issues (3+ occurrences)\ncentralgauge rules model-shortcomings/claude-opus.json --min-occurrences 3\n</code></pre>"},{"location":"cli/commands/#models","title":"models","text":"<p>List and test model resolution.</p>"},{"location":"cli/commands/#usage_5","title":"Usage","text":"<pre><code>centralgauge models [spec]\n</code></pre>"},{"location":"cli/commands/#arguments_3","title":"Arguments","text":"Argument Description <code>spec</code> Model specification to resolve (optional)"},{"location":"cli/commands/#examples_5","title":"Examples","text":"<pre><code># List all models\ncentralgauge models\n\n# Test alias resolution\ncentralgauge models sonnet\n\n# Test group resolution\ncentralgauge models flagship\n\n# Test variant\ncentralgauge models \"opus@temp=0.5\"\n</code></pre>"},{"location":"cli/commands/#config","title":"config","text":"<p>Configuration management commands.</p>"},{"location":"cli/commands/#subcommands","title":"Subcommands","text":""},{"location":"cli/commands/#config-init","title":"config init","text":"<p>Create a sample configuration file.</p> <pre><code>centralgauge config init\n</code></pre>"},{"location":"cli/commands/#config-show","title":"config show","text":"<p>Display effective configuration.</p> <pre><code>centralgauge config show\n</code></pre>"},{"location":"cli/commands/#config-validate","title":"config validate","text":"<p>Validate configuration file.</p> <pre><code>centralgauge config validate\n</code></pre>"},{"location":"cli/commands/#stats-commands","title":"Stats Commands","text":""},{"location":"cli/commands/#stats-import","title":"stats-import","text":"<p>Import JSON results into the database.</p> <pre><code>centralgauge stats-import &lt;results-dir&gt; [options]\n</code></pre> Option Type Default Description <code>--db</code> string results/centralgauge.db Database path"},{"location":"cli/commands/#stats-runs","title":"stats-runs","text":"<p>View benchmark run history.</p> <pre><code>centralgauge stats-runs [options]\n</code></pre> Option Type Default Description <code>--db</code> string results/centralgauge.db Database path <code>--task-set</code> string - Filter by task set hash <code>--model</code> string - Filter by model <code>--limit</code> number 20 Maximum runs to show"},{"location":"cli/commands/#stats-compare","title":"stats-compare","text":"<p>Compare two models head-to-head.</p> <pre><code>centralgauge stats-compare &lt;model1&gt; &lt;model2&gt; [options]\n</code></pre> Option Type Default Description <code>--db</code> string results/centralgauge.db Database path <code>--task-set</code> string - Filter by task set hash"},{"location":"cli/commands/#stats-regression","title":"stats-regression","text":"<p>Detect performance regressions.</p> <pre><code>centralgauge stats-regression [options]\n</code></pre> Option Type Default Description <code>--db</code> string results/centralgauge.db Database path <code>--threshold</code> number 10 Regression threshold (%)"},{"location":"cli/commands/#stats-cost","title":"stats-cost","text":"<p>View cost breakdown.</p> <pre><code>centralgauge stats-cost [options]\n</code></pre> Option Type Default Description <code>--db</code> string results/centralgauge.db Database path <code>--group</code> string model Group by (model, task)"},{"location":"cli/commands/#container-commands","title":"Container Commands","text":""},{"location":"cli/commands/#container-status","title":"container status","text":"<p>Check container status.</p> <pre><code>centralgauge container status &lt;name&gt;\n</code></pre>"},{"location":"cli/commands/#container-start","title":"container start","text":"<p>Start a container.</p> <pre><code>centralgauge container start &lt;name&gt;\n</code></pre>"},{"location":"cli/commands/#container-stop","title":"container stop","text":"<p>Stop a container.</p> <pre><code>centralgauge container stop &lt;name&gt;\n</code></pre>"},{"location":"cli/commands/#compiletest-commands","title":"Compile/Test Commands","text":""},{"location":"cli/commands/#compile","title":"compile","text":"<p>Compile AL code in a container.</p> <pre><code>centralgauge compile &lt;project-path&gt; --container &lt;name&gt;\n</code></pre>"},{"location":"cli/commands/#test","title":"test","text":"<p>Run AL tests in a container.</p> <pre><code>centralgauge test &lt;project-path&gt; --container &lt;name&gt; [--codeunit &lt;id&gt;]\n</code></pre>"},{"location":"cli/commands/#exit-codes","title":"Exit Codes","text":"Code Description 0 Success 1 General error 2 Invalid arguments 3 Configuration error 4 Container error 5 LLM provider error"},{"location":"cli/commands/#environment-variables","title":"Environment Variables","text":"<p>See Configuration for environment variable reference.</p>"},{"location":"cli/commands/#next-steps","title":"Next Steps","text":"<ul> <li>bench Command - Detailed bench reference</li> <li>rules Command - Rules generation reference</li> <li>Running Benchmarks - Usage guide</li> <li>Configuration - Config reference</li> </ul>"},{"location":"cli/config/","title":"config Command","text":"<p>The <code>config</code> command manages CentralGauge configuration.</p>"},{"location":"cli/config/#synopsis","title":"Synopsis","text":"<pre><code>centralgauge config &lt;subcommand&gt;\n</code></pre>"},{"location":"cli/config/#subcommands","title":"Subcommands","text":""},{"location":"cli/config/#config-init","title":"config init","text":"<p>Creates a sample configuration file in the current directory.</p> <pre><code>centralgauge config init\n</code></pre> <p>This creates <code>.centralgauge.yml</code> with documented defaults and examples.</p> <p>Output:</p> <pre><code>Created .centralgauge.yml with sample configuration.\nEdit this file to customize CentralGauge settings.\n</code></pre>"},{"location":"cli/config/#config-show","title":"config show","text":"<p>Displays the effective configuration after merging all sources.</p> <pre><code>centralgauge config show\n</code></pre> <p>Shows merged configuration from:</p> <ol> <li>CLI arguments</li> <li>Environment variables</li> <li>Local config file</li> <li>Home directory config</li> <li>Built-in defaults</li> </ol> <p>Example output:</p> <pre><code># Effective Configuration\n\ndefaultModels:\n  benchmark:\n    - sonnet\n    - gpt-4o\n  development:\n    - mock\n\nllm:\n  temperature: 0.1\n  maxTokens: 4000\n  timeout: 30000\n\ncontainer:\n  provider: bccontainer\n  name: Cronus27\n  bcVersion: \"27.0\"\n\n# Sources:\n# - .centralgauge.yml (local)\n# - Environment variables\n# - Built-in defaults\n</code></pre>"},{"location":"cli/config/#config-validate","title":"config validate","text":"<p>Validates the configuration file.</p> <pre><code>centralgauge config validate\n</code></pre> <p>Checks:</p> <ul> <li>YAML syntax</li> <li>Required fields</li> <li>Valid values</li> <li>File paths exist</li> </ul> <p>Example output:</p> <pre><code>Validating .centralgauge.yml...\n\n[OK] YAML syntax valid\n[OK] All required fields present\n[WARN] Container 'TestContainer' not found (may need to create)\n[OK] Template directory exists\n\nConfiguration is valid with 1 warning(s).\n</code></pre>"},{"location":"cli/config/#configuration-file","title":"Configuration File","text":""},{"location":"cli/config/#default-location","title":"Default Location","text":"<p>CentralGauge looks for configuration in:</p> <ol> <li><code>.centralgauge.yml</code> (current directory)</li> <li><code>~/.centralgauge.yml</code> (home directory)</li> </ol>"},{"location":"cli/config/#sample-configuration","title":"Sample Configuration","text":"<pre><code># Default models for different scenarios\ndefaultModels:\n  benchmark: [sonnet, gpt-4o]\n  development: [mock]\n  comparison: [flagship]\n\n# LLM provider settings\nllm:\n  temperature: 0.1\n  maxTokens: 4000\n  timeout: 30000\n\n# Benchmark settings\nbenchmark:\n  attempts: 2\n  outputDir: results\n  templateDir: templates\n\n# Container settings\ncontainer:\n  provider: bccontainer\n  name: Cronus27\n  bcVersion: \"27.0\"\n  credentials:\n    username: admin\n    password: admin\n\n# System prompts for variants\nsystemPrompts:\n  strict-al:\n    content: |\n      You are a strict AL code generator.\n      Only output valid AL code.\n\n# Variant profiles\nvariantProfiles:\n  conservative:\n    config:\n      temperature: 0.1\n      maxTokens: 4000\n</code></pre>"},{"location":"cli/config/#environment-variables","title":"Environment Variables","text":"<p>Configuration can be overridden via environment variables:</p> <pre><code>CENTRALGAUGE_TEMPERATURE=0.2\nCENTRALGAUGE_MAX_TOKENS=8000\nCENTRALGAUGE_CONTAINER_NAME=MyContainer\nCENTRALGAUGE_DEBUG=true\n</code></pre>"},{"location":"cli/config/#priority-order","title":"Priority Order","text":"<p>Configuration sources (highest priority first):</p> <ol> <li>CLI arguments - <code>--temperature 0.3</code></li> <li>Environment variables - <code>CENTRALGAUGE_TEMPERATURE=0.3</code></li> <li>Local config - <code>.centralgauge.yml</code></li> <li>Home config - <code>~/.centralgauge.yml</code></li> <li>Defaults - Built-in values</li> </ol>"},{"location":"cli/config/#see-also","title":"See Also","text":"<ul> <li>Configuration Guide - Full configuration reference</li> <li>Model Variants - Variant configuration</li> <li>Running Benchmarks - Using configuration</li> </ul>"},{"location":"cli/report/","title":"report Command","text":"<p>The <code>report</code> command generates reports from benchmark results.</p>"},{"location":"cli/report/#synopsis","title":"Synopsis","text":"<pre><code>centralgauge report &lt;input&gt; [options]\n</code></pre>"},{"location":"cli/report/#arguments","title":"Arguments","text":"Argument Description <code>input</code> Input directory or file containing benchmark results"},{"location":"cli/report/#options","title":"Options","text":"Option Type Default Description <code>--html</code> boolean false Generate HTML report <code>-o, --output</code> string <code>reports-output/</code> Output directory for generated files <code>--save-as</code> string - Save file selection as a named dataset <code>--add-to</code> string - Add files to an existing dataset <code>--dataset</code> string - Generate report from a saved dataset <code>--list-datasets</code> boolean false List all saved datasets"},{"location":"cli/report/#examples","title":"Examples","text":""},{"location":"cli/report/#generate-html-report","title":"Generate HTML Report","text":"<pre><code>centralgauge report results/ --html --output reports/\n</code></pre> <p>This generates an interactive HTML report with:</p> <ul> <li>Model comparison charts</li> <li>Task-by-task breakdown</li> <li>Pass rate visualizations</li> <li>Cost analysis</li> <li>Score distributions</li> </ul>"},{"location":"cli/report/#generate-json-summary","title":"Generate JSON Summary","text":"<pre><code>centralgauge report results/ --format json\n</code></pre> <p>Outputs a consolidated JSON file with aggregated statistics.</p>"},{"location":"cli/report/#generate-csv-export","title":"Generate CSV Export","text":"<pre><code>centralgauge report results/ --format csv --output exports/\n</code></pre> <p>Exports results in CSV format for spreadsheet analysis.</p>"},{"location":"cli/report/#report-contents","title":"Report Contents","text":""},{"location":"cli/report/#html-report-sections","title":"HTML Report Sections","text":"<ol> <li>Overview - Summary statistics and key metrics</li> <li>Model Comparison - Head-to-head model performance</li> <li>Task Results - Per-task pass/fail breakdown</li> <li>Cost Analysis - Token usage and estimated costs</li> <li>Performance Trends - Score distributions and timing</li> </ol>"},{"location":"cli/report/#json-output-structure","title":"JSON Output Structure","text":"<pre><code>{\n  \"summary\": {\n    \"totalTasks\": 50,\n    \"totalModels\": 3,\n    \"overallPassRate\": 0.85,\n    \"totalCost\": 2.34\n  },\n  \"models\": {\n    \"anthropic/claude-sonnet-4\": {\n      \"passRate\": 0.90,\n      \"avgScore\": 0.92,\n      \"cost\": 0.78\n    }\n  },\n  \"tasks\": {\n    \"CG-AL-E001\": {\n      \"passingModels\": [\"anthropic/claude-sonnet-4\", \"openai/gpt-4o\"]\n    }\n  }\n}\n</code></pre>"},{"location":"cli/report/#input-sources","title":"Input Sources","text":"<p>The command accepts:</p> <ol> <li>Directory - Scans for <code>benchmark-results-*.json</code> files</li> <li>Single file - Processes a specific results file</li> <li>Glob pattern - Matches multiple files</li> </ol> <pre><code># Directory\ncentralgauge report results/\n\n# Single file\ncentralgauge report results/benchmark-results-1704067200000.json\n\n# Glob pattern\ncentralgauge report \"results/benchmark-results-*.json\"\n</code></pre>"},{"location":"cli/report/#multiple-runs","title":"Multiple Runs","text":"<p>When multiple result files are found, the report:</p> <ul> <li>Shows latest results prominently</li> <li>Provides comparison across runs</li> <li>Tracks historical performance</li> </ul>"},{"location":"cli/report/#datasets","title":"Datasets","text":"<p>Datasets allow you to save and reuse file selections for report generation. This is useful when you have a specific set of result files you want to compare repeatedly.</p>"},{"location":"cli/report/#creating-a-dataset","title":"Creating a Dataset","text":"<p>Save your file selection when generating a report:</p> <pre><code>centralgauge report results/ --html --save-as january-comparison\n</code></pre> <p>This creates <code>results/datasets/january-comparison.yml</code> containing the selected files.</p>"},{"location":"cli/report/#listing-datasets","title":"Listing Datasets","text":"<p>View all saved datasets:</p> <pre><code>centralgauge report results/ --list-datasets\n</code></pre> <p>Output:</p> <pre><code>Datasets in results/datasets/:\n  january-comparison    3 files   Updated: Jan 20, 2025\n  february-run          5 files   Updated: Feb 1, 2025\n</code></pre>"},{"location":"cli/report/#using-a-dataset","title":"Using a Dataset","text":"<p>Generate a report from a saved dataset:</p> <pre><code>centralgauge report results/ --dataset january-comparison --html\n</code></pre> <p>The command shows a summary of files in the dataset and asks for confirmation before generating the report. Missing files are automatically skipped with a warning.</p>"},{"location":"cli/report/#adding-files-to-a-dataset","title":"Adding Files to a Dataset","text":"<p>Add new result files to an existing dataset:</p> <pre><code>centralgauge report results/ --add-to january-comparison --html\n</code></pre> <p>This shows only files not already in the dataset, lets you select which to add, updates the dataset, and generates a report with all files.</p>"},{"location":"cli/report/#dataset-storage","title":"Dataset Storage","text":"<p>Datasets are stored in <code>&lt;results-dir&gt;/datasets/</code> as YAML files:</p> <pre><code>name: \"january-comparison\"\ndescription: \"January 2025 model comparison\"\ncreated: \"2025-01-15T10:30:00Z\"\nupdated: \"2025-01-20T14:15:00Z\"\nfiles:\n  - \"llm-benchmark-2025-01-15-sonnet.json\"\n  - \"agent-benchmark-2025-01-16.json\"\n</code></pre> <p>File paths are stored relative to the results directory for portability.</p>"},{"location":"cli/report/#see-also","title":"See Also","text":"<ul> <li>report-from-db - Generate reports from database</li> <li>Understanding Results - Result interpretation</li> <li>Running Benchmarks - Generating results</li> </ul>"},{"location":"cli/rules/","title":"rules Command","text":"<p>The <code>rules</code> command converts model shortcomings JSON files into markdown rules files that can help guide LLM code generation. This is useful for creating model-specific guidance that helps LLMs avoid known mistakes when generating AL code.</p>"},{"location":"cli/rules/#synopsis","title":"Synopsis","text":"<pre><code>centralgauge rules &lt;input&gt; [options]\n</code></pre>"},{"location":"cli/rules/#purpose","title":"Purpose","text":"<p>During benchmark evaluation, CentralGauge tracks common mistakes that each model makes. These are stored in JSON files in the <code>model-shortcomings/</code> directory. The <code>rules</code> command transforms this data into human-readable markdown rules that can be:</p> <ul> <li>Added to <code>.claude/rules/</code> for Claude Code guidance</li> <li>Included in system prompts for other LLM tools</li> <li>Used as reference documentation for AL code patterns</li> <li>Shared across teams to improve code generation quality</li> </ul>"},{"location":"cli/rules/#arguments","title":"Arguments","text":"Argument Description <code>input</code> Path to a model shortcomings JSON file"},{"location":"cli/rules/#options","title":"Options","text":"Option Type Default Description <code>-o, --output</code> string {input}.rules.md Override the output file path <code>--min-occurrences</code> number 1 Only include shortcomings with at least N occurrences"},{"location":"cli/rules/#input-format","title":"Input Format","text":"<p>The input JSON file must follow the <code>ModelShortcomingsFile</code> format:</p> <pre><code>{\n  \"model\": \"gpt-5.2-2025-12-11\",\n  \"lastUpdated\": \"2025-12-29T10:07:51.020Z\",\n  \"shortcomings\": [\n    {\n      \"concept\": \"json-typed-getter-methods\",\n      \"alConcept\": \"json-handling\",\n      \"description\": \"The model failed to use correct JSON getter patterns...\",\n      \"correctPattern\": \"procedure ParseData(Json: JsonObject)...\",\n      \"incorrectPattern\": \"// Incorrect usage of GetText() directly...\",\n      \"errorCodes\": [\"AL0133\", \"AL0132\"],\n      \"affectedTasks\": [\"CG-AL-H014\", \"CG-AL-M020\"],\n      \"firstSeen\": \"2025-12-28T23:45:01.770Z\",\n      \"occurrences\": 4\n    }\n  ]\n}\n</code></pre>"},{"location":"cli/rules/#input-fields","title":"Input Fields","text":"Field Type Description <code>model</code> string Model identifier <code>lastUpdated</code> string ISO 8601 timestamp <code>shortcomings[].concept</code> string Short slug describing the issue <code>shortcomings[].alConcept</code> string AL category for grouping (e.g., \"json-handling\", \"table-definition\") <code>shortcomings[].description</code> string Detailed explanation of the issue <code>shortcomings[].correctPattern</code> string Example of correct AL code <code>shortcomings[].incorrectPattern</code> string Example of incorrect pattern the model used <code>shortcomings[].errorCodes</code> string[] AL compiler error codes <code>shortcomings[].affectedTasks</code> string[] Task IDs where this issue occurred <code>shortcomings[].occurrences</code> number How many times this issue was seen"},{"location":"cli/rules/#output-format","title":"Output Format","text":"<p>The generated markdown file includes:</p> <ol> <li>Header - Model name and generation date</li> <li>Table of Contents - Links to each category</li> <li>Rules by Category - Grouped by <code>alConcept</code></li> <li>Individual Rules - Title, error codes, description, incorrect/correct patterns</li> </ol>"},{"location":"cli/rules/#example-output","title":"Example Output","text":"<pre><code># AL Code Generation Rules for gpt-5.2-2025-12-11\n\n&gt; Auto-generated from benchmark shortcomings on 12/29/2025.\n&gt; 8 rules covering 5 categories.\n\n## Categories\n\n- [Json Handling](#json-handling) (2 rules)\n- [Table Definition](#table-definition) (3 rules)\n- [Query Definition](#query-definition) (2 rules)\n- [Codeunit Self Reference](#codeunit-self-reference) (1 rules)\n\n## Json Handling {#json-handling}\n\n### Json Typed Getter Methods\n\n**Error codes**: AL0133, AL0132, AL0134\n\nThe model failed to generate valid JSON getter patterns...\n\n**Incorrect:**\n\n```al\n// Direct GetText() call that doesn't exist\nName := CustomerJson.GetText('name');\n```\n</code></pre> <p>Correct:</p> <pre><code>if CustomerJson.Get('name', JToken) then begin\n    JValue := JToken.AsValue();\n    Name := JValue.AsText();\nend;\n</code></pre> <pre><code>## Examples\n\n### Basic Usage\n\nGenerate rules file next to the input JSON:\n\n```bash\ncentralgauge rules model-shortcomings/gpt-5.2-2025-12-11.json\n</code></pre> <p>Output: <code>model-shortcomings/gpt-5.2-2025-12-11.rules.md</code></p>"},{"location":"cli/rules/#custom-output-path","title":"Custom Output Path","text":"<p>Place rules in Claude Code's rules directory:</p> <pre><code>centralgauge rules model-shortcomings/gpt-5.2.json -o .claude/rules/gpt-5.2.md\n</code></pre>"},{"location":"cli/rules/#filter-by-frequency","title":"Filter by Frequency","text":"<p>Only include issues that occurred 2 or more times (more likely to be systematic):</p> <pre><code>centralgauge rules model-shortcomings/claude-opus.json --min-occurrences 2\n</code></pre>"},{"location":"cli/rules/#generate-rules-for-all-models","title":"Generate Rules for All Models","text":"<pre><code>for f in model-shortcomings/*.json; do\n  centralgauge rules \"$f\" --min-occurrences 2\ndone\n</code></pre>"},{"location":"cli/rules/#workflow-integration","title":"Workflow Integration","text":""},{"location":"cli/rules/#using-with-claude-code","title":"Using with Claude Code","text":"<ol> <li> <p>Generate rules from benchmark shortcomings:    <pre><code>centralgauge rules model-shortcomings/claude-sonnet-4-5.json \\\n  -o .claude/rules/al-patterns.md\n</code></pre></p> </li> <li> <p>Claude Code automatically picks up rules from <code>.claude/rules/</code></p> </li> <li> <p>Rules help the model avoid known AL syntax mistakes</p> </li> </ol>"},{"location":"cli/rules/#using-with-knowledge-bank","title":"Using with Knowledge Bank","text":"<p>Generated rules can be injected directly into benchmarks via the knowledge bank feature:</p> <ol> <li> <p>Generate rules from benchmark shortcomings:    <pre><code>centralgauge rules model-shortcomings/gpt-5.json\n</code></pre></p> </li> <li> <p>Run a guided benchmark with the generated rules:    <pre><code>centralgauge bench --llms gpt-5 --knowledge model-shortcomings/gpt-5.rules.md\n</code></pre></p> </li> <li> <p>Compare guided vs unguided performance in reports</p> </li> </ol> <p>The guided run is automatically labeled with \"(guided)\" suffix for easy comparison.</p>"},{"location":"cli/rules/#continuous-improvement-cycle","title":"Continuous Improvement Cycle","text":"<ol> <li> <p>Run benchmarks to identify model weaknesses:    <pre><code>centralgauge bench --llms sonnet --tasks \"tasks/**/*.yml\"\n</code></pre></p> </li> <li> <p>Analyze failures to update shortcomings:    <pre><code>centralgauge verify debug/ --mode shortcomings-only\n</code></pre></p> </li> <li> <p>Generate updated rules:    <pre><code>centralgauge rules model-shortcomings/claude-sonnet-4.json \\\n  -o .claude/rules/al-sonnet.md\n</code></pre></p> </li> <li> <p>Re-run benchmarks with knowledge injection:    <pre><code>centralgauge bench --llms sonnet --knowledge model-shortcomings/claude-sonnet-4.rules.md\n</code></pre></p> </li> <li> <p>Compare results to measure improvement</p> </li> </ol>"},{"location":"cli/rules/#source-files","title":"Source Files","text":"File Purpose <code>src/rules/generator.ts</code> Core markdown generation logic <code>src/rules/mod.ts</code> Module barrel export <code>cli/commands/rules-command.ts</code> CLI command handler <code>src/verify/types.ts</code> Type definitions for shortcomings"},{"location":"cli/rules/#exit-codes","title":"Exit Codes","text":"Code Description 0 Success 1 Error (invalid input, file not found, etc.)"},{"location":"cli/rules/#see-also","title":"See Also","text":"<ul> <li>bench Command - Run benchmarks with knowledge bank injection</li> <li>verify Command - Analyze failures and update shortcomings</li> <li>Running Benchmarks - Knowledge Bank - Detailed guide</li> <li>Understanding Results - Interpret benchmark output</li> </ul>"},{"location":"contributing/development/","title":"Development Setup","text":"<p>This guide covers setting up a development environment for contributing to CentralGauge.</p>"},{"location":"contributing/development/#prerequisites","title":"Prerequisites","text":"<ul> <li>Deno 1.44+</li> <li>Git</li> <li>Windows 10/11 or Server (for BC containers)</li> <li>Docker Desktop</li> <li>bccontainerhelper PowerShell module</li> </ul>"},{"location":"contributing/development/#clone-and-setup","title":"Clone and Setup","text":"<pre><code># Clone the repository\ngit clone https://github.com/SShadowS/CentralGuage.git\ncd CentralGuage\n\n# Copy environment file\ncp .env.example .env\n\n# Add at least one API key to .env\n# ANTHROPIC_API_KEY=sk-ant-...\n</code></pre>"},{"location":"contributing/development/#development-commands","title":"Development Commands","text":"<pre><code># Run with watch mode\ndeno task dev\n\n# Type checking\ndeno check cli/centralgauge.ts\n\n# Linting\ndeno lint\n\n# Formatting\ndeno fmt\n\n# All checks\ndeno check &amp;&amp; deno lint &amp;&amp; deno fmt\n</code></pre>"},{"location":"contributing/development/#running-tests","title":"Running Tests","text":"<pre><code># Full test suite\ndeno task test\n\n# Unit tests only\ndeno task test:unit\n\n# Integration tests only\ndeno task test:integration\n\n# Watch mode\ndeno task test:watch\n\n# Coverage report\ndeno task coverage\ndeno task coverage:html\n</code></pre> <p>Important: Always use <code>deno task test</code>, not <code>deno test</code> directly. The tasks include required permissions (<code>--allow-all</code>).</p>"},{"location":"contributing/development/#project-structure","title":"Project Structure","text":"<pre><code>CentralGuage/\n\u251c\u2500\u2500 cli/                    # CLI commands and helpers\n\u2502   \u251c\u2500\u2500 commands/           # Command implementations\n\u2502   \u2502   \u251c\u2500\u2500 bench-command.ts\n\u2502   \u2502   \u251c\u2500\u2500 report-command.ts\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 helpers/            # Shared utilities\n\u2502   \u2514\u2500\u2500 tui/                # Terminal UI\n\u251c\u2500\u2500 src/                    # Core library\n\u2502   \u251c\u2500\u2500 llm/                # LLM adapters\n\u2502   \u251c\u2500\u2500 container/          # Container providers\n\u2502   \u251c\u2500\u2500 tasks/              # Task execution\n\u2502   \u251c\u2500\u2500 parallel/           # Orchestration\n\u2502   \u251c\u2500\u2500 agents/             # Agent system\n\u2502   \u251c\u2500\u2500 config/             # Configuration\n\u2502   \u2514\u2500\u2500 utils/              # Utilities\n\u251c\u2500\u2500 tests/                  # Test suite\n\u2502   \u251c\u2500\u2500 unit/               # Unit tests (mirrors src/)\n\u2502   \u251c\u2500\u2500 integration/        # Integration tests\n\u2502   \u2514\u2500\u2500 utils/              # Test helpers\n\u251c\u2500\u2500 tasks/                  # Task definitions\n\u251c\u2500\u2500 templates/              # Prompt templates\n\u251c\u2500\u2500 agents/                 # Agent configurations\n\u2514\u2500\u2500 docs/                   # Documentation\n</code></pre>"},{"location":"contributing/development/#coding-standards","title":"Coding Standards","text":""},{"location":"contributing/development/#import-order","title":"Import Order","text":"<pre><code>// 1. Standard library\nimport { assertEquals } from \"@std/assert\";\n\n// 2. Type imports\nimport type { LLMConfig } from \"../../src/llm/types.ts\";\n\n// 3. Implementation imports\nimport { LLMAdapterRegistry } from \"../../src/llm/registry.ts\";\n\n// 4. Relative imports\nimport { helper } from \"./utils.ts\";\n</code></pre>"},{"location":"contributing/development/#barrel-exports","title":"Barrel Exports","text":"<p>Each module has a <code>mod.ts</code> with explicit exports:</p> <pre><code>// src/llm/mod.ts\nexport type { LLMAdapter, LLMConfig, LLMResponse } from \"./types.ts\";\nexport { LLMAdapterRegistry } from \"./registry.ts\";\n</code></pre>"},{"location":"contributing/development/#console-output","title":"Console Output","text":"<p>Use colored output with tag prefixes instead of emojis:</p> <pre><code>import * as colors from \"@std/fmt/colors\";\n\n// Good\nconsole.log(colors.green(\"[OK]\"), \"Task completed\");\nconsole.log(colors.red(\"[FAIL]\"), \"Task failed\");\n\n// Avoid\nconsole.log(\"\u2705 Task completed\");\nconsole.log(\"\u274c Task failed\");\n</code></pre>"},{"location":"contributing/development/#error-handling","title":"Error Handling","text":"<p>Use the error hierarchy:</p> <pre><code>import { CentralGaugeError, TaskExecutionError } from \"../src/errors.ts\";\n\n// Good - specific error with context\nthrow new TaskExecutionError(\n  `Compilation failed for ${taskId}`,\n  taskId,\n  attemptNumber,\n  { errors: compilationErrors },\n);\n\n// Avoid - generic error\nthrow new Error(\"Compilation failed\");\n</code></pre>"},{"location":"contributing/development/#typescript-strictness","title":"TypeScript Strictness","text":"<p>The project uses strict TypeScript settings:</p> <pre><code>{\n  \"compilerOptions\": {\n    \"strict\": true,\n    \"noImplicitReturns\": true,\n    \"noUnusedLocals\": true,\n    \"noUnusedParameters\": true,\n    \"exactOptionalPropertyTypes\": true\n  }\n}\n</code></pre>"},{"location":"contributing/development/#adding-features","title":"Adding Features","text":""},{"location":"contributing/development/#new-llm-adapter","title":"New LLM Adapter","text":"<ol> <li>Create adapter in <code>src/llm/</code>:</li> </ol> <pre><code>// src/llm/my-adapter.ts\nexport class MyAdapter implements LLMAdapter {\n  readonly name = \"my-adapter\";\n  // ... implementation\n}\n</code></pre> <ol> <li>Register in <code>src/llm/registry.ts</code>:</li> </ol> <pre><code>import { MyAdapter } from \"./my-adapter.ts\";\n\nstatic {\n  this.register(\"my-adapter\", () =&gt; new MyAdapter());\n}\n</code></pre> <ol> <li> <p>Add tests in <code>tests/unit/llm/my-adapter.test.ts</code></p> </li> <li> <p>Export from <code>src/llm/mod.ts</code></p> </li> </ol>"},{"location":"contributing/development/#new-cli-command","title":"New CLI Command","text":"<ol> <li>Create command in <code>cli/commands/</code>:</li> </ol> <pre><code>// cli/commands/my-command.ts\nimport { Command } from \"@cliffy/command\";\n\nexport function registerMyCommand(cli: Command): void {\n  cli.command(\"my-cmd\", \"Description\")\n    .option(\"-f, --flag\", \"Flag description\")\n    .action(async (options) =&gt; {\n      // Implementation\n    });\n}\n</code></pre> <ol> <li>Register in <code>cli/commands/mod.ts</code>:</li> </ol> <pre><code>export { registerMyCommand } from \"./my-command.ts\";\n</code></pre> <ol> <li>Add to <code>cli/centralgauge.ts</code>:</li> </ol> <pre><code>import { registerMyCommand } from \"./commands/mod.ts\";\nregisterMyCommand(cli);\n</code></pre>"},{"location":"contributing/development/#new-task-type","title":"New Task Type","text":"<ol> <li>Create YAML in <code>tasks/{difficulty}/</code>:</li> </ol> <pre><code>id: CG-AL-E999\nprompt_template: code-gen.md\nfix_template: bugfix.md\nmax_attempts: 2\ndescription: &gt;-\n  Your task description\nexpected:\n  compile: true\n  testApp: tests/al/easy/CG-AL-E999.Test.al\n  testCodeunitId: 80099\nmetrics:\n  - compile_pass\n  - tests_pass\n</code></pre> <ol> <li>Create test file in <code>tests/al/{difficulty}/</code>:</li> </ol> <pre><code>codeunit 80099 \"CG-AL-E999 Test\"\n{\n    Subtype = Test;\n    TestPermissions = Disabled;\n    // ... tests\n}\n</code></pre> <ol> <li>Validate:</li> </ol> <pre><code>deno task bench --llms mock --tasks \"tasks/easy/CG-AL-E999*.yml\"\n</code></pre>"},{"location":"contributing/development/#testing-guidelines","title":"Testing Guidelines","text":""},{"location":"contributing/development/#test-organization","title":"Test Organization","text":"<p>Mirror source structure:</p> <pre><code>src/llm/registry.ts      \u2192 tests/unit/llm/registry.test.ts\nsrc/tasks/loader.ts      \u2192 tests/unit/tasks/loader.test.ts\n</code></pre>"},{"location":"contributing/development/#test-helpers","title":"Test Helpers","text":"<p>Use helpers from <code>tests/utils/test-helpers.ts</code>:</p> <pre><code>import {\n  createMockLLMConfig,\n  createMockTaskManifest,\n  EventCollector,\n  MockEnv,\n} from \"../utils/test-helpers.ts\";\n\nDeno.test(\"my test\", async () =&gt; {\n  const mockEnv = new MockEnv();\n  try {\n    mockEnv.set(\"API_KEY\", \"test\");\n    // Test code\n  } finally {\n    mockEnv.restore();\n  }\n});\n</code></pre>"},{"location":"contributing/development/#mock-factories","title":"Mock Factories","text":"<pre><code>// Create mock configs with overrides\nconst config = createMockLLMConfig({ temperature: 0.5 });\nconst manifest = createMockTaskManifest({ id: \"CG-AL-E999\" });\n\n// Create mock results\nconst compileResult = createMockCompilationResult({ success: true });\nconst testResult = createMockTestResult({ passedTests: 5, failedTests: 0 });\n</code></pre>"},{"location":"contributing/development/#git-workflow","title":"Git Workflow","text":""},{"location":"contributing/development/#branch-naming","title":"Branch Naming","text":"<ul> <li><code>feature/description</code> - New features</li> <li><code>fix/description</code> - Bug fixes</li> <li><code>docs/description</code> - Documentation</li> <li><code>refactor/description</code> - Code refactoring</li> </ul>"},{"location":"contributing/development/#commit-messages","title":"Commit Messages","text":"<p>Follow conventional commits:</p> <pre><code>feat: add OpenRouter adapter support\nfix: handle rate limit errors in Anthropic adapter\ndocs: update CLI reference\nrefactor: extract code extractor to separate module\ntest: add unit tests for task loader\n</code></pre>"},{"location":"contributing/development/#pull-requests","title":"Pull Requests","text":"<ol> <li>Create feature branch</li> <li>Make changes</li> <li>Run all checks: <code>deno check &amp;&amp; deno lint &amp;&amp; deno fmt &amp;&amp; deno task test</code></li> <li>Push and create PR</li> <li>Ensure CI passes</li> <li>Request review</li> </ol>"},{"location":"contributing/development/#debugging","title":"Debugging","text":""},{"location":"contributing/development/#debug-logging","title":"Debug Logging","text":"<p>Enable debug logging:</p> <pre><code>deno task bench --llms sonnet --tasks \"tasks/easy/*.yml\" --debug --debug-level verbose\n</code></pre> <p>Check logs in <code>debug/</code> directory.</p>"},{"location":"contributing/development/#vs-code-configuration","title":"VS Code Configuration","text":"<p>Recommended <code>.vscode/settings.json</code>:</p> <pre><code>{\n  \"deno.enable\": true,\n  \"deno.lint\": true,\n  \"deno.unstable\": false,\n  \"[typescript]\": {\n    \"editor.defaultFormatter\": \"denoland.vscode-deno\"\n  }\n}\n</code></pre>"},{"location":"contributing/development/#running-specific-tests","title":"Running Specific Tests","text":"<pre><code># Run single test file\ndeno test --allow-all tests/unit/llm/registry.test.ts\n\n# Run tests matching pattern\ndeno test --allow-all --filter \"registry\"\n</code></pre>"},{"location":"contributing/development/#building","title":"Building","text":""},{"location":"contributing/development/#compile-binary","title":"Compile Binary","text":"<pre><code># Current platform\ndeno task build\n\n# Cross-platform\ndeno task build:all\n</code></pre> <p>Outputs to <code>dist/</code>:</p> <ul> <li><code>centralgauge</code> (Linux)</li> <li><code>centralgauge.exe</code> (Windows)</li> <li><code>centralgauge-macos</code> (macOS x64)</li> <li><code>centralgauge-macos-arm</code> (macOS ARM)</li> </ul>"},{"location":"contributing/development/#next-steps","title":"Next Steps","text":"<ul> <li>Testing Patterns - Test writing guide</li> <li>Code Style - Style conventions</li> <li>Architecture - System design</li> </ul>"},{"location":"contributing/style/","title":"Code Style Guide","text":"<p>This guide documents the coding conventions used in CentralGauge.</p>"},{"location":"contributing/style/#typescript","title":"TypeScript","text":""},{"location":"contributing/style/#strict-mode","title":"Strict Mode","text":"<p>The project uses strict TypeScript settings:</p> <pre><code>{\n  \"compilerOptions\": {\n    \"strict\": true,\n    \"noImplicitReturns\": true,\n    \"noUnusedLocals\": true,\n    \"noUnusedParameters\": true,\n    \"exactOptionalPropertyTypes\": true,\n    \"noUncheckedIndexedAccess\": true\n  }\n}\n</code></pre>"},{"location":"contributing/style/#type-annotations","title":"Type Annotations","text":"<p>Always annotate function return types and complex parameters:</p> <pre><code>// Good\nfunction calculateScore(results: TestResult[]): number {\n  return results.filter((r) =&gt; r.passed).length / results.length;\n}\n\n// Avoid - missing return type\nfunction calculateScore(results: TestResult[]) {\n  return results.filter((r) =&gt; r.passed).length / results.length;\n}\n</code></pre>"},{"location":"contributing/style/#optional-properties","title":"Optional Properties","text":"<p>Use <code>undefined</code> explicitly for optional properties:</p> <pre><code>// Good\ninterface Config {\n  name: string;\n  timeout?: number | undefined;\n}\n\n// Avoid\ninterface Config {\n  name: string;\n  timeout?: number;\n}\n</code></pre>"},{"location":"contributing/style/#type-guards","title":"Type Guards","text":"<p>Use discriminated unions with type guards:</p> <pre><code>type Result =\n  | { success: true; data: string }\n  | { success: false; error: Error };\n\nfunction isSuccess(r: Result): r is { success: true; data: string } {\n  return r.success === true;\n}\n</code></pre>"},{"location":"contributing/style/#imports","title":"Imports","text":""},{"location":"contributing/style/#import-order","title":"Import Order","text":"<pre><code>// 1. Standard library\nimport { assertEquals } from \"@std/assert\";\nimport { parse } from \"@std/yaml\";\n\n// 2. Type imports from project\nimport type { LLMConfig, LLMResponse } from \"../../src/llm/types.ts\";\n\n// 3. Implementation imports from project\nimport { LLMAdapterRegistry } from \"../../src/llm/registry.ts\";\n\n// 4. Relative imports\nimport { helper } from \"./utils.ts\";\n</code></pre>"},{"location":"contributing/style/#barrel-exports","title":"Barrel Exports","text":"<p>Each module has a <code>mod.ts</code> with explicit exports:</p> <pre><code>// src/llm/mod.ts\n\n// Types first\nexport type { LLMAdapter, LLMConfig, LLMResponse } from \"./types.ts\";\n\n// Then implementations\nexport { LLMAdapterRegistry } from \"./registry.ts\";\nexport { AnthropicAdapter } from \"./anthropic-adapter.ts\";\n</code></pre>"},{"location":"contributing/style/#extension-full-paths","title":"Extension-Full Paths","text":"<p>Always include <code>.ts</code> extension:</p> <pre><code>// Good\nimport { helper } from \"./utils.ts\";\n\n// Bad\nimport { helper } from \"./utils\";\n</code></pre>"},{"location":"contributing/style/#naming","title":"Naming","text":""},{"location":"contributing/style/#files","title":"Files","text":"<ul> <li>Use kebab-case for files: <code>llm-adapter.ts</code>, <code>code-extractor.ts</code></li> <li>Use <code>.test.ts</code> suffix for tests: <code>registry.test.ts</code></li> <li>Use <code>mod.ts</code> for barrel exports</li> </ul>"},{"location":"contributing/style/#classes-and-interfaces","title":"Classes and Interfaces","text":"<ul> <li>PascalCase for classes and interfaces</li> <li>Descriptive suffixes: <code>Adapter</code>, <code>Provider</code>, <code>Registry</code>, <code>Config</code></li> </ul> <pre><code>class AnthropicAdapter {}\ninterface LLMConfig {}\nclass ContainerProviderRegistry {}\n</code></pre>"},{"location":"contributing/style/#functions-and-variables","title":"Functions and Variables","text":"<ul> <li>camelCase for functions and variables</li> <li>Verb prefixes for functions: <code>create</code>, <code>get</code>, <code>load</code>, <code>parse</code></li> </ul> <pre><code>function createAdapter() {}\nfunction loadTaskManifest() {}\nconst defaultConfig = {};\n</code></pre>"},{"location":"contributing/style/#constants","title":"Constants","text":"<ul> <li>UPPER_SNAKE_CASE for true constants</li> <li>camelCase for configuration objects</li> </ul> <pre><code>const DEFAULT_TIMEOUT_MS = 30000;\nconst MAX_RETRIES = 3;\n\nconst defaultConfig = {\n  timeout: DEFAULT_TIMEOUT_MS,\n  retries: MAX_RETRIES,\n};\n</code></pre>"},{"location":"contributing/style/#console-output","title":"Console Output","text":""},{"location":"contributing/style/#colored-output","title":"Colored Output","text":"<p>Use <code>@std/fmt/colors</code> with tag prefixes:</p> <pre><code>import * as colors from \"@std/fmt/colors\";\n\n// Good\nconsole.log(colors.green(\"[OK]\"), \"Task completed\");\nconsole.log(colors.red(\"[FAIL]\"), \"Task failed\");\nconsole.log(colors.yellow(\"[WARN]\"), \"Warning message\");\nconsole.log(colors.blue(\"[Info]\"), \"Information\");\n\n// Avoid emojis\nconsole.log(\"\u2705 Task completed\"); // Don't do this\n</code></pre>"},{"location":"contributing/style/#structured-logging","title":"Structured Logging","text":"<p>Use helpers from <code>cli/helpers/logging.ts</code>:</p> <pre><code>import { log } from \"../helpers/mod.ts\";\n\nlog.task(`Starting ${taskId}`);\nlog.llm(model, \"Generating code...\");\nlog.compile(model, \"success\");\nlog.success(\"Benchmark complete\");\nlog.fail(\"Task failed\");\n</code></pre>"},{"location":"contributing/style/#error-handling","title":"Error Handling","text":""},{"location":"contributing/style/#error-hierarchy","title":"Error Hierarchy","text":"<p>Use the structured error hierarchy:</p> <pre><code>import {\n  CentralGaugeError,\n  LLMProviderError,\n  TaskExecutionError,\n} from \"../src/errors.ts\";\n\n// Good - specific error with context\nthrow new TaskExecutionError(\n  `Compilation failed for ${taskId}`,\n  taskId,\n  attemptNumber,\n  { errors: compilationErrors },\n);\n\n// Avoid - generic error\nthrow new Error(\"Compilation failed\");\n</code></pre>"},{"location":"contributing/style/#error-checking","title":"Error Checking","text":"<pre><code>import { getRetryDelay, isRetryableError } from \"../src/errors.ts\";\n\ntry {\n  await operation();\n} catch (error) {\n  if (error instanceof LLMProviderError &amp;&amp; isRetryableError(error)) {\n    const delay = getRetryDelay(error, 1000);\n    await sleep(delay);\n    // Retry\n  } else {\n    throw error;\n  }\n}\n</code></pre>"},{"location":"contributing/style/#async-code","title":"Async Code","text":""},{"location":"contributing/style/#asyncawait","title":"Async/Await","text":"<p>Always use async/await over raw promises:</p> <pre><code>// Good\nasync function loadManifest(path: string): Promise&lt;TaskManifest&gt; {\n  const content = await Deno.readTextFile(path);\n  return parseYaml(content) as TaskManifest;\n}\n\n// Avoid\nfunction loadManifest(path: string): Promise&lt;TaskManifest&gt; {\n  return Deno.readTextFile(path).then((content) =&gt;\n    parseYaml(content) as TaskManifest\n  );\n}\n</code></pre>"},{"location":"contributing/style/#async-generators","title":"Async Generators","text":"<p>When using async generators with return values:</p> <pre><code>// Don't use for await...of if you need the return value\nasync function processGenerator&lt;Y, R&gt;(gen: AsyncGenerator&lt;Y, R&gt;): Promise&lt;R&gt; {\n  let result = await gen.next();\n  while (!result.done) {\n    console.log(\"Yield:\", result.value);\n    result = await gen.next();\n  }\n  return result.value; // Return value captured correctly\n}\n</code></pre>"},{"location":"contributing/style/#functions","title":"Functions","text":""},{"location":"contributing/style/#function-length","title":"Function Length","text":"<p>Keep functions under 50 lines. Extract helpers:</p> <pre><code>// Good - extracted helpers\nasync function runBenchmark(options: Options): Promise&lt;Results&gt; {\n  const tasks = await loadTasks(options.taskPatterns);\n  const models = resolveModels(options.models);\n  const results = await executeAll(tasks, models);\n  return formatResults(results);\n}\n\n// Avoid - monolithic function\nasync function runBenchmark(options: Options): Promise&lt;Results&gt; {\n  // 200 lines of logic...\n}\n</code></pre>"},{"location":"contributing/style/#pure-functions","title":"Pure Functions","text":"<p>Prefer pure functions where possible:</p> <pre><code>// Good - pure function\nfunction calculateScore(results: TestResult[]): number {\n  return results.filter((r) =&gt; r.passed).length / results.length;\n}\n\n// Avoid - side effects\nfunction calculateScore(results: TestResult[]): number {\n  console.log(\"Calculating...\"); // Side effect\n  globalState.lastScore = score; // Side effect\n  return score;\n}\n</code></pre>"},{"location":"contributing/style/#classes","title":"Classes","text":""},{"location":"contributing/style/#single-responsibility","title":"Single Responsibility","text":"<p>Each class should have one primary responsibility:</p> <pre><code>// Good - focused class\nclass CodeExtractor {\n  extract(response: string): string {}\n  detectLanguage(code: string): \"al\" | \"diff\" {}\n}\n\n// Avoid - multiple responsibilities\nclass TaskProcessor {\n  loadTask() {}\n  compileCode() {}\n  runTests() {}\n  formatResults() {}\n  sendNotification() {}\n}\n</code></pre>"},{"location":"contributing/style/#dependency-injection","title":"Dependency Injection","text":"<p>Use constructor injection for dependencies:</p> <pre><code>// Good\nclass TaskExecutor {\n  constructor(\n    private llmAdapter: LLMAdapter,\n    private containerProvider: ContainerProvider,\n  ) {}\n}\n\n// Avoid - hard-coded dependencies\nclass TaskExecutor {\n  private llmAdapter = new AnthropicAdapter();\n}\n</code></pre>"},{"location":"contributing/style/#documentation","title":"Documentation","text":""},{"location":"contributing/style/#jsdoc-comments","title":"JSDoc Comments","text":"<p>Use JSDoc for public APIs:</p> <pre><code>/**\n * Loads a task manifest from a YAML file\n *\n * @param path - Path to the YAML file\n * @returns Parsed task manifest\n * @throws {ValidationError} If the manifest is invalid\n *\n * @example\n * ```typescript\n * const manifest = await loadTaskManifest(\"tasks/easy/CG-AL-E001.yml\");\n * ```\n */\nexport async function loadTaskManifest(path: string): Promise&lt;TaskManifest&gt; {\n  // ...\n}\n</code></pre>"},{"location":"contributing/style/#inline-comments","title":"Inline Comments","text":"<p>Use comments for complex logic:</p> <pre><code>// Calculate weighted score:\n// - First attempt success: 1.0\n// - Second attempt success: 0.8 (penalty for retry)\n// - Failed: 0.0\nconst score = attempt === 1 ? 1.0 : attempt === 2 ? 0.8 : 0.0;\n</code></pre>"},{"location":"contributing/style/#formatting","title":"Formatting","text":""},{"location":"contributing/style/#deno-formatter","title":"Deno Formatter","text":"<p>Use <code>deno fmt</code> with project settings:</p> <pre><code>{\n  \"fmt\": {\n    \"useTabs\": false,\n    \"lineWidth\": 80,\n    \"indentWidth\": 2,\n    \"semiColons\": true,\n    \"singleQuote\": false,\n    \"proseWrap\": \"preserve\"\n  }\n}\n</code></pre>"},{"location":"contributing/style/#run-before-commit","title":"Run Before Commit","text":"<pre><code>deno fmt\ndeno lint\ndeno check cli/centralgauge.ts\n</code></pre>"},{"location":"contributing/style/#testing-style","title":"Testing Style","text":""},{"location":"contributing/style/#test-names","title":"Test Names","text":"<p>Use descriptive test names:</p> <pre><code>// Good\nDeno.test(\"LLMAdapter generates AL code when given valid prompt\", async () =&gt; {});\nDeno.test(\"LLMAdapter throws LLMProviderError when API key is missing\", async () =&gt; {});\n\n// Avoid\nDeno.test(\"test1\", async () =&gt; {});\nDeno.test(\"adapter\", async () =&gt; {});\n</code></pre>"},{"location":"contributing/style/#test-structure","title":"Test Structure","text":"<pre><code>Deno.test(\"FeatureName\", async (t) =&gt; {\n  // Setup (if needed)\n  const mockEnv = new MockEnv();\n\n  try {\n    await t.step(\"handles normal case\", async () =&gt; {\n      // Arrange\n      const input = \"valid\";\n\n      // Act\n      const result = await process(input);\n\n      // Assert\n      assertEquals(result.success, true);\n    });\n\n    await t.step(\"handles edge case\", async () =&gt; {\n      // ...\n    });\n  } finally {\n    // Cleanup\n    mockEnv.restore();\n  }\n});\n</code></pre>"},{"location":"contributing/style/#file-organization","title":"File Organization","text":""},{"location":"contributing/style/#module-structure","title":"Module Structure","text":"<pre><code>src/feature/\n\u251c\u2500\u2500 mod.ts           # Barrel exports\n\u251c\u2500\u2500 types.ts         # Interfaces and types\n\u251c\u2500\u2500 registry.ts      # Registry class\n\u251c\u2500\u2500 provider-a.ts    # Implementation A\n\u2514\u2500\u2500 provider-b.ts    # Implementation B\n</code></pre>"},{"location":"contributing/style/#test-structure_1","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/\n\u2502   \u2514\u2500\u2500 feature/\n\u2502       \u251c\u2500\u2500 registry.test.ts\n\u2502       \u2514\u2500\u2500 provider-a.test.ts\n\u251c\u2500\u2500 integration/\n\u2502   \u2514\u2500\u2500 feature-real.test.ts\n\u2514\u2500\u2500 utils/\n    \u2514\u2500\u2500 test-helpers.ts\n</code></pre>"},{"location":"contributing/style/#next-steps","title":"Next Steps","text":"<ul> <li>Development Setup - Environment setup</li> <li>Testing Patterns - Test writing guide</li> <li>Architecture - System design</li> </ul>"},{"location":"contributing/testing/","title":"Testing Patterns","text":"<p>This guide covers testing patterns and utilities used in CentralGauge.</p>"},{"location":"contributing/testing/#running-tests","title":"Running Tests","text":"<pre><code># Full test suite with coverage\ndeno task test\n\n# Unit tests only\ndeno task test:unit\n\n# Integration tests only\ndeno task test:integration\n\n# Watch mode\ndeno task test:watch\n\n# Coverage report\ndeno task coverage\ndeno task coverage:html\n</code></pre> <p>Important: Always use <code>deno task test</code>, not <code>deno test</code> directly. The tasks include <code>--allow-all</code> for required permissions.</p>"},{"location":"contributing/testing/#test-organization","title":"Test Organization","text":"<p>Tests mirror the source structure:</p> <pre><code>src/\n\u251c\u2500\u2500 llm/\n\u2502   \u251c\u2500\u2500 registry.ts\n\u2502   \u2514\u2500\u2500 anthropic-adapter.ts\n\u2514\u2500\u2500 tasks/\n    \u2514\u2500\u2500 loader.ts\n\ntests/\n\u251c\u2500\u2500 unit/\n\u2502   \u251c\u2500\u2500 llm/\n\u2502   \u2502   \u251c\u2500\u2500 registry.test.ts\n\u2502   \u2502   \u2514\u2500\u2500 anthropic-adapter.test.ts\n\u2502   \u2514\u2500\u2500 tasks/\n\u2502       \u2514\u2500\u2500 loader.test.ts\n\u2514\u2500\u2500 integration/\n    \u2514\u2500\u2500 bc-container-real.test.ts\n</code></pre>"},{"location":"contributing/testing/#test-structure","title":"Test Structure","text":"<p>Use nested test steps:</p> <pre><code>import { assertEquals, assertThrows } from \"@std/assert\";\n\nDeno.test(\"FeatureName\", async (t) =&gt; {\n  await t.step(\"handles normal case\", async () =&gt; {\n    const result = await myFunction(\"valid input\");\n    assertEquals(result, expectedValue);\n  });\n\n  await t.step(\"handles edge case\", async () =&gt; {\n    const result = await myFunction(\"\");\n    assertEquals(result, null);\n  });\n\n  await t.step(\"throws on invalid input\", () =&gt; {\n    assertThrows(\n      () =&gt; myFunction(null),\n      Error,\n      \"Input required\",\n    );\n  });\n});\n</code></pre>"},{"location":"contributing/testing/#mock-factories","title":"Mock Factories","text":"<p>Use factories from <code>tests/utils/test-helpers.ts</code>:</p>"},{"location":"contributing/testing/#llm-mocks","title":"LLM Mocks","text":"<pre><code>import {\n  createMockLLMConfig,\n  createMockLLMResponse,\n} from \"../utils/test-helpers.ts\";\n\n// Default mock config\nconst config = createMockLLMConfig();\n\n// Override specific fields\nconst customConfig = createMockLLMConfig({\n  provider: \"anthropic\",\n  model: \"claude-sonnet-4\",\n  temperature: 0.5,\n});\n\n// Mock response\nconst response = createMockLLMResponse({\n  content: \"procedure MyProc() begin end;\",\n  usage: { promptTokens: 50, completionTokens: 20, totalTokens: 70 },\n});\n</code></pre>"},{"location":"contributing/testing/#task-mocks","title":"Task Mocks","text":"<pre><code>import {\n  createMockExecutionAttempt,\n  createMockTaskExecutionContext,\n  createMockTaskManifest,\n} from \"../utils/test-helpers.ts\";\n\nconst manifest = createMockTaskManifest({\n  id: \"CG-AL-E001\",\n  max_attempts: 3,\n});\n\nconst context = createMockTaskExecutionContext({\n  llmProvider: \"anthropic\",\n  llmModel: \"claude-sonnet-4\",\n});\n\nconst attempt = createMockExecutionAttempt({\n  attemptNumber: 2,\n  success: false,\n  failureReasons: [\"Compilation failed\"],\n});\n</code></pre>"},{"location":"contributing/testing/#container-result-mocks","title":"Container Result Mocks","text":"<pre><code>import {\n  createMockCompilationError,\n  createMockCompilationResult,\n  createMockTestCaseResult,\n  createMockTestResult,\n} from \"../utils/test-helpers.ts\";\n\nconst compileResult = createMockCompilationResult({\n  success: false,\n  errors: [createMockCompilationError({ message: \"Syntax error\" })],\n});\n\nconst testResult = createMockTestResult({\n  passed: 5,\n  failed: 1,\n  testCases: [\n    createMockTestCaseResult({ name: \"TestAdd\", passed: true }),\n    createMockTestCaseResult({ name: \"TestSub\", passed: false }),\n  ],\n});\n</code></pre>"},{"location":"contributing/testing/#mockenv","title":"MockEnv","text":"<p>Test environment variable handling:</p> <pre><code>import { MockEnv } from \"../utils/test-helpers.ts\";\n\nDeno.test(\"uses API key from env\", async () =&gt; {\n  const mockEnv = new MockEnv();\n\n  try {\n    mockEnv.set(\"ANTHROPIC_API_KEY\", \"test-key-123\");\n    mockEnv.delete(\"OPENAI_API_KEY\");\n\n    // Test code that reads env vars\n    const key = Deno.env.get(\"ANTHROPIC_API_KEY\");\n    assertEquals(key, \"test-key-123\");\n  } finally {\n    mockEnv.restore(); // Always restore\n  }\n});\n</code></pre>"},{"location":"contributing/testing/#eventcollector","title":"EventCollector","text":"<p>Collect and analyze events:</p> <pre><code>import { EventCollector } from \"../utils/test-helpers.ts\";\n\nDeno.test(\"emits correct events\", async () =&gt; {\n  const collector = new EventCollector();\n\n  orchestrator.on(collector.listener);\n  await orchestrator.run(tasks);\n\n  // Check event count\n  assertEquals(collector.count, 10);\n\n  // Check for specific event types\n  assert(collector.hasEventType(\"task_started\"));\n  assert(collector.hasEventType(\"llm_completed\"));\n\n  // Get typed events\n  const llmEvents = collector.getByType(\"llm_started\");\n  assertEquals(llmEvents.length, 3);\n  assertEquals(llmEvents[0].model, \"sonnet\");\n\n  // Get first/last\n  const first = collector.getFirst();\n  const last = collector.getLast();\n\n  // Reset for next test\n  collector.clear();\n});\n</code></pre>"},{"location":"contributing/testing/#assertion-helpers","title":"Assertion Helpers","text":"<pre><code>import {\n  assertThrowsWithMessage,\n  assertValidCostEstimate,\n  assertValidLLMResponse,\n} from \"../utils/test-helpers.ts\";\n\n// Validate response structure\nassertValidLLMResponse(response);\n// Checks: content exists, usage fields exist, totalTokens = prompt + completion\n\n// Validate cost\nassertValidCostEstimate(cost);\n// Checks: is number, non-negative, finite\n\n// Assert error message\nawait assertThrowsWithMessage(\n  () =&gt; riskyOperation(),\n  \"expected error substring\",\n);\n</code></pre>"},{"location":"contributing/testing/#mockalcode","title":"MockALCode","text":"<p>Pre-built AL code for testing:</p> <pre><code>import { MockALCode } from \"../utils/test-helpers.ts\";\n\nconst code = MockALCode.table; // Complete table definition\nconst page = MockALCode.page; // Complete page definition\nconst codeunit = MockALCode.codeunit; // Complete codeunit\n</code></pre>"},{"location":"contributing/testing/#temporary-directories","title":"Temporary Directories","text":"<pre><code>import { cleanupTempDir, createTempDir } from \"../utils/test-helpers.ts\";\n\nDeno.test(\"writes output files\", async () =&gt; {\n  const tempDir = await createTempDir(\"my-test\");\n\n  try {\n    await writeOutput(tempDir);\n\n    const files = Array.from(Deno.readDirSync(tempDir));\n    assertEquals(files.length, 1);\n  } finally {\n    await cleanupTempDir(tempDir);\n  }\n});\n</code></pre>"},{"location":"contributing/testing/#conditional-tests","title":"Conditional Tests","text":"<p>Skip tests on specific platforms:</p> <pre><code>const isWindows = Deno.build.os === \"windows\";\n\nDeno.test({\n  name: \"bccontainer compiles AL code\",\n  ignore: !isWindows, // Skip on non-Windows\n  fn: async () =&gt; {\n    // Windows-only test\n  },\n});\n</code></pre>"},{"location":"contributing/testing/#testing-async-generators","title":"Testing Async Generators","text":"<p>When testing generators with return values:</p> <pre><code>Deno.test(\"generator returns final result\", async () =&gt; {\n  const gen = myGenerator();\n\n  // Don't use for await...of - it discards return value\n  let iterResult = await gen.next();\n  while (!iterResult.done) {\n    // Process yields\n    iterResult = await gen.next();\n  }\n\n  // Now we have the return value\n  assertExists(iterResult.value);\n  assertEquals(iterResult.value.success, true);\n});\n</code></pre>"},{"location":"contributing/testing/#testing-error-cases","title":"Testing Error Cases","text":"<pre><code>Deno.test(\"handles errors correctly\", async (t) =&gt; {\n  await t.step(\"throws on invalid input\", () =&gt; {\n    assertThrows(\n      () =&gt; validate(null),\n      ValidationError,\n      \"Input is required\",\n    );\n  });\n\n  await t.step(\"returns error result on failure\", async () =&gt; {\n    const result = await process({ invalid: true });\n    assertEquals(result.success, false);\n    assertStringIncludes(result.error, \"invalid\");\n  });\n\n  await t.step(\"retries on transient errors\", async () =&gt; {\n    let attempts = 0;\n    const result = await retryable(async () =&gt; {\n      attempts++;\n      if (attempts &lt; 3) throw new Error(\"Transient\");\n      return \"success\";\n    });\n\n    assertEquals(attempts, 3);\n    assertEquals(result, \"success\");\n  });\n});\n</code></pre>"},{"location":"contributing/testing/#integration-tests","title":"Integration Tests","text":"<p>Integration tests use real containers (when available):</p> <pre><code>// tests/integration/bc-container-real.test.ts\n\nconst hasContainer = await checkContainerExists(\"Cronus27\");\n\nDeno.test({\n  name: \"compiles AL code in real container\",\n  ignore: !hasContainer,\n  fn: async () =&gt; {\n    const provider = ContainerProviderRegistry.create(\"bccontainer\");\n    const result = await provider.compile(\"Cronus27\", testProjectPath);\n    assertEquals(result.success, true);\n  },\n});\n</code></pre>"},{"location":"contributing/testing/#test-data","title":"Test Data","text":"<p>Keep test data in <code>tests/fixtures/</code>:</p> <pre><code>import { testData } from \"../fixtures/provider-responses.ts\";\n\nDeno.test(\"parses provider response\", () =&gt; {\n  const result = parseResponse(testData.anthropicResponse);\n  assertEquals(result.model, \"claude-sonnet-4\");\n});\n</code></pre>"},{"location":"contributing/testing/#coverage","title":"Coverage","text":"<p>Check coverage after tests:</p> <pre><code># Generate coverage\ndeno task test\n\n# View coverage report\ndeno task coverage\n\n# Generate HTML report\ndeno task coverage:html\nopen coverage/html/index.html\n</code></pre>"},{"location":"contributing/testing/#best-practices","title":"Best Practices","text":""},{"location":"contributing/testing/#isolate-tests","title":"Isolate Tests","text":"<p>Each test should be independent:</p> <pre><code>// Good - setup/teardown in each test\nDeno.test(\"test A\", async () =&gt; {\n  const data = await setup();\n  try {\n    // test\n  } finally {\n    await cleanup(data);\n  }\n});\n\n// Bad - shared state\nlet sharedData;\nDeno.test(\"test A\", () =&gt; {\n  sharedData = \"from A\";\n});\nDeno.test(\"test B\", () =&gt; {\n  assertEquals(sharedData, \"from A\"); // Depends on A\n});\n</code></pre>"},{"location":"contributing/testing/#test-edge-cases","title":"Test Edge Cases","text":"<pre><code>Deno.test(\"handles edge cases\", async (t) =&gt; {\n  await t.step(\"empty input\", () =&gt; {/* ... */});\n  await t.step(\"null input\", () =&gt; {/* ... */});\n  await t.step(\"very long input\", () =&gt; {/* ... */});\n  await t.step(\"special characters\", () =&gt; {/* ... */});\n  await t.step(\"unicode\", () =&gt; {/* ... */});\n});\n</code></pre>"},{"location":"contributing/testing/#use-descriptive-names","title":"Use Descriptive Names","text":"<pre><code>// Good\nDeno.test(\"LLMAdapter generates code when given valid prompt\", async () =&gt; {});\nDeno.test(\"LLMAdapter throws when API key is missing\", async () =&gt; {});\n\n// Bad\nDeno.test(\"test1\", async () =&gt; {});\nDeno.test(\"adapter test\", async () =&gt; {});\n</code></pre>"},{"location":"contributing/testing/#prefer-specific-assertions","title":"Prefer Specific Assertions","text":"<pre><code>// Good - specific\nassertEquals(result.count, 5);\nassertStringIncludes(result.message, \"error\");\nassertArrayIncludes(result.items, [\"a\", \"b\"]);\n\n// Bad - generic\nassert(result.count === 5);\nassert(result.message.includes(\"error\"));\n</code></pre>"},{"location":"contributing/testing/#next-steps","title":"Next Steps","text":"<ul> <li>Development Setup - Environment setup</li> <li>Code Style - Style conventions</li> <li>API Reference - Module documentation</li> </ul>"},{"location":"guides/configuration/","title":"Configuration","text":"<p>CentralGauge uses a layered configuration system that merges settings from multiple sources.</p>"},{"location":"guides/configuration/#configuration-sources-priority-order","title":"Configuration Sources (Priority Order)","text":"<ol> <li>CLI arguments (highest priority)</li> <li>Environment variables</li> <li><code>.centralgauge.yml</code> in current directory</li> <li><code>.centralgauge.yml</code> in home directory</li> <li>Built-in defaults (lowest priority)</li> </ol> <p>Higher-priority sources override lower-priority ones.</p>"},{"location":"guides/configuration/#configuration-file","title":"Configuration File","text":""},{"location":"guides/configuration/#creating-a-configuration-file","title":"Creating a Configuration File","text":"<p>Generate a sample configuration file:</p> <pre><code>deno run --allow-all cli/centralgauge.ts config init\n</code></pre> <p>This creates <code>.centralgauge.yml</code> in your current directory.</p>"},{"location":"guides/configuration/#full-configuration-reference","title":"Full Configuration Reference","text":"<pre><code># .centralgauge.yml\n\n# Default models for different scenarios\ndefaultModels:\n  benchmark: [sonnet, gpt-4o] # Models for production benchmarks\n  development: [mock] # Models for development/testing\n  comparison: [flagship] # Models for side-by-side comparison\n\n# LLM provider settings\nllm:\n  temperature: 0.1 # Lower = more deterministic\n  maxTokens: 4000 # Maximum response length\n  timeout: 30000 # Request timeout in milliseconds\n\n# Benchmark execution settings\nbenchmark:\n  attempts: 2 # Number of attempts per task\n  outputDir: results # Directory for benchmark results\n  templateDir: templates # Directory for prompt templates\n\n# Container settings\ncontainer:\n  provider: bccontainer # Container provider (mock, bccontainer, docker)\n  name: Cronus27 # Container name\n  bcVersion: \"24.0\" # Business Central version\n  memoryLimit: 8G # Container memory limit\n  credentials:\n    username: admin # Container authentication username\n    password: admin # Container authentication password\n\n# Debug settings\ndebug:\n  enabled: false # Enable debug logging\n  outputDir: debug # Debug output directory\n  logLevel: basic # basic | detailed | verbose\n  includeRawResponse: false # Include full API responses\n  includeRequestHeaders: false # Include request headers\n  maxFileSize: 100 # Max log file size in MB\n\n# Named system prompts for model variants\nsystemPrompts:\n  strict-al:\n    content: |\n      You are a strict AL code generator for Business Central.\n      Only output valid AL code without explanations.\n      Always use proper naming conventions.\n\n  creative:\n    content: |\n      Think creatively about solutions while ensuring code compiles.\n      Consider multiple approaches before choosing the best one.\n\n# Named variant profiles for comparing same model with different configs\nvariantProfiles:\n  conservative:\n    description: \"Low temperature for deterministic output\"\n    config:\n      temperature: 0.1\n      maxTokens: 4000\n\n  creative:\n    description: \"Higher temperature for varied solutions\"\n    config:\n      temperature: 0.8\n      maxTokens: 8000\n      systemPromptName: creative\n\n  deep-thinking:\n    description: \"Extended reasoning for complex tasks\"\n    config:\n      temperature: 0.2\n      thinkingBudget: 50000\n\n# Prompt injection configuration (advanced)\nprompts:\n  enabled: true\n  injections:\n    anthropic:\n      default:\n        prefix: \"\"\n        suffix: \"\\n\\nRemember to include proper error handling.\"\n    openai:\n      generation:\n        prefix: \"Important context: \"\n</code></pre>"},{"location":"guides/configuration/#environment-variables","title":"Environment Variables","text":"<p>All settings can be overridden via environment variables using the <code>CENTRALGAUGE_</code> prefix:</p>"},{"location":"guides/configuration/#model-settings","title":"Model Settings","text":"<pre><code># Default models for scenarios\nCENTRALGAUGE_BENCHMARK_MODELS=sonnet,gpt-4o\nCENTRALGAUGE_DEV_MODELS=mock\nCENTRALGAUGE_COMPARISON_MODELS=flagship\n</code></pre>"},{"location":"guides/configuration/#llm-settings","title":"LLM Settings","text":"<pre><code>CENTRALGAUGE_TEMPERATURE=0.1\nCENTRALGAUGE_MAX_TOKENS=4000\n</code></pre>"},{"location":"guides/configuration/#benchmark-settings","title":"Benchmark Settings","text":"<pre><code>CENTRALGAUGE_ATTEMPTS=2\nCENTRALGAUGE_OUTPUT_DIR=results\n</code></pre>"},{"location":"guides/configuration/#container-settings","title":"Container Settings","text":"<pre><code>CENTRALGAUGE_CONTAINER_PROVIDER=bccontainer\nCENTRALGAUGE_CONTAINER_NAME=Cronus27\nCENTRALGAUGE_CONTAINER_USERNAME=admin\nCENTRALGAUGE_CONTAINER_PASSWORD=admin\n</code></pre>"},{"location":"guides/configuration/#debug-settings","title":"Debug Settings","text":"<pre><code>CENTRALGAUGE_DEBUG=true\nCENTRALGAUGE_DEBUG_OUTPUT_DIR=debug\nCENTRALGAUGE_DEBUG_LOG_LEVEL=verbose\nCENTRALGAUGE_DEBUG_INCLUDE_RAW=true\nCENTRALGAUGE_DEBUG_INCLUDE_HEADERS=false\nCENTRALGAUGE_DEBUG_MAX_FILE_SIZE=100\n</code></pre>"},{"location":"guides/configuration/#api-keys","title":"API Keys","text":"<pre><code># Provider API keys (required)\nANTHROPIC_API_KEY=sk-ant-api03-...\nOPENAI_API_KEY=sk-proj-...\nGOOGLE_API_KEY=AIzaSy...\nOPENROUTER_API_KEY=sk-or-v1-...\n\n# Azure OpenAI\nAZURE_OPENAI_API_KEY=...\nAZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/\n</code></pre>"},{"location":"guides/configuration/#cli-overrides","title":"CLI Overrides","text":"<p>Any configuration can be overridden via CLI arguments:</p> <pre><code># Override temperature\ndeno task bench --llms sonnet --temperature 0.3\n\n# Override output directory\ndeno task bench --llms sonnet --output my-results/\n\n# Override attempts\ndeno task bench --llms sonnet --attempts 3\n\n# Override container\ndeno task bench --llms sonnet --container MyContainer\n</code></pre>"},{"location":"guides/configuration/#container-configuration","title":"Container Configuration","text":""},{"location":"guides/configuration/#using-bccontainerhelper","title":"Using bccontainerhelper","text":"<p>The default and recommended provider for Windows:</p> <pre><code>container:\n  provider: bccontainer\n  name: Cronus27\n  bcVersion: \"27.0\"\n  credentials:\n    username: admin\n    password: admin\n</code></pre>"},{"location":"guides/configuration/#using-docker-directly","title":"Using Docker Directly","text":"<p>For Linux or custom setups:</p> <pre><code>container:\n  provider: docker\n  name: my-bc-container\n</code></pre>"},{"location":"guides/configuration/#using-mock-provider","title":"Using Mock Provider","text":"<p>For development and testing (no real container):</p> <pre><code>container:\n  provider: mock\n  name: mock-container\n</code></pre>"},{"location":"guides/configuration/#variant-profiles","title":"Variant Profiles","text":"<p>Define reusable model configurations:</p> <pre><code>variantProfiles:\n  conservative:\n    description: \"Low temperature for deterministic output\"\n    config:\n      temperature: 0.1\n      maxTokens: 4000\n\n  extended-thinking:\n    description: \"Use extended thinking for complex tasks\"\n    config:\n      thinkingBudget: 50000\n      maxTokens: 16000\n</code></pre> <p>Use profiles in benchmarks:</p> <pre><code>deno task bench --llms \"opus@profile=conservative,opus@profile=extended-thinking\"\n</code></pre>"},{"location":"guides/configuration/#system-prompts","title":"System Prompts","text":"<p>Define named system prompts:</p> <pre><code>systemPrompts:\n  strict:\n    content: |\n      You are a strict AL code generator.\n      Only output valid AL code in code blocks.\n      No explanations or comments outside the code.\n</code></pre> <p>Use in benchmarks:</p> <pre><code>deno task bench --llms \"sonnet@prompt=strict\"\n</code></pre>"},{"location":"guides/configuration/#viewing-current-configuration","title":"Viewing Current Configuration","text":"<p>Display the effective configuration:</p> <pre><code>deno run --allow-all cli/centralgauge.ts config show\n</code></pre> <p>This shows the merged configuration from all sources.</p>"},{"location":"guides/configuration/#configuration-validation","title":"Configuration Validation","text":"<p>Validate your configuration file:</p> <pre><code>deno run --allow-all cli/centralgauge.ts config validate\n</code></pre>"},{"location":"guides/configuration/#best-practices","title":"Best Practices","text":""},{"location":"guides/configuration/#development-vs-production","title":"Development vs Production","text":"<p>Use different configurations for development and production:</p> <pre><code># Development (in .centralgauge.yml)\ndefaultModels:\n  development: [mock]\n\n# Production (override via environment)\nCENTRALGAUGE_BENCHMARK_MODELS=opus,gpt-5\n</code></pre>"},{"location":"guides/configuration/#secure-credentials","title":"Secure Credentials","text":"<p>Never commit API keys to version control:</p> <pre><code># Use .env file (git-ignored)\ncp .env.example .env\necho \".env\" &gt;&gt; .gitignore\n</code></pre>"},{"location":"guides/configuration/#container-credentials","title":"Container Credentials","text":"<p>Store container credentials securely:</p> <pre><code># Environment variables (preferred)\nCENTRALGAUGE_CONTAINER_USERNAME=admin\nCENTRALGAUGE_CONTAINER_PASSWORD=$(cat /path/to/secure/password)\n</code></pre>"},{"location":"guides/configuration/#per-project-configuration","title":"Per-Project Configuration","text":"<p>Each project can have its own <code>.centralgauge.yml</code>:</p> <pre><code>my-project/\n  .centralgauge.yml    # Project-specific settings\n  tasks/               # Custom tasks\n  templates/           # Custom templates\n</code></pre>"},{"location":"guides/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Model Variants - Advanced model configuration</li> <li>Running Benchmarks - Benchmark execution</li> <li>CLI Reference - All CLI options</li> </ul>"},{"location":"guides/model-variants/","title":"Model Variants","text":"<p>Model variants allow you to compare the same model with different configurations, enabling precise evaluation of how settings like temperature, token limits, and system prompts affect performance.</p>"},{"location":"guides/model-variants/#variant-syntax","title":"Variant Syntax","text":"<p>Use the <code>@</code> symbol to specify variant parameters:</p> <pre><code>deno task bench --llms \"model@param=value\"\n</code></pre>"},{"location":"guides/model-variants/#single-parameter","title":"Single Parameter","text":"<pre><code>deno task bench --llms \"opus@temp=0.5\"\n</code></pre>"},{"location":"guides/model-variants/#multiple-parameters","title":"Multiple Parameters","text":"<p>Separate parameters with semicolons:</p> <pre><code>deno task bench --llms \"opus@temp=0.5;maxTokens=8000\"\n</code></pre>"},{"location":"guides/model-variants/#comparing-variants","title":"Comparing Variants","text":"<pre><code>deno task bench --llms \"opus@temp=0.1,opus@temp=0.5,opus@temp=0.9\"\n</code></pre>"},{"location":"guides/model-variants/#supported-parameters","title":"Supported Parameters","text":"Parameter Aliases Type Description <code>temperature</code> <code>temp</code> number Generation temperature (0.0-1.0) <code>maxTokens</code> <code>max_tokens</code>, <code>tokens</code> number Maximum response tokens <code>systemPromptName</code> <code>prompt</code>, <code>system_prompt</code> string Named prompt from config <code>thinkingBudget</code> <code>thinking</code>, <code>reasoning</code> number Extended thinking/reasoning budget <code>timeout</code> - number Request timeout in ms <code>profile</code> - string Named variant profile from config"},{"location":"guides/model-variants/#temperature-comparison","title":"Temperature Comparison","text":"<p>Temperature controls the randomness of model outputs:</p> <pre><code># Compare different temperatures\ndeno task bench --llms \"sonnet@temp=0.0,sonnet@temp=0.3,sonnet@temp=0.7,sonnet@temp=1.0\"\n</code></pre> Temperature Behavior 0.0 Most deterministic, repeatable 0.1-0.3 Low variance, consistent code style 0.5-0.7 Balanced creativity and consistency 0.8-1.0 High variance, more creative <p>For AL code generation, lower temperatures (0.1-0.3) typically produce more consistent results.</p>"},{"location":"guides/model-variants/#token-limits","title":"Token Limits","text":"<p>Control maximum response length:</p> <pre><code># Compare different token limits\ndeno task bench --llms \"opus@tokens=4000,opus@tokens=8000,opus@tokens=16000\"\n</code></pre> <p>Higher token limits allow for:</p> <ul> <li>More complete code</li> <li>Better comments and documentation</li> <li>More detailed error handling</li> </ul> <p>But may also lead to:</p> <ul> <li>Higher costs</li> <li>More verbose unnecessary content</li> <li>Slower response times</li> </ul>"},{"location":"guides/model-variants/#extended-thinking-reasoning","title":"Extended Thinking / Reasoning","text":"<p>For reasoning-capable models, set a thinking budget:</p>"},{"location":"guides/model-variants/#claude-extended-thinking","title":"Claude (Extended Thinking)","text":"<pre><code># Claude with extended thinking\ndeno task bench --llms \"opus@thinking=10000\"\ndeno task bench --llms \"opus@thinking=50000;tokens=20000\"\n</code></pre>"},{"location":"guides/model-variants/#openai-reasoning-effort","title":"OpenAI (Reasoning Effort)","text":"<p>For o1/o3 models, the thinking budget maps to reasoning effort:</p> <pre><code># OpenAI reasoning models\ndeno task bench --llms \"o3@reasoning=5000\"   # Low effort\ndeno task bench --llms \"o3@reasoning=20000\"  # Medium effort\ndeno task bench --llms \"o3@reasoning=50000\"  # High effort\n</code></pre>"},{"location":"guides/model-variants/#comparing-reasoning-levels","title":"Comparing Reasoning Levels","text":"<pre><code>deno task bench \\\n  --llms \"opus@reasoning=10000,opus@reasoning=30000,opus@reasoning=50000,o3@reasoning=20000\"\n</code></pre>"},{"location":"guides/model-variants/#system-prompts","title":"System Prompts","text":"<p>Use named system prompts from configuration:</p>"},{"location":"guides/model-variants/#define-in-configuration","title":"Define in Configuration","text":"<pre><code># .centralgauge.yml\nsystemPrompts:\n  strict-al:\n    content: |\n      You are a strict AL code generator for Business Central.\n      Only output valid AL code without explanations.\n\n  detailed:\n    content: |\n      You are an AL code expert. Generate well-documented code\n      with proper error handling and comments.\n</code></pre>"},{"location":"guides/model-variants/#use-in-benchmarks","title":"Use in Benchmarks","text":"<pre><code>deno task bench --llms \"sonnet@prompt=strict-al,sonnet@prompt=detailed\"\n</code></pre>"},{"location":"guides/model-variants/#variant-profiles","title":"Variant Profiles","text":"<p>Define complete variant configurations as reusable profiles:</p>"},{"location":"guides/model-variants/#define-profiles","title":"Define Profiles","text":"<pre><code># .centralgauge.yml\nvariantProfiles:\n  conservative:\n    description: \"Low temperature, standard tokens\"\n    config:\n      temperature: 0.1\n      maxTokens: 4000\n\n  creative:\n    description: \"Higher temperature, more tokens\"\n    config:\n      temperature: 0.7\n      maxTokens: 8000\n\n  reasoning:\n    description: \"Extended thinking for complex tasks\"\n    config:\n      temperature: 0.2\n      thinkingBudget: 50000\n      maxTokens: 16000\n\n  strict:\n    description: \"Strict output with custom prompt\"\n    config:\n      temperature: 0.1\n      maxTokens: 4000\n      systemPromptName: strict-al\n</code></pre>"},{"location":"guides/model-variants/#use-profiles","title":"Use Profiles","text":"<pre><code># Single profile\ndeno task bench --llms \"opus@profile=conservative\"\n\n# Compare profiles\ndeno task bench --llms \"opus@profile=conservative,opus@profile=creative,opus@profile=reasoning\"\n\n# Mix profiles and inline parameters\ndeno task bench --llms \"opus@profile=conservative,opus@temp=0.5\"\n</code></pre>"},{"location":"guides/model-variants/#variant-identifiers","title":"Variant Identifiers","text":"<p>Each variant gets a unique identifier for results tracking:</p> <pre><code>provider/model@param1=value1;param2=value2\n</code></pre> <p>Examples:</p> <ul> <li><code>anthropic/claude-opus-4-5-20251101@temp=0.5</code></li> <li><code>openai/gpt-4o@temp=0.1;tokens=8000</code></li> <li><code>anthropic/claude-opus-4-5-20251101@profile=reasoning</code></li> </ul> <p>These identifiers appear in results files and reports.</p>"},{"location":"guides/model-variants/#practical-examples","title":"Practical Examples","text":""},{"location":"guides/model-variants/#optimizing-temperature","title":"Optimizing Temperature","text":"<p>Find the best temperature for a model:</p> <pre><code>deno task bench \\\n  --llms \"sonnet@temp=0.1,sonnet@temp=0.2,sonnet@temp=0.3,sonnet@temp=0.4\" \\\n  --tasks \"tasks/**/*.yml\" \\\n  --output results/temperature-sweep\n</code></pre>"},{"location":"guides/model-variants/#comparing-reasoning-depth","title":"Comparing Reasoning Depth","text":"<p>Evaluate thinking budget impact:</p> <pre><code>deno task bench \\\n  --llms \"opus@thinking=0,opus@thinking=10000,opus@thinking=30000,opus@thinking=50000\" \\\n  --tasks \"tasks/hard/*.yml\" \\\n  --output results/reasoning-comparison\n</code></pre>"},{"location":"guides/model-variants/#provider-comparison-at-similar-settings","title":"Provider Comparison at Similar Settings","text":"<p>Compare providers with matched settings:</p> <pre><code>deno task bench \\\n  --llms \"opus@temp=0.1;tokens=8000,gpt-5@temp=0.1;tokens=8000,gemini@temp=0.1;tokens=8000\" \\\n  --tasks \"tasks/**/*.yml\"\n</code></pre>"},{"location":"guides/model-variants/#custom-system-prompt-ab-test","title":"Custom System Prompt A/B Test","text":"<p>Test different prompting strategies:</p> <pre><code>deno task bench \\\n  --llms \"sonnet@prompt=default,sonnet@prompt=strict-al,sonnet@prompt=detailed\" \\\n  --tasks \"tasks/medium/*.yml\"\n</code></pre>"},{"location":"guides/model-variants/#best-practices","title":"Best Practices","text":""},{"location":"guides/model-variants/#start-with-defaults","title":"Start with Defaults","text":"<p>Begin with default settings to establish a baseline:</p> <pre><code>deno task bench --llms sonnet --tasks \"tasks/**/*.yml\"\n</code></pre>"},{"location":"guides/model-variants/#vary-one-parameter-at-a-time","title":"Vary One Parameter at a Time","text":"<p>When optimizing, change only one parameter:</p> <pre><code># Good: isolate temperature effect\n--llms \"opus@temp=0.1,opus@temp=0.3,opus@temp=0.5\"\n\n# Less useful: multiple changes\n--llms \"opus@temp=0.1;tokens=4000,opus@temp=0.5;tokens=8000\"\n</code></pre>"},{"location":"guides/model-variants/#use-profiles-for-reproducibility","title":"Use Profiles for Reproducibility","text":"<p>Define profiles in config for consistent testing:</p> <pre><code>variantProfiles:\n  baseline:\n    config:\n      temperature: 0.1\n      maxTokens: 4000\n</code></pre> <pre><code>deno task bench --llms \"opus@profile=baseline,gpt-5@profile=baseline\"\n</code></pre>"},{"location":"guides/model-variants/#track-results-over-time","title":"Track Results Over Time","text":"<p>Import results to track variant performance:</p> <pre><code>deno run --allow-all cli/centralgauge.ts stats-import results/\ndeno run --allow-all cli/centralgauge.ts stats-compare opus@temp=0.1 opus@temp=0.3\n</code></pre>"},{"location":"guides/model-variants/#next-steps","title":"Next Steps","text":"<ul> <li>Running Benchmarks - Full benchmark guide</li> <li>Configuration - Define system prompts and profiles</li> <li>Understanding Results - Analyze variant comparisons</li> </ul>"},{"location":"guides/running-benchmarks/","title":"Running Benchmarks","text":"<p>CentralGauge supports two benchmark modes: LLM benchmarks (single API calls) and Agent benchmarks (autonomous iterative execution).</p>"},{"location":"guides/running-benchmarks/#llm-benchmarks","title":"LLM Benchmarks","text":"<p>LLM benchmarks evaluate models on their ability to generate correct AL code in a single attempt, with an optional second attempt to fix compilation errors.</p>"},{"location":"guides/running-benchmarks/#basic-usage","title":"Basic Usage","text":"<pre><code>deno task bench --llms &lt;models&gt; --tasks &lt;patterns&gt; [options]\n</code></pre>"},{"location":"guides/running-benchmarks/#specifying-models","title":"Specifying Models","text":""},{"location":"guides/running-benchmarks/#model-aliases","title":"Model Aliases","text":"<p>Use convenient short names:</p> <pre><code>deno task bench --llms sonnet,opus,gpt-5\n</code></pre> Alias Full Model <code>opus</code> claude-4.5-opus <code>sonnet</code> claude-sonnet-4 <code>gpt-5</code> gpt-5.2 <code>gpt-4o</code> gpt-4o <code>o3</code> o3 <code>o1</code> o1 <code>gemini</code> gemini-3-pro-preview"},{"location":"guides/running-benchmarks/#providermodel-format","title":"Provider/Model Format","text":"<p>Explicitly specify provider and model:</p> <pre><code>deno task bench --llms anthropic/claude-sonnet-4-20250514,openai/gpt-4o-2024-08-06\n</code></pre>"},{"location":"guides/running-benchmarks/#model-groups","title":"Model Groups","text":"<p>Use predefined groups:</p> <pre><code># Flagship models from each provider\ndeno task bench --llms flagship\n\n# Best coding models\ndeno task bench --llms coding\n\n# Budget-friendly options\ndeno task bench --llms budget\n</code></pre>"},{"location":"guides/running-benchmarks/#openrouter-models","title":"OpenRouter Models","text":"<p>Access 200+ models through OpenRouter:</p> <pre><code>deno task bench --llms openrouter/anthropic/claude-4.5-opus\ndeno task bench --llms openrouter/google/gemini-3-pro-preview\n</code></pre>"},{"location":"guides/running-benchmarks/#specifying-tasks","title":"Specifying Tasks","text":"<p>Use glob patterns to select tasks:</p> <pre><code># Single task\ndeno task bench --llms sonnet --tasks \"tasks/easy/CG-AL-E001-basic-table.yml\"\n\n# All easy tasks\ndeno task bench --llms sonnet --tasks \"tasks/easy/*.yml\"\n\n# All tasks in any difficulty\ndeno task bench --llms sonnet --tasks \"tasks/**/*.yml\"\n\n# Multiple patterns\ndeno task bench --llms sonnet --tasks \"tasks/easy/*.yml\" \"tasks/medium/*.yml\"\n</code></pre>"},{"location":"guides/running-benchmarks/#execution-options","title":"Execution Options","text":""},{"location":"guides/running-benchmarks/#attempts","title":"Attempts","text":"<p>Control how many attempts each model gets:</p> <pre><code># Single attempt (no retry on failure)\ndeno task bench --llms sonnet --tasks tasks/*.yml --attempts 1\n\n# Two attempts (default)\ndeno task bench --llms sonnet --tasks tasks/*.yml --attempts 2\n</code></pre>"},{"location":"guides/running-benchmarks/#temperature","title":"Temperature","text":"<p>Adjust model creativity:</p> <pre><code># Lower temperature = more deterministic\ndeno task bench --llms sonnet --tasks tasks/*.yml --temperature 0.1\n\n# Higher temperature = more varied\ndeno task bench --llms sonnet --tasks tasks/*.yml --temperature 0.7\n</code></pre>"},{"location":"guides/running-benchmarks/#token-limits","title":"Token Limits","text":"<p>Set maximum response length:</p> <pre><code>deno task bench --llms sonnet --tasks tasks/*.yml --max-tokens 8000\n</code></pre>"},{"location":"guides/running-benchmarks/#concurrency","title":"Concurrency","text":"<p>Control parallel execution:</p> <pre><code># Limit concurrent LLM calls\ndeno task bench --llms sonnet --tasks tasks/*.yml --max-concurrency 5\n\n# Disable parallelism entirely\ndeno task bench --llms sonnet --tasks tasks/*.yml --sequential\n</code></pre>"},{"location":"guides/running-benchmarks/#output-options","title":"Output Options","text":""},{"location":"guides/running-benchmarks/#output-directory","title":"Output Directory","text":"<p>Specify where results are saved:</p> <pre><code>deno task bench --llms sonnet --tasks tasks/*.yml --output my-results/\n</code></pre>"},{"location":"guides/running-benchmarks/#output-formats","title":"Output Formats","text":"<p>Choose display format:</p> <pre><code># Verbose (default) - full details\ndeno task bench --llms sonnet --format verbose\n\n# Leaderboard - ranked table\ndeno task bench --llms sonnet --format leaderboard\n\n# Scorecard - compact summary\ndeno task bench --llms sonnet --format scorecard\n\n# JSON - machine readable\ndeno task bench --llms sonnet --format json\n</code></pre>"},{"location":"guides/running-benchmarks/#debug-logging","title":"Debug Logging","text":"<p>Capture detailed execution logs:</p> <pre><code># Enable debug mode\ndeno task bench --llms sonnet --tasks tasks/*.yml --debug\n\n# Verbose debug with raw responses\ndeno task bench --llms sonnet --tasks tasks/*.yml --debug-level verbose\n\n# Custom debug output directory\ndeno task bench --llms sonnet --tasks tasks/*.yml --debug --debug-output ./my-debug\n</code></pre>"},{"location":"guides/running-benchmarks/#tui-mode","title":"TUI Mode","text":"<p>Enable the terminal UI for real-time progress visualization:</p> <pre><code>deno task bench --llms sonnet --tasks tasks/*.yml --tui\n</code></pre> <p>The TUI shows:</p> <ul> <li>Progress bar</li> <li>Active LLM calls</li> <li>Compile queue status</li> <li>Pass/fail rates per model</li> <li>Error log</li> </ul>"},{"location":"guides/running-benchmarks/#retry-mode","title":"Retry Mode","text":"<p>Resume a failed benchmark run:</p> <pre><code># Initial run\ndeno task bench --llms sonnet,gpt-4o --tasks tasks/**/*.yml -o results/run1\n\n# Retry missing combinations\ndeno task bench --llms sonnet,gpt-4o --retry results/run1/benchmark-results-*.json\n</code></pre>"},{"location":"guides/running-benchmarks/#agent-benchmarks","title":"Agent Benchmarks","text":"<p>Agent benchmarks evaluate autonomous agents (like Claude Code) that can iteratively generate, compile, and fix code until success.</p>"},{"location":"guides/running-benchmarks/#basic-usage_1","title":"Basic Usage","text":"<pre><code>deno task bench --agents &lt;agent-ids&gt; --tasks &lt;patterns&gt; --container &lt;name&gt;\n</code></pre>"},{"location":"guides/running-benchmarks/#specifying-agents","title":"Specifying Agents","text":"<p>Agent configurations are defined in <code>agents/*.yml</code>:</p> <pre><code># Single agent\ndeno task bench --agents default --tasks tasks/easy/*.yml\n\n# Multiple agents for comparison\ndeno task bench --agents default,minimal --tasks tasks/easy/*.yml\n</code></pre>"},{"location":"guides/running-benchmarks/#agent-configuration","title":"Agent Configuration","text":"<p>Create custom agent configurations in <code>agents/</code>:</p> <pre><code># agents/my-agent.yml\nid: my-agent\nname: \"My Custom Agent\"\ndescription: \"Optimized for BC development\"\nmodel: claude-opus-4-5-20251101\nmaxTurns: 100\nmaxTokens: 500000\n\nallowedTools:\n  - Read\n  - Write\n  - Edit\n  - Glob\n  - Grep\n  - Bash\n  - Skill\n\nlimits:\n  maxCompileAttempts: 10\n  timeoutMs: 180000\n</code></pre>"},{"location":"guides/running-benchmarks/#sandbox-mode","title":"Sandbox Mode","text":"<p>Run agents in isolated Windows containers:</p> <pre><code>deno task bench \\\n  --agents default \\\n  --tasks tasks/easy/*.yml \\\n  --container Cronus27 \\\n  --sandbox\n</code></pre> <p>Sandbox mode:</p> <ul> <li>Isolates agent execution</li> <li>Provides MCP tools via HTTP</li> <li>Prevents interference between runs</li> <li>Requires Docker with Windows containers</li> </ul>"},{"location":"guides/running-benchmarks/#agent-options","title":"Agent Options","text":"<pre><code># Enable debug output\ndeno task bench --agents default --tasks tasks/*.yml --debug\n\n# Show detailed failure output\ndeno task bench --agents default --tasks tasks/*.yml --verbose\n\n# Enable streaming\ndeno task bench --agents default --tasks tasks/*.yml --stream\n</code></pre>"},{"location":"guides/running-benchmarks/#understanding-results","title":"Understanding Results","text":""},{"location":"guides/running-benchmarks/#pass-rates","title":"Pass Rates","text":"<ul> <li>Pass Rate 1 (PR1): Percentage passing on first attempt</li> <li>Pass Rate 2 (PR2): Percentage passing on second attempt</li> <li>Overall Pass Rate: Total percentage passing within attempt limit</li> </ul>"},{"location":"guides/running-benchmarks/#scoring","title":"Scoring","text":"<p>Each task execution receives a score from 0.0 to 1.0:</p> Score Meaning 1.0 Compilation successful, all tests pass 0.7-0.9 Compilation successful, some tests pass 0.3-0.5 Compilation successful, no tests 0.0 Compilation failed"},{"location":"guides/running-benchmarks/#cost-tracking","title":"Cost Tracking","text":"<p>Results include estimated API costs:</p> <pre><code>{\n  \"stats\": {\n    \"totalTokens\": 45678,\n    \"totalCost\": 0.2345,\n    \"perModel\": {\n      \"anthropic/claude-sonnet-4-20250514\": {\n        \"cost\": 0.1234,\n        \"tokens\": 23456\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"guides/running-benchmarks/#prompt-customization","title":"Prompt Customization","text":"<p>Override prompts at runtime:</p> <pre><code># Custom system prompt\ndeno task bench --llms sonnet --system-prompt \"You are an AL expert...\"\n\n# Add prefix/suffix to prompts\ndeno task bench --llms sonnet --prompt-prefix \"Important: \" --prompt-suffix \" Be concise.\"\n\n# Apply only to specific stage\ndeno task bench --llms sonnet --system-prompt \"...\" --prompt-stage generation\n</code></pre>"},{"location":"guides/running-benchmarks/#knowledge-bank-injection","title":"Knowledge Bank Injection","text":"<p>The knowledge bank feature allows injecting markdown files into the system prompt to provide model-specific guidance. This enables comparing model performance with and without guidance (e.g., \"gpt-5\" vs \"gpt-5 (guided)\").</p>"},{"location":"guides/running-benchmarks/#basic-usage_2","title":"Basic Usage","text":"<pre><code># Single knowledge file\ndeno task bench --llms gpt-5 --knowledge model-shortcomings/gpt-5.rules.md\n\n# Multiple files\ndeno task bench --llms gpt-5 --knowledge rules1.md rules2.md tips.md\n\n# Directory of .md files (loaded alphabetically)\ndeno task bench --llms gpt-5 --knowledge-dir .claude/rules/\n</code></pre>"},{"location":"guides/running-benchmarks/#run-labeling","title":"Run Labeling","text":"<p>When knowledge files are provided, the run is automatically labeled with \"(guided)\" suffix:</p> <pre><code># Auto-labeled as \"gpt-5 (guided)\"\ndeno task bench --llms gpt-5 --knowledge rules.md\n\n# Custom label override\ndeno task bench --llms gpt-5 --knowledge rules.md --run-label \"gpt-5-optimized\"\n</code></pre>"},{"location":"guides/running-benchmarks/#knowledge-bank-format","title":"Knowledge Bank Format","text":"<p>Knowledge content is formatted and prepended to the system prompt:</p> <pre><code># Knowledge Bank\n\nThe following guidance should inform your code generation:\n\n---\n## filename.md\n{ content of filename.md }\n---\n\n## another-file.md\n\n{content of another-file.md}\n\n# End Knowledge Bank\n</code></pre>"},{"location":"guides/running-benchmarks/#workflow-rules-to-knowledge","title":"Workflow: Rules to Knowledge","text":"<p>This feature integrates with the <code>rules</code> command for a complete improvement cycle:</p> <pre><code># Step 1: Run baseline benchmark\ndeno task bench --llms gpt-5 --tasks \"tasks/**/*.yml\" -o results/baseline\n\n# Step 2: Analyze failures and generate shortcomings JSON\n# (Done automatically during benchmark or via verify command)\n\n# Step 3: Generate rules from shortcomings\ndeno run --allow-all cli/centralgauge.ts rules model-shortcomings/gpt-5.json\n\n# Step 4: Run guided benchmark with generated rules\ndeno task bench --llms gpt-5 --knowledge model-shortcomings/gpt-5.rules.md \\\n  --tasks \"tasks/**/*.yml\" -o results/guided\n\n# Step 5: Compare results to measure improvement\n</code></pre>"},{"location":"guides/running-benchmarks/#use-cases","title":"Use Cases","text":"Use Case Command Test model-specific rules <code>--knowledge model-shortcomings/gpt-5.rules.md</code> Test Claude Code rules <code>--knowledge-dir .claude/rules/</code> A/B test guidance Run with/without <code>--knowledge</code>, compare reports Custom prompting strategies <code>--knowledge strategy.md --run-label \"strategy-v2\"</code>"},{"location":"guides/running-benchmarks/#historical-stats","title":"Historical Stats","text":"<p>Track benchmark results over time:</p> <pre><code># Import results to database\ndeno run --allow-all cli/centralgauge.ts stats-import results/\n\n# View recent runs\ndeno run --allow-all cli/centralgauge.ts stats-runs\n\n# Compare models\ndeno run --allow-all cli/centralgauge.ts stats-compare opus gpt-5\n\n# Detect regressions\ndeno run --allow-all cli/centralgauge.ts stats-regression --threshold 10\n</code></pre>"},{"location":"guides/running-benchmarks/#next-steps","title":"Next Steps","text":"<ul> <li>Model Variants - Compare same model with different settings</li> <li>Configuration - Customize CentralGauge</li> <li>Understanding Results - Deep dive into output</li> </ul>"},{"location":"guides/understanding-results/","title":"Understanding Results","text":"<p>This guide explains how to interpret CentralGauge benchmark results, including metrics, scoring, and analysis techniques.</p>"},{"location":"guides/understanding-results/#result-files","title":"Result Files","text":"<p>After a benchmark run, CentralGauge produces several output files:</p> <pre><code>results/\n\u251c\u2500\u2500 benchmark-results-1704067200000.json    # Detailed results\n\u251c\u2500\u2500 scores-1704067200000.txt                # Quick score summary\n\u2514\u2500\u2500 centralgauge.db                         # Historical database (optional)\n</code></pre>"},{"location":"guides/understanding-results/#json-results-structure","title":"JSON Results Structure","text":"<p>The main results file contains:</p> <pre><code>{\n  \"results\": [...],           // Individual task results\n  \"stats\": {...},             // Aggregate statistics\n  \"comparisons\": [...],       // Task-by-task model comparisons\n  \"hashInfo\": {...}           // Task set identification\n}\n</code></pre>"},{"location":"guides/understanding-results/#individual-results","title":"Individual Results","text":"<p>Each result entry contains:</p> <pre><code>{\n  \"taskId\": \"CG-AL-E001\",\n  \"executionId\": \"exec-123\",\n  \"success\": true,\n  \"finalScore\": 1.0,\n  \"passedAttemptNumber\": 1,\n  \"totalTokensUsed\": 1234,\n  \"totalCost\": 0.0056,\n  \"totalDuration\": 12345,\n  \"context\": {\n    \"llmProvider\": \"anthropic\",\n    \"llmModel\": \"claude-sonnet-4-20250514\",\n    \"variantId\": \"anthropic/claude-sonnet-4-20250514\"\n  },\n  \"attempts\": [...]\n}\n</code></pre>"},{"location":"guides/understanding-results/#attempt-details","title":"Attempt Details","text":"<p>Each attempt records:</p> <pre><code>{\n  \"attemptNumber\": 1,\n  \"success\": true,\n  \"score\": 1.0,\n  \"llmResponse\": {\n    \"content\": \"...\",\n    \"usage\": {\n      \"promptTokens\": 500,\n      \"completionTokens\": 734,\n      \"totalTokens\": 1234,\n      \"estimatedCost\": 0.0056\n    },\n    \"duration\": 5000\n  },\n  \"compilationResult\": {\n    \"success\": true,\n    \"errors\": [],\n    \"warnings\": [],\n    \"duration\": 3000\n  },\n  \"testResult\": {\n    \"success\": true,\n    \"totalTests\": 4,\n    \"passedTests\": 4,\n    \"failedTests\": 0,\n    \"duration\": 2000\n  }\n}\n</code></pre>"},{"location":"guides/understanding-results/#scoring-system","title":"Scoring System","text":""},{"location":"guides/understanding-results/#score-calculation","title":"Score Calculation","text":"<p>Tasks are scored on a 0.0 to 1.0 scale:</p> Outcome Score Description Compilation failed 0.0 Code did not compile Compilation only 0.5 Compiled but no tests ran Partial tests 0.5-0.9 Some tests passed All tests pass 1.0 Full success"},{"location":"guides/understanding-results/#attempt-weighting","title":"Attempt Weighting","text":"<p>When a task passes on a later attempt, the score may be adjusted:</p> <ul> <li>Pass on attempt 1: Full score</li> <li>Pass on attempt 2: Score reflects need for retry</li> </ul>"},{"location":"guides/understanding-results/#final-score","title":"Final Score","text":"<p>The <code>finalScore</code> reflects the best attempt outcome, while <code>passedAttemptNumber</code> indicates which attempt succeeded (0 if none).</p>"},{"location":"guides/understanding-results/#key-metrics","title":"Key Metrics","text":""},{"location":"guides/understanding-results/#pass-rates","title":"Pass Rates","text":"<pre><code>{\n  \"overallPassRate\": 0.85, // 85% of tasks passed\n  \"passRate1\": 0.70, // 70% passed on first attempt\n  \"passRate2\": 0.15, // 15% passed on second attempt (after failing first)\n  \"passNum1\": 7, // Count passed on attempt 1\n  \"passNum2\": 2 // Count passed on attempt 2\n}\n</code></pre>"},{"location":"guides/understanding-results/#token-usage","title":"Token Usage","text":"<pre><code>{\n  \"totalTokens\": 45678,\n  \"promptTokens\": 23456,\n  \"completionTokens\": 22222\n}\n</code></pre>"},{"location":"guides/understanding-results/#cost","title":"Cost","text":"<pre><code>{\n  \"totalCost\": 0.2345 // USD\n}\n</code></pre>"},{"location":"guides/understanding-results/#timing","title":"Timing","text":"<pre><code>{\n  \"totalDuration\": 120000, // Total wall-clock time (ms)\n  \"totalLLMDuration\": 80000, // Time in LLM calls\n  \"totalCompileDuration\": 25000, // Time compiling\n  \"totalTestDuration\": 15000, // Time running tests\n  \"secondsPerTask\": 12.5 // Average per task\n}\n</code></pre>"},{"location":"guides/understanding-results/#per-model-statistics","title":"Per-Model Statistics","text":"<p>The <code>perModel</code> map contains statistics for each model variant:</p> <pre><code>{\n  \"perModel\": {\n    \"anthropic/claude-sonnet-4-20250514\": {\n      \"tasksPassed\": 8,\n      \"tasksFailed\": 2,\n      \"passedOnAttempt1\": 7,\n      \"passedOnAttempt2\": 1,\n      \"avgScore\": 0.85,\n      \"avgAttempts\": 1.2,\n      \"tokens\": 12345,\n      \"cost\": 0.0567\n    },\n    \"openai/gpt-4o\": {\n      \"tasksPassed\": 7,\n      \"tasksFailed\": 3,\n      ...\n    }\n  }\n}\n</code></pre>"},{"location":"guides/understanding-results/#task-comparisons","title":"Task Comparisons","text":"<p>The <code>comparisons</code> array shows head-to-head results:</p> <pre><code>{\n  \"comparisons\": [\n    {\n      \"taskId\": \"CG-AL-E001\",\n      \"winner\": \"anthropic/claude-sonnet-4-20250514\",\n      \"bestScore\": 1.0,\n      \"passingModels\": [\"anthropic/claude-sonnet-4-20250514\", \"openai/gpt-4o\"],\n      \"results\": {\n        \"anthropic/claude-sonnet-4-20250514\": {\n          \"score\": 1.0,\n          \"attempt\": 1,\n          \"duration\": 5000\n        },\n        \"openai/gpt-4o\": {\n          \"score\": 1.0,\n          \"attempt\": 2,\n          \"duration\": 8000\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"guides/understanding-results/#winner-determination","title":"Winner Determination","text":"<ol> <li>Higher score wins</li> <li>If scores tie, earlier attempt wins</li> <li>If attempts tie, faster duration wins</li> <li>If all equal, result is \"TIE\"</li> </ol>"},{"location":"guides/understanding-results/#task-set-hash","title":"Task Set Hash","text":"<p>The <code>hashInfo</code> helps identify comparable runs:</p> <pre><code>{\n  \"hashInfo\": {\n    \"taskSetHash\": \"c71a992f\", // Unique hash of all tasks\n    \"testAppManifestHash\": \"abc123\", // Hash of test app.json\n    \"totalFilesHashed\": 25, // Number of files included\n    \"computedAt\": \"2025-01-05T10:00:00Z\"\n  }\n}\n</code></pre> <p>Runs with the same <code>taskSetHash</code> tested identical task sets and are directly comparable.</p>"},{"location":"guides/understanding-results/#score-file-format","title":"Score File Format","text":"<p>The quick score summary (<code>scores-*.txt</code>) provides:</p> <pre><code># CentralGauge Benchmark Scores\n# 2025-01-05T10:30:00.000Z\n\ntasks: 10\nmodels: anthropic/claude-sonnet-4-20250514, openai/gpt-4o\nattempts: 2\n\n# Aggregate Stats\npass_rate_1: 70.0%\npass_rate_2: 85.0%\navg_score: 0.82\ntotal_cost: $0.2345\n\n# Per-Model Scores\nanthropic/claude-sonnet-4-20250514: pr1=80.0% pr2=90.0% score=0.88 cost=$0.1234\nopenai/gpt-4o: pr1=60.0% pr2=80.0% score=0.76 cost=$0.1111\n</code></pre>"},{"location":"guides/understanding-results/#html-reports","title":"HTML Reports","text":"<p>Generate visual reports:</p> <pre><code>deno task report results/ --html --output reports/\n</code></pre> <p>Reports include:</p> <ul> <li>Model comparison charts</li> <li>Task-by-task breakdown</li> <li>Pass rate visualizations</li> <li>Cost analysis</li> <li>Score distributions</li> </ul>"},{"location":"guides/understanding-results/#analyzing-results","title":"Analyzing Results","text":""},{"location":"guides/understanding-results/#identify-weak-areas","title":"Identify Weak Areas","text":"<p>Find tasks where models struggle:</p> <pre><code>cat results/benchmark-results-*.json | jq '[.results[] | select(.success == false)] | group_by(.taskId) | map({task: .[0].taskId, failures: length})'\n</code></pre>"},{"location":"guides/understanding-results/#compare-model-strengths","title":"Compare Model Strengths","text":"<p>See which models excel at specific task types:</p> <pre><code>cat results/benchmark-results-*.json | jq '.comparisons | group_by(.winner) | map({winner: .[0].winner, wins: length})'\n</code></pre>"},{"location":"guides/understanding-results/#track-cost-efficiency","title":"Track Cost Efficiency","text":"<p>Compare cost per successful task:</p> <pre><code>cat results/benchmark-results-*.json | jq '.stats.perModel | to_entries | map({model: .key, costPerPass: (.value.cost / .value.tasksPassed)})'\n</code></pre>"},{"location":"guides/understanding-results/#historical-analysis","title":"Historical Analysis","text":"<p>Use the stats database for long-term analysis:</p>"},{"location":"guides/understanding-results/#import-results","title":"Import Results","text":"<pre><code>deno run --allow-all cli/centralgauge.ts stats-import results/\n</code></pre>"},{"location":"guides/understanding-results/#view-run-history","title":"View Run History","text":"<pre><code>deno run --allow-all cli/centralgauge.ts stats-runs\n</code></pre>"},{"location":"guides/understanding-results/#compare-models-over-time","title":"Compare Models Over Time","text":"<pre><code>deno run --allow-all cli/centralgauge.ts stats-compare opus gpt-5\n</code></pre>"},{"location":"guides/understanding-results/#detect-regressions","title":"Detect Regressions","text":"<pre><code>deno run --allow-all cli/centralgauge.ts stats-regression --threshold 10\n</code></pre>"},{"location":"guides/understanding-results/#troubleshooting-results","title":"Troubleshooting Results","text":""},{"location":"guides/understanding-results/#all-tasks-failed","title":"All Tasks Failed","text":"<p>Check:</p> <ol> <li>Container is running: <code>docker ps</code></li> <li>API keys are set: <code>source .env &amp;&amp; echo $ANTHROPIC_API_KEY</code></li> <li>Debug logs: Run with <code>--debug</code> flag</li> </ol>"},{"location":"guides/understanding-results/#inconsistent-results","title":"Inconsistent Results","text":"<p>If the same model produces different results:</p> <ol> <li>Check temperature setting (0.0 for deterministic)</li> <li>Verify task set hash matches</li> <li>Check for rate limiting or timeouts</li> </ol>"},{"location":"guides/understanding-results/#missing-cost-data","title":"Missing Cost Data","text":"<p>Cost estimates require provider pricing data. Mock provider always shows $0.00.</p>"},{"location":"guides/understanding-results/#next-steps","title":"Next Steps","text":"<ul> <li>Running Benchmarks - Generate results</li> <li>Configuration - Customize output</li> <li>CLI Reference - All analysis commands</li> </ul>"},{"location":"tasks/categories/","title":"Task Categories","text":"<p>Tasks are categorized by difficulty: Easy, Medium, and Hard. This guide explains what makes a task fit each category and provides guidelines for creating new tasks.</p>"},{"location":"tasks/categories/#easy-tasks-cg-al-e","title":"Easy Tasks (CG-AL-E###)","text":"<p>Easy tasks test basic AL syntax and simple object creation. A model with foundational AL knowledge should pass these.</p>"},{"location":"tasks/categories/#characteristics","title":"Characteristics","text":"<ul> <li>Single object creation</li> <li>Standard patterns with minimal complexity</li> <li>Basic syntax knowledge required</li> <li>Few or no edge cases</li> <li>Clear, unambiguous requirements</li> </ul>"},{"location":"tasks/categories/#examples","title":"Examples","text":"Task Type Description Simple table 3-4 fields with basic types Basic enum 3-5 values with captions Simple page Card or List for existing table Basic codeunit One procedure with simple logic Interface definition 2-3 method signatures Simple extension Add 1-2 fields to existing object"},{"location":"tasks/categories/#sample-easy-task","title":"Sample Easy Task","text":"<pre><code>id: CG-AL-E001\ndescription: &gt;-\n  Create a simple AL table called \"Product Category\" with ID 70000.\n\n  Fields:\n  - Code (Code[20], primary key)\n  - Description (Text[100])\n  - Active (Boolean, default true)\n  - Created Date (Date)\n\n  Include proper captions and data classification.\n</code></pre>"},{"location":"tasks/categories/#what-makes-it-easy","title":"What Makes It Easy","text":"<ul> <li>Single object (one table)</li> <li>Standard field types</li> <li>No complex validation</li> <li>No triggers beyond defaults</li> <li>No relationships to other objects</li> </ul>"},{"location":"tasks/categories/#medium-tasks-cg-al-m","title":"Medium Tasks (CG-AL-M###)","text":"<p>Medium tasks require understanding of multiple AL concepts and often involve object interactions.</p>"},{"location":"tasks/categories/#characteristics_1","title":"Characteristics","text":"<ul> <li>Multiple related objects</li> <li>Complex validation logic</li> <li>Triggers with business rules</li> <li>Error handling requirements</li> <li>Cross-object interactions</li> <li>API pages with CRUD operations</li> </ul>"},{"location":"tasks/categories/#examples_1","title":"Examples","text":"Task Type Description API page Full CRUD with proper configuration Multi-object Table + Page + Codeunit together Interface implementation Implement a defined interface Complex validation Multiple triggers with rules State machines Status transitions with validation Integration HTTP calls, JSON handling"},{"location":"tasks/categories/#sample-medium-task","title":"Sample Medium Task","text":"<pre><code>id: CG-AL-M001\ndescription: &gt;-\n  Create an API page called \"Customer API\" with ID 70500.\n\n  Source: Customer table\n  Entity: customer\n  EntitySet: customers\n  API Version: v2.0\n\n  Expose fields:\n  - no (Code field)\n  - name\n  - address\n  - city\n  - country\n\n  Include proper OData settings for CRUD operations.\n  Handle InsertAllowed, ModifyAllowed, DeleteAllowed.\n</code></pre>"},{"location":"tasks/categories/#what-makes-it-medium","title":"What Makes It Medium","text":"<ul> <li>Multiple configuration options</li> <li>Must understand API page conventions</li> <li>Requires OData knowledge</li> <li>Multiple fields with proper mapping</li> <li>CRUD operation handling</li> </ul>"},{"location":"tasks/categories/#hard-tasks-cg-al-h","title":"Hard Tasks (CG-AL-H###)","text":"<p>Hard tasks test advanced AL patterns, edge cases, and deep platform knowledge.</p>"},{"location":"tasks/categories/#characteristics_2","title":"Characteristics","text":"<ul> <li>Complex conditional logic with many branches</li> <li>Multiple interacting rules</li> <li>Precise mathematical calculations</li> <li>Boundary condition handling</li> <li>Country/region-specific logic</li> <li>Performance-sensitive operations</li> <li>Advanced patterns (DI, events, etc.)</li> <li>Platform-specific quirks</li> </ul>"},{"location":"tasks/categories/#examples_2","title":"Examples","text":"Task Type Description Tax calculator Tiered rates by country/product Currency conversion Rounding rules and edge cases FlowField/CalcFormula Complex aggregations RecordRef operations Dynamic field access Event patterns Integration and business events Enum ordinal traps Testing AL-specific gotchas"},{"location":"tasks/categories/#sample-hard-task","title":"Sample Hard Task","text":"<pre><code>id: CG-AL-H001\ndescription: &gt;-\n  Create a codeunit called \"Tax Calculator\" with ID 70100.\n\n  Implement:\n  CalculateTax(Amount: Decimal; CountryCode: Code[2]; ProductType: Enum \"CG Product Type\"): Decimal\n\n  Tax rules by country:\n  - US: 0% for amounts &lt; 100, 7% for 100-999, 10% for &gt;= 1000\n  - CA: Flat 13%\n  - DE: 19% standard, 7% for Food, 0% for Books\n  - UK: 20% standard, 0% for Food and Books\n  - Other: 0%\n\n  Return the calculated tax amount (not the total).\n  Negative amounts should return 0.\n</code></pre>"},{"location":"tasks/categories/#what-makes-it-hard","title":"What Makes It Hard","text":"<ul> <li>Multiple country-specific rules</li> <li>Product type variations</li> <li>Tiered rate thresholds</li> <li>Boundary conditions</li> <li>Edge case handling (negative amounts)</li> <li>Many code paths to test</li> </ul>"},{"location":"tasks/categories/#al-specific-knowledge-tests","title":"AL-Specific Knowledge Tests","text":"<p>Some tasks specifically test whether models understand AL quirks:</p>"},{"location":"tasks/categories/#interface-ids","title":"Interface IDs","text":"<pre><code># Tests that model knows interfaces don't have numeric IDs\ndescription: &gt;-\n  Create an interface called \"Payment Processor\"...\n</code></pre> <p>If model adds <code>interface 70000 \"Payment Processor\"</code>, it fails.</p>"},{"location":"tasks/categories/#flowfield-syntax","title":"FlowField Syntax","text":"<pre><code># Tests CalcFormula knowledge\ndescription: &gt;-\n  Create a FlowField \"Total Amount\" using CalcFormula = sum(...)\n</code></pre>"},{"location":"tasks/categories/#enum-ordinal-traps","title":"Enum Ordinal Traps","text":"<pre><code># Tests understanding of enum value assignment\ndescription: &gt;-\n  Create an enum where values are NOT consecutive...\n</code></pre>"},{"location":"tasks/categories/#record-modification-patterns","title":"Record Modification Patterns","text":"<pre><code># Tests Modify vs direct assignment\ndescription: &gt;-\n  Implement OnValidate trigger that updates related fields...\n</code></pre>"},{"location":"tasks/categories/#difficulty-assessment-criteria","title":"Difficulty Assessment Criteria","text":"<p>When creating a new task, score it on these factors:</p> Factor Easy Medium Hard Object count 1 2-3 3+ Code paths 1-2 3-5 6+ Edge cases 0-1 2-4 5+ AL concepts Basic Intermediate Advanced BC knowledge Minimal Moderate Deep Business logic Simple Moderate Complex"},{"location":"tasks/categories/#scoring-guide","title":"Scoring Guide","text":"<ul> <li>Easy: Score 1 in most categories</li> <li>Medium: Score 2-3 in most categories</li> <li>Hard: Score 3+ in most categories</li> </ul>"},{"location":"tasks/categories/#creating-balanced-task-sets","title":"Creating Balanced Task Sets","text":"<p>A good benchmark should include:</p>"},{"location":"tasks/categories/#breadth-object-types","title":"Breadth (Object Types)","text":"<ul> <li>Tables</li> <li>Pages (Card, List, API)</li> <li>Codeunits</li> <li>Reports</li> <li>Enums</li> <li>Interfaces</li> <li>Extensions</li> <li>XMLports</li> <li>Queries</li> </ul>"},{"location":"tasks/categories/#depth-difficulty-spread","title":"Depth (Difficulty Spread)","text":"Difficulty Percentage Easy 30-40% Medium 40-50% Hard 20-30%"},{"location":"tasks/categories/#coverage-al-concepts","title":"Coverage (AL Concepts)","text":"<ul> <li>Field types and properties</li> <li>Keys and indexes</li> <li>Triggers (OnInsert, OnValidate, etc.)</li> <li>FlowFields and CalcFormulas</li> <li>TableRelations</li> <li>Page controls and actions</li> <li>Report layouts</li> <li>Error handling</li> <li>Events and subscribers</li> </ul>"},{"location":"tasks/categories/#avoiding-common-mistakes","title":"Avoiding Common Mistakes","text":""},{"location":"tasks/categories/#too-much-guidance","title":"Too Much Guidance","text":"<pre><code># BAD - Tells model what to do\ndescription: &gt;-\n  Create an interface (note: interfaces don't have IDs in AL)...\n\n# GOOD - Tests model's knowledge\ndescription: &gt;-\n  Create an interface called \"Payment Processor\"...\n</code></pre>"},{"location":"tasks/categories/#ambiguous-requirements","title":"Ambiguous Requirements","text":"<pre><code># BAD - Unclear what fields to include\ndescription: &gt;-\n  Create a customer table with some fields...\n\n# GOOD - Specific requirements\ndescription: &gt;-\n  Create a customer table with:\n  - No. (Code[20], primary key)\n  - Name (Text[100])\n</code></pre>"},{"location":"tasks/categories/#untestable-requirements","title":"Untestable Requirements","text":"<pre><code># BAD - Subjective\ndescription: &gt;-\n  Create a well-structured page...\n\n# GOOD - Testable\ndescription: &gt;-\n  Create a page with fields in a \"General\" group...\n</code></pre>"},{"location":"tasks/categories/#next-steps","title":"Next Steps","text":"<ul> <li>Task Format - YAML structure</li> <li>Writing Tests - Create test codeunits</li> <li>Running Benchmarks - Execute benchmarks</li> </ul>"},{"location":"tasks/task-creation-prompt/","title":"CentralGauge Task Creation Guide","text":"<p>You are being asked to create benchmark tasks for CentralGauge, an open-source benchmark for evaluating LLMs on AL (Application Language) code generation for Microsoft Dynamics 365 Business Central.</p>"},{"location":"tasks/task-creation-prompt/#your-goal","title":"Your Goal","text":"<p>Create challenging but fair benchmark tasks that test whether LLMs truly understand AL syntax, semantics, and Business Central conventions - not just pattern matching.</p>"},{"location":"tasks/task-creation-prompt/#what-is-al","title":"What is AL?","text":"<p>AL (Application Language) is the programming language for Microsoft Dynamics 365 Business Central. It's used to create:</p> <ul> <li>Tables - Data storage with fields, keys, triggers, and relations</li> <li>Pages - User interfaces (Cards, Lists, API pages)</li> <li>Codeunits - Business logic containers</li> <li>Reports - Data extraction and presentation</li> <li>Enums - Type-safe option values</li> <li>Interfaces - Contract definitions for polymorphism</li> <li>Table Extensions - Extend existing tables with new fields</li> <li>Page Extensions - Extend existing pages with new controls/actions</li> <li>XMLports - Data import/export</li> <li>Queries - SQL-like data retrieval</li> </ul>"},{"location":"tasks/task-creation-prompt/#task-yaml-format","title":"Task YAML Format","text":"<p>Each task is defined in a <code>.yml</code> file with this structure:</p> <pre><code>id: CG-AL-XXXX # Unique ID (E=Easy, M=Medium, H=Hard)\nprompt_template: code-gen.md # Always use this\nfix_template: bugfix.md # Always use this\nmax_attempts: 2 # Always 2 (first attempt + one retry)\ndescription: &gt;-\n  Clear description of what to build.\n  Include specific requirements:\n  - Object names and IDs\n  - Field names, types, and constraints\n  - Procedure signatures\n  - Expected behaviors\n  - Error messages (exact text if validation is tested)\nexpected:\n  compile: true\n  testApp: tests/al/{difficulty}/CG-AL-XXXX.Test.al\nmetrics:\n  - compile_pass\n  - tests_pass\n  - pass_attempt\n</code></pre>"},{"location":"tasks/task-creation-prompt/#id-format","title":"ID Format","text":"<ul> <li><code>CG-AL-E###</code> - Easy tasks (001-999)</li> <li><code>CG-AL-M###</code> - Medium tasks (001-999)</li> <li><code>CG-AL-H###</code> - Hard tasks (001-999)</li> </ul>"},{"location":"tasks/task-creation-prompt/#file-naming","title":"File Naming","text":"<ul> <li>Task YAML: <code>tasks/{difficulty}/CG-AL-{ID}-{short-name}.yml</code></li> <li>Test file: <code>tests/al/{difficulty}/CG-AL-{ID}.Test.al</code></li> <li>Helper files: <code>tests/al/{difficulty}/CG-AL-{ID}.{HelperName}.al</code></li> </ul>"},{"location":"tasks/task-creation-prompt/#test-file-format","title":"Test File Format","text":"<p>Tests are AL codeunits that verify the LLM's generated code works correctly.</p>"},{"location":"tasks/task-creation-prompt/#basic-structure","title":"Basic Structure","text":"<pre><code>codeunit 80XXX \"CG-AL-XXXX Test\"\n{\n    Subtype = Test;\n    TestPermissions = Disabled;\n\n    var\n        Assert: Codeunit Assert;\n        LibraryRandom: Codeunit \"Library - Random\";\n\n    [Test]\n    procedure TestName()\n    var\n        // Variables\n    begin\n        // [SCENARIO] What we're testing\n        // [GIVEN] Initial conditions\n        // [WHEN] Action taken\n        // [THEN] Expected result\n\n        // Actual test code with assertions\n    end;\n}\n</code></pre>"},{"location":"tasks/task-creation-prompt/#test-codeunit-ids","title":"Test Codeunit IDs","text":"<ul> <li>Easy tests: 80001-80099</li> <li>Medium tests: 80100-80199</li> <li>Hard tests: 80200-80299</li> </ul>"},{"location":"tasks/task-creation-prompt/#helper-object-ids","title":"Helper Object IDs","text":"<ul> <li>Mock codeunits/enums: 70090-70099</li> </ul>"},{"location":"tasks/task-creation-prompt/#helper-files","title":"Helper Files","text":"<p>Some tasks require helper objects that are provided to the LLM (not generated by it).</p>"},{"location":"tasks/task-creation-prompt/#mock-implementations-for-interface-tests","title":"Mock Implementations (for interface tests)","text":"<pre><code>codeunit 70096 \"CG-AL-E008 Mock Processor\" implements \"Payment Processor\"\n{\n    procedure ProcessPayment(Amount: Decimal; PaymentMethod: Text): Boolean\n    begin\n        exit(Amount &gt; 0);  // Simple mock logic\n    end;\n\n    // ... other interface methods\n}\n</code></pre>"},{"location":"tasks/task-creation-prompt/#enums-provided-dependencies","title":"Enums (provided dependencies)","text":"<pre><code>enum 70098 \"CG Product Type\"\n{\n    Extensible = false;\n\n    value(0; Standard) { Caption = 'Standard'; }\n    value(1; Food) { Caption = 'Food'; }\n    value(2; Books) { Caption = 'Books'; }\n}\n</code></pre>"},{"location":"tasks/task-creation-prompt/#difficulty-levels","title":"Difficulty Levels","text":""},{"location":"tasks/task-creation-prompt/#easy-cg-al-e","title":"Easy (CG-AL-E###)","text":"<p>What makes it Easy:</p> <ul> <li>Single object creation</li> <li>Standard patterns with minimal complexity</li> <li>Basic syntax knowledge</li> <li>Few or no edge cases</li> </ul> <p>Examples:</p> <ul> <li>Create a simple table with 3-4 fields</li> <li>Create a basic enum with options</li> <li>Create a page for an existing table</li> <li>Create a simple codeunit with one procedure</li> <li>Create a basic interface definition</li> <li>Create a simple table extension</li> </ul>"},{"location":"tasks/task-creation-prompt/#medium-cg-al-m","title":"Medium (CG-AL-M###)","text":"<p>What makes it Medium:</p> <ul> <li>Multiple related objects</li> <li>Complex validation logic</li> <li>Triggers with business rules</li> <li>Error handling requirements</li> <li>Cross-object interactions</li> <li>API pages with CRUD operations</li> </ul> <p>Examples:</p> <ul> <li>Table with complex validation triggers (date ranges, status transitions)</li> <li>Multi-object scenarios (table + page + codeunit)</li> <li>Interface implementation</li> <li>Reports with calculations</li> <li>Workflow-like state machines</li> <li>Integration scenarios with HTTP calls</li> </ul>"},{"location":"tasks/task-creation-prompt/#hard-cg-al-h","title":"Hard (CG-AL-H###)","text":"<p>What makes it Hard:</p> <ul> <li>Complex conditional logic with many branches</li> <li>Multiple interacting rules</li> <li>Precise mathematical calculations</li> <li>Boundary condition handling</li> <li>Country/region-specific logic</li> <li>Performance-sensitive operations</li> <li>Advanced patterns (dependency injection, events)</li> </ul> <p>Examples:</p> <ul> <li>Tax calculator with tiered rates by country and product type</li> <li>Multi-currency conversion with rounding rules</li> <li>Complex discount engines</li> <li>Inventory costing algorithms</li> <li>Posting routines with multiple validations</li> </ul>"},{"location":"tasks/task-creation-prompt/#critical-rules-for-task-descriptions","title":"Critical Rules for Task Descriptions","text":""},{"location":"tasks/task-creation-prompt/#do-not-add-guidance-or-hints","title":"DO NOT Add Guidance or Hints","text":"<p>BAD - This guides the model:</p> <pre><code>description: &gt;-\n  Create an interface called \"Payment Processor\"\n  (note: interfaces in AL do not use numeric IDs)\n</code></pre> <p>GOOD - This tests the model's knowledge:</p> <pre><code>description: &gt;-\n  Create an interface called \"Payment Processor\"\n</code></pre> <p>If a model incorrectly adds an ID to an interface, that's a valid test failure - it shows the model doesn't understand AL syntax.</p>"},{"location":"tasks/task-creation-prompt/#do-specify-exact-error-messages","title":"DO Specify Exact Error Messages","text":"<p>If you're testing validation, specify the exact error message:</p> <pre><code>description: &gt;-\n  OnDelete trigger to prevent deletion of Active contracts.\n  Error message must be exactly: \"Cannot delete active contract\"\n</code></pre> <p>This allows precise test assertions.</p>"},{"location":"tasks/task-creation-prompt/#do-specify-field-types-and-names-exactly","title":"DO Specify Field Types and Names Exactly","text":"<pre><code>description: &gt;-\n  Fields:\n  - Contract No. (Code[20], primary key)\n  - Customer No. (Code[20], with TableRelation to Customer)\n  - Start Date (Date)\n  - Contract Value (Decimal)\n</code></pre>"},{"location":"tasks/task-creation-prompt/#do-specify-procedure-signatures-exactly","title":"DO Specify Procedure Signatures Exactly","text":"<pre><code>description: &gt;-\n  CalculateTax(Amount: Decimal; CountryCode: Code[2]; ProductType: Enum \"CG Product Type\"): Decimal\n</code></pre>"},{"location":"tasks/task-creation-prompt/#critical-rules-for-tests","title":"Critical Rules for Tests","text":""},{"location":"tasks/task-creation-prompt/#never-use-placeholder-assertions","title":"NEVER Use Placeholder Assertions","text":"<p>BAD:</p> <pre><code>[Test]\nprocedure TestSomething()\nbegin\n    Assert.IsTrue(true, 'This always passes');  // USELESS\nend;\n</code></pre> <p>GOOD:</p> <pre><code>[Test]\nprocedure TestSomething()\nvar\n    Result: Decimal;\nbegin\n    Result := Calculator.Add(2, 3);\n    Assert.AreEqual(5, Result, 'Addition should return correct sum');\nend;\n</code></pre>"},{"location":"tasks/task-creation-prompt/#test-everything-specified","title":"Test Everything Specified","text":"<p>If the task says \"Active field defaults to true\", test it:</p> <pre><code>[Test]\nprocedure TestActiveDefaultValue()\nvar\n    ProductCategory: Record \"Product Category\";\n    TestCode: Code[20];\nbegin\n    TestCode := CopyStr(LibraryRandom.RandText(10), 1, 20);\n    ProductCategory.Init();\n    ProductCategory.Code := TestCode;\n    ProductCategory.Description := 'Test';\n    ProductCategory.\"Created Date\" := WorkDate();\n    // Note: Active NOT explicitly set\n\n    ProductCategory.Insert(true);\n\n    Clear(ProductCategory);\n    ProductCategory.Get(TestCode);\n    Assert.IsTrue(ProductCategory.Active, 'Active should default to true via InitValue');\n\n    ProductCategory.Delete();\nend;\n</code></pre>"},{"location":"tasks/task-creation-prompt/#test-boundary-conditions","title":"Test Boundary Conditions","text":"<p>If the task says \"tax is 7% for amounts &gt;= 100 and &lt; 1000\":</p> <pre><code>[Test]\nprocedure TestUS_JustBelowLowerThreshold_NoTax()\nbegin\n    // $99.99 should have 0% tax\n    Result := TaxCalculator.CalculateTax(99.99, 'US', \"CG Product Type\"::Standard);\n    Assert.AreEqual(0, Result, 'US amount 99.99 should have 0% tax');\nend;\n\n[Test]\nprocedure TestUS_ExactlyAtLowerThreshold_7Percent()\nbegin\n    // $100 exactly should have 7% tax\n    Result := TaxCalculator.CalculateTax(100, 'US', \"CG Product Type\"::Standard);\n    Assert.AreEqual(7, Result, 'US amount exactly 100 should have 7% tax');\nend;\n</code></pre>"},{"location":"tasks/task-creation-prompt/#test-edge-cases","title":"Test Edge Cases","text":"<ul> <li>Negative amounts</li> <li>Zero amounts</li> <li>Empty strings</li> <li>Unknown/invalid codes</li> <li>Maximum length strings</li> </ul>"},{"location":"tasks/task-creation-prompt/#interface-tests-need-mock-implementations","title":"Interface Tests Need Mock Implementations","text":"<p>Interfaces can't be instantiated directly:</p> <pre><code>[Test]\nprocedure TestProcessPayment()\nvar\n    PaymentProcessor: Interface \"Payment Processor\";\n    MockProcessor: Codeunit \"CG-AL-E008 Mock Processor\";\nbegin\n    PaymentProcessor := MockProcessor;\n    Assert.IsTrue(PaymentProcessor.ProcessPayment(100.00, 'Card'), 'Should process');\nend;\n</code></pre>"},{"location":"tasks/task-creation-prompt/#al-object-types-reference","title":"AL Object Types Reference","text":""},{"location":"tasks/task-creation-prompt/#table","title":"Table","text":"<pre><code>table 70000 \"Product Category\"\n{\n    Caption = 'Product Category';\n    DataClassification = CustomerContent;\n\n    fields\n    {\n        field(1; \"Code\"; Code[20])\n        {\n            Caption = 'Code';\n            NotBlank = true;\n        }\n        field(2; Description; Text[100])\n        {\n            Caption = 'Description';\n        }\n        field(3; Active; Boolean)\n        {\n            Caption = 'Active';\n            InitValue = true;\n        }\n    }\n\n    keys\n    {\n        key(PK; \"Code\") { Clustered = true; }\n    }\n\n    trigger OnInsert()\n    begin\n        // Insert logic\n    end;\n}\n</code></pre>"},{"location":"tasks/task-creation-prompt/#page-card","title":"Page (Card)","text":"<pre><code>page 70000 \"Product Category Card\"\n{\n    PageType = Card;\n    SourceTable = \"Product Category\";\n    Caption = 'Product Category Card';\n    ApplicationArea = All;\n    UsageCategory = Documents;\n\n    layout\n    {\n        area(Content)\n        {\n            group(General)\n            {\n                field(\"Code\"; Rec.\"Code\") { }\n                field(Description; Rec.Description) { }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"tasks/task-creation-prompt/#codeunit","title":"Codeunit","text":"<pre><code>codeunit 70000 \"Calculator\"\n{\n    Access = Public;\n\n    procedure Add(A: Decimal; B: Decimal): Decimal\n    begin\n        exit(A + B);\n    end;\n}\n</code></pre>"},{"location":"tasks/task-creation-prompt/#enum","title":"Enum","text":"<pre><code>enum 70000 \"Order Status\"\n{\n    Extensible = true;\n\n    value(0; Draft) { Caption = 'Draft'; }\n    value(1; Released) { Caption = 'Released'; }\n    value(2; Shipped) { Caption = 'Shipped'; }\n}\n</code></pre>"},{"location":"tasks/task-creation-prompt/#interface-no-id","title":"Interface (NO ID!)","text":"<pre><code>interface \"Payment Processor\"\n{\n    Access = Public;\n\n    procedure ProcessPayment(Amount: Decimal; PaymentMethod: Text): Boolean;\n    procedure ValidatePayment(PaymentData: Text): Boolean;\n}\n</code></pre>"},{"location":"tasks/task-creation-prompt/#table-extension","title":"Table Extension","text":"<pre><code>tableextension 70000 \"Item Extension\" extends Item\n{\n    fields\n    {\n        field(70000; \"Warranty Period\"; Integer)\n        {\n            Caption = 'Warranty Period';\n            DataClassification = CustomerContent;\n        }\n    }\n}\n</code></pre>"},{"location":"tasks/task-creation-prompt/#event-subscriber","title":"Event Subscriber","text":"<pre><code>codeunit 70001 \"Item Event Subscriber\"\n{\n    Access = Internal;\n\n    [EventSubscriber(ObjectType::Table, Database::Item, 'OnAfterInsertEvent', '', false, false)]\n    local procedure OnAfterInsertItem(var Rec: Record Item)\n    begin\n        Message('Item %1 created', Rec.\"No.\");\n    end;\n}\n</code></pre>"},{"location":"tasks/task-creation-prompt/#ideas-for-challenging-tasks","title":"Ideas for Challenging Tasks","text":""},{"location":"tasks/task-creation-prompt/#test-al-specific-knowledge","title":"Test AL-Specific Knowledge","text":"<ul> <li>Interfaces don't have IDs (unlike most AL objects)</li> <li>CalcFormula syntax for flowfields</li> <li>TableRelation with conditions</li> <li>Proper trigger usage (OnValidate, OnInsert, OnModify, OnDelete)</li> <li>Option vs Enum differences</li> <li>FlowField vs normal field behaviors</li> </ul>"},{"location":"tasks/task-creation-prompt/#test-business-central-conventions","title":"Test Business Central Conventions","text":"<ul> <li>Proper naming conventions (spaces, quotes)</li> <li>Caption requirements</li> <li>ApplicationArea and UsageCategory</li> <li>Proper use of Rec vs xRec</li> <li>TestPermissions in test codeunits</li> </ul>"},{"location":"tasks/task-creation-prompt/#test-complex-logic","title":"Test Complex Logic","text":"<ul> <li>Multi-condition validations</li> <li>State machines (Draft -&gt; Active -&gt; Completed)</li> <li>Calculations with rounding</li> <li>Date arithmetic</li> <li>Currency conversions</li> <li>Tiered pricing/tax rules</li> </ul>"},{"location":"tasks/task-creation-prompt/#test-error-handling","title":"Test Error Handling","text":"<ul> <li>Specific error messages</li> <li>Error vs Confirm dialogs</li> <li>Try functions</li> <li>Transaction handling</li> </ul>"},{"location":"tasks/task-creation-prompt/#output-format","title":"Output Format","text":"<p>For each task you create, provide:</p>"},{"location":"tasks/task-creation-prompt/#1-task-yaml-file","title":"1. Task YAML File","text":"<pre><code>id: CG-AL-XXXX\nprompt_template: code-gen.md\nfix_template: bugfix.md\nmax_attempts: 2\ndescription: &gt;-\n  [Your task description here]\nexpected:\n  compile: true\n  testApp: tests/al/{difficulty}/CG-AL-XXXX.Test.al\nmetrics:\n  - compile_pass\n  - tests_pass\n  - pass_attempt\n</code></pre>"},{"location":"tasks/task-creation-prompt/#2-test-al-file","title":"2. Test AL File","text":"<pre><code>codeunit 80XXX \"CG-AL-XXXX Test\"\n{\n    Subtype = Test;\n    TestPermissions = Disabled;\n\n    // Your test procedures here\n}\n</code></pre>"},{"location":"tasks/task-creation-prompt/#3-helper-files-if-needed","title":"3. Helper Files (if needed)","text":"<p>Any mock implementations, enums, or other supporting objects.</p>"},{"location":"tasks/task-creation-prompt/#checklist-before-submitting","title":"Checklist Before Submitting","text":"<ul> <li>[ ] Task ID is unique and follows format (CG-AL-E/M/H###)</li> <li>[ ] Description specifies exact names, types, and signatures</li> <li>[ ] Description does NOT include hints or guidance</li> <li>[ ] Test codeunit has proper ID in range</li> <li>[ ] All assertions verify actual computed values (no <code>Assert.IsTrue(true, ...)</code>)</li> <li>[ ] Tests cover all requirements from description</li> <li>[ ] Tests cover boundary conditions and edge cases</li> <li>[ ] Helper files provided if task involves interfaces or external dependencies</li> <li>[ ] Error messages match exactly between task description and test assertions</li> </ul>"},{"location":"tasks/task-creation-prompt/#example-complete-task","title":"Example Complete Task","text":""},{"location":"tasks/task-creation-prompt/#task-yaml-taskseasycg-al-e020-discount-calculatoryml","title":"Task YAML (<code>tasks/easy/CG-AL-E020-discount-calculator.yml</code>)","text":"<pre><code>id: CG-AL-E020\nprompt_template: code-gen.md\nfix_template: bugfix.md\nmax_attempts: 2\ndescription: &gt;-\n  Create a codeunit called \"Discount Calculator\" with ID 70010.\n\n  Implement a procedure:\n  CalculateDiscount(OrderAmount: Decimal; CustomerTier: Option Standard,Silver,Gold): Decimal\n\n  Discount rules:\n  - Standard customers: No discount (0%)\n  - Silver customers: 5% discount\n  - Gold customers: 10% discount\n\n  The procedure should return the discount AMOUNT (not the discounted price).\n  Negative order amounts should return 0.\n\n  Include Access = Public on the codeunit.\nexpected:\n  compile: true\n  testApp: tests/al/easy/CG-AL-E020.Test.al\nmetrics:\n  - compile_pass\n  - tests_pass\n  - pass_attempt\n</code></pre>"},{"location":"tasks/task-creation-prompt/#test-file-testsaleasycg-al-e020testal","title":"Test File (<code>tests/al/easy/CG-AL-E020.Test.al</code>)","text":"<pre><code>codeunit 80020 \"CG-AL-E020 Test\"\n{\n    Subtype = Test;\n    TestPermissions = Disabled;\n\n    var\n        Assert: Codeunit Assert;\n        DiscountCalculator: Codeunit \"Discount Calculator\";\n\n    [Test]\n    procedure TestStandardCustomer_NoDiscount()\n    var\n        Result: Decimal;\n    begin\n        Result := DiscountCalculator.CalculateDiscount(100, 0); // Standard = 0\n        Assert.AreEqual(0, Result, 'Standard customers should get 0% discount');\n    end;\n\n    [Test]\n    procedure TestSilverCustomer_5Percent()\n    var\n        Result: Decimal;\n    begin\n        Result := DiscountCalculator.CalculateDiscount(100, 1); // Silver = 1\n        Assert.AreEqual(5, Result, 'Silver customers should get 5% discount = 5');\n    end;\n\n    [Test]\n    procedure TestGoldCustomer_10Percent()\n    var\n        Result: Decimal;\n    begin\n        Result := DiscountCalculator.CalculateDiscount(200, 2); // Gold = 2\n        Assert.AreEqual(20, Result, 'Gold customers should get 10% discount = 20');\n    end;\n\n    [Test]\n    procedure TestNegativeAmount_ReturnsZero()\n    var\n        Result: Decimal;\n    begin\n        Result := DiscountCalculator.CalculateDiscount(-100, 2);\n        Assert.AreEqual(0, Result, 'Negative amounts should return 0');\n    end;\n\n    [Test]\n    procedure TestZeroAmount_ReturnsZero()\n    var\n        Result: Decimal;\n    begin\n        Result := DiscountCalculator.CalculateDiscount(0, 2);\n        Assert.AreEqual(0, Result, 'Zero amount should return 0 discount');\n    end;\n\n    [Test]\n    procedure TestLargeAmount_Gold()\n    var\n        Result: Decimal;\n    begin\n        Result := DiscountCalculator.CalculateDiscount(9999.99, 2);\n        Assert.AreEqual(999.999, Result, 'Large amount gold discount should be 999.999');\n    end;\n}\n</code></pre> <p>Now create new benchmark tasks! Aim for variety - different object types, different difficulty levels, and tasks that test knowledge models might NOT have seen as frequently in training data.</p>"},{"location":"tasks/task-format/","title":"Task Format","text":"<p>Tasks are defined in YAML files that describe what AL code the LLM should generate and how to verify it.</p>"},{"location":"tasks/task-format/#task-file-location","title":"Task File Location","text":"<p>Tasks are organized by difficulty:</p> <pre><code>tasks/\n\u251c\u2500\u2500 easy/                    # Basic AL syntax\n\u2502   \u2514\u2500\u2500 CG-AL-E001-basic-table.yml\n\u251c\u2500\u2500 medium/                  # Multi-object, business logic\n\u2502   \u2514\u2500\u2500 CG-AL-M001-api-page-crud.yml\n\u2514\u2500\u2500 hard/                    # Advanced patterns, edge cases\n    \u2514\u2500\u2500 CG-AL-H001-tax-calculator.yml\n</code></pre>"},{"location":"tasks/task-format/#yaml-schema","title":"YAML Schema","text":""},{"location":"tasks/task-format/#minimal-task","title":"Minimal Task","text":"<pre><code>id: CG-AL-E001\nprompt_template: code-gen.md\nfix_template: bugfix.md\nmax_attempts: 2\ndescription: &gt;-\n  Create a simple AL table called \"Product Category\" with ID 70000.\nexpected:\n  compile: true\n  testApp: tests/al/easy/CG-AL-E001.Test.al\nmetrics:\n  - compile_pass\n  - tests_pass\n  - pass_attempt\n</code></pre>"},{"location":"tasks/task-format/#full-task-schema","title":"Full Task Schema","text":"<pre><code># Unique task identifier\n# Format: CG-AL-{E|M|H}{###}\nid: CG-AL-E001\n\n# Prompt template for code generation (relative to templates/)\nprompt_template: code-gen.md\n\n# Prompt template for fix attempts (relative to templates/)\nfix_template: bugfix.md\n\n# Maximum attempts allowed (usually 2)\nmax_attempts: 2\n\n# Task description - what the LLM should generate\ndescription: &gt;-\n  Create a simple AL table called \"Product Category\" with ID 70000.\n\n  The table should have the following fields:\n  - Code (Code[20], primary key)\n  - Description (Text[100])\n  - Active (Boolean, default true)\n  - Created Date (Date)\n\n  Include proper captions and data classification.\n\n# Expected outcomes for evaluation\nexpected:\n  # Whether the code should compile successfully\n  compile: true\n\n  # Path to test file (relative to project root)\n  testApp: tests/al/easy/CG-AL-E001.Test.al\n\n  # Test codeunit ID (optional, speeds up test execution)\n  testCodeunitId: 80001\n\n  # Patterns that must appear in generated code\n  mustContain:\n    - \"table 70000\"\n    - '\"Product Category\"'\n\n  # Patterns that must NOT appear\n  mustNotContain:\n    - \"// TODO\"\n\n# Metrics to collect\nmetrics:\n  - compile_pass # Did it compile?\n  - tests_pass # Did tests pass?\n  - pass_attempt # Which attempt passed?\n\n# Optional metadata\nmetadata:\n  difficulty: easy # easy | medium | hard\n  category: table # Object type being tested\n  tags: # For filtering\n    - basic-syntax\n    - table-definition\n  estimatedTokens: 500 # Expected token usage\n  target: Cloud # Cloud | OnPrem (for HttpClient, etc.)\n\n# Task-specific prompt injections (optional)\nprompts:\n  injections:\n    anthropic:\n      generation:\n        suffix: \"\\nRemember to include DataClassification.\"\n</code></pre>"},{"location":"tasks/task-format/#field-reference","title":"Field Reference","text":""},{"location":"tasks/task-format/#id","title":"id","text":"<p>Unique identifier following the pattern <code>CG-AL-{difficulty}{number}</code>:</p> <ul> <li><code>E</code> = Easy (001-999)</li> <li><code>M</code> = Medium (001-999)</li> <li><code>H</code> = Hard (001-999)</li> </ul> <pre><code>id: CG-AL-E001 # Easy task 001\nid: CG-AL-M015 # Medium task 015\nid: CG-AL-H003 # Hard task 003\n</code></pre>"},{"location":"tasks/task-format/#prompt_template-fix_template","title":"prompt_template / fix_template","text":"<p>References to prompt templates in the <code>templates/</code> directory:</p> <pre><code>prompt_template: code-gen.md # For first attempt\nfix_template: bugfix.md # For retry after errors\n</code></pre> <p>Default templates:</p> <ul> <li><code>code-gen.md</code> - Standard code generation prompt</li> <li><code>bugfix.md</code> - Error fix prompt with compilation errors</li> </ul>"},{"location":"tasks/task-format/#max_attempts","title":"max_attempts","text":"<p>Maximum number of generation attempts:</p> <pre><code>max_attempts: 2 # First try + one retry (default)\nmax_attempts: 1 # Single attempt only\nmax_attempts: 3 # First try + two retries\n</code></pre>"},{"location":"tasks/task-format/#description","title":"description","text":"<p>The task description is the core of the prompt. It should:</p> <ul> <li>Clearly specify what to create</li> <li>Include exact names and IDs</li> <li>Define field types and constraints</li> <li>Specify expected behaviors</li> <li>NOT include hints or guidance</li> </ul> <p>Good description:</p> <pre><code>description: &gt;-\n  Create a table called \"Product Category\" with ID 70000.\n\n  Fields:\n  - Code (Code[20], primary key)\n  - Description (Text[100])\n  - Active (Boolean, default true)\n</code></pre> <p>Bad description (includes guidance):</p> <pre><code>description: &gt;-\n  Create a table called \"Product Category\" with ID 70000.\n  Note: Remember to use InitValue for default values.\n  Hint: Active should default to true.\n</code></pre>"},{"location":"tasks/task-format/#expected","title":"expected","text":"<p>Defines success criteria:</p> <pre><code>expected:\n  # Compilation requirement\n  compile: true\n\n  # Test file path (optional - omit for compile-only tasks)\n  testApp: tests/al/easy/CG-AL-E001.Test.al\n\n  # Test codeunit ID (optional, improves performance)\n  testCodeunitId: 80001\n\n  # Required patterns (optional)\n  mustContain:\n    - \"table 70000\"\n    - \"TableRelation\"\n\n  # Forbidden patterns (optional)\n  mustNotContain:\n    - \"// TODO\"\n    - \"NotImplemented\"\n</code></pre>"},{"location":"tasks/task-format/#metrics","title":"metrics","text":"<p>Metrics to track for this task:</p> <pre><code>metrics:\n  - compile_pass # Boolean: compilation succeeded\n  - tests_pass # Boolean: all tests passed\n  - pass_attempt # Integer: which attempt succeeded (0=none)\n</code></pre>"},{"location":"tasks/task-format/#metadata","title":"metadata","text":"<p>Optional task metadata:</p> <pre><code>metadata:\n  # Difficulty classification\n  difficulty: easy # easy | medium | hard\n\n  # Primary AL object type\n  category: table # table | page | codeunit | report | etc.\n\n  # Tags for filtering\n  tags:\n    - basic-syntax\n    - flowfield\n    - api\n\n  # Expected token usage\n  estimatedTokens: 500\n\n  # Target platform (for OnPrem-only features)\n  target: Cloud # Cloud | OnPrem\n</code></pre>"},{"location":"tasks/task-format/#prompts","title":"prompts","text":"<p>Task-specific prompt injections:</p> <pre><code>prompts:\n  enabled: true\n  injections:\n    # Provider-specific\n    anthropic:\n      generation:\n        suffix: \"\\nBe concise.\"\n    openai:\n      generation:\n        prefix: \"Important: \"\n\n    # All providers\n    default:\n      generation:\n        systemPrompt: \"You are an AL expert.\"\n</code></pre>"},{"location":"tasks/task-format/#id-ranges","title":"ID Ranges","text":"<p>Objects in generated code and tests should use specific ID ranges:</p> Range Purpose 50000-59999 Standard Business Central 69000-69999 Prereq app objects 70000-79999 Generated code (benchmark tasks) 80000-89999 Test codeunits"},{"location":"tasks/task-format/#test-file-naming","title":"Test File Naming","text":"<p>Test files follow the pattern:</p> <pre><code>tests/al/{difficulty}/CG-AL-{ID}.Test.al\n</code></pre> <p>Example:</p> <pre><code>tests/al/easy/CG-AL-E001.Test.al\ntests/al/medium/CG-AL-M005.Test.al\n</code></pre>"},{"location":"tasks/task-format/#example-tasks","title":"Example Tasks","text":""},{"location":"tasks/task-format/#simple-table-task","title":"Simple Table Task","text":"<pre><code>id: CG-AL-E001\nprompt_template: code-gen.md\nfix_template: bugfix.md\nmax_attempts: 2\ndescription: &gt;-\n  Create a simple AL table called \"Product Category\" with ID 70000.\n\n  Fields:\n  - Code (Code[20], primary key)\n  - Description (Text[100])\n  - Active (Boolean, default true)\n  - Created Date (Date)\n\n  Include proper captions and data classification.\nexpected:\n  compile: true\n  testApp: tests/al/easy/CG-AL-E001.Test.al\n  testCodeunitId: 80001\nmetrics:\n  - compile_pass\n  - tests_pass\n  - pass_attempt\nmetadata:\n  difficulty: easy\n  category: table\n</code></pre>"},{"location":"tasks/task-format/#complex-codeunit-task","title":"Complex Codeunit Task","text":"<pre><code>id: CG-AL-H001\nprompt_template: code-gen.md\nfix_template: bugfix.md\nmax_attempts: 2\ndescription: &gt;-\n  Create a codeunit called \"Tax Calculator\" with ID 70100.\n\n  Implement a procedure:\n  CalculateTax(Amount: Decimal; CountryCode: Code[2]; ProductType: Enum \"CG Product Type\"): Decimal\n\n  Tax rules by country:\n  - US: 0% for amounts &lt; 100, 7% for 100-999, 10% for &gt;= 1000\n  - CA: Flat 13%\n  - DE: 19% standard, 7% for Food, 0% for Books\n  - UK: 20% standard, 0% for Food and Books\n  - Other: 0%\n\n  Return the calculated tax amount (not the total).\n  Negative amounts should return 0.\nexpected:\n  compile: true\n  testApp: tests/al/hard/CG-AL-H001.Test.al\n  testCodeunitId: 80200\nmetrics:\n  - compile_pass\n  - tests_pass\n  - pass_attempt\nmetadata:\n  difficulty: hard\n  category: codeunit\n  tags:\n    - business-logic\n    - calculations\n    - edge-cases\n</code></pre>"},{"location":"tasks/task-format/#compile-only-task","title":"Compile-Only Task","text":"<p>For tasks that don't need runtime testing:</p> <pre><code>id: CG-AL-E003\nprompt_template: code-gen.md\nfix_template: bugfix.md\nmax_attempts: 2\ndescription: &gt;-\n  Create an enum called \"Order Status\" with ID 70050.\n\n  Values:\n  - Draft (0)\n  - Released (1)\n  - Shipped (2)\n  - Completed (3)\n  - Cancelled (4)\n\n  Set Extensible = true and include proper captions.\nexpected:\n  compile: true\n  # No testApp - compile-only\nmetrics:\n  - compile_pass\n  - pass_attempt\nmetadata:\n  difficulty: easy\n  category: enum\n</code></pre>"},{"location":"tasks/task-format/#validation","title":"Validation","text":"<p>Validate task files before use:</p> <pre><code>deno run --allow-all cli/centralgauge.ts validate-tasks tasks/\n</code></pre> <p>This checks:</p> <ul> <li>YAML syntax</li> <li>Required fields present</li> <li>ID format correct</li> <li>Test file exists</li> <li>No duplicate IDs</li> </ul>"},{"location":"tasks/task-format/#next-steps","title":"Next Steps","text":"<ul> <li>Writing Tests - Create test codeunits</li> <li>Task Categories - Difficulty guidelines</li> <li>Running Benchmarks - Execute tasks</li> </ul>"},{"location":"tasks/writing-tests/","title":"Writing Tests","text":"<p>Test codeunits verify that LLM-generated code works correctly. They run inside the Business Central container after successful compilation.</p>"},{"location":"tasks/writing-tests/#test-file-structure","title":"Test File Structure","text":"<pre><code>codeunit 80001 \"CG-AL-E001 Test\"\n{\n    Subtype = Test;\n    TestPermissions = Disabled;\n\n    var\n        Assert: Codeunit Assert;\n        LibraryRandom: Codeunit \"Library - Random\";\n\n    [Test]\n    procedure TestFieldExistence()\n    begin\n        // Test code\n    end;\n}\n</code></pre>"},{"location":"tasks/writing-tests/#required-elements","title":"Required Elements","text":"Element Description <code>Subtype = Test</code> Marks as test codeunit <code>TestPermissions = Disabled</code> Allows unrestricted testing <code>[Test]</code> attribute Marks each test procedure <code>Assert</code> codeunit Provides assertion methods"},{"location":"tasks/writing-tests/#test-codeunit-ids","title":"Test Codeunit IDs","text":"Range Difficulty 80001-80099 Easy tasks 80100-80199 Medium tasks 80200-80299 Hard tasks"},{"location":"tasks/writing-tests/#assertion-methods","title":"Assertion Methods","text":"<p>The <code>Assert</code> codeunit provides:</p> <pre><code>// Equality\nAssert.AreEqual(Expected, Actual, ErrorMessage);\nAssert.AreNotEqual(NotExpected, Actual, ErrorMessage);\n\n// Boolean\nAssert.IsTrue(Condition, ErrorMessage);\nAssert.IsFalse(Condition, ErrorMessage);\n\n// Numeric comparisons\nAssert.AreNearlyEqual(Expected, Actual, Tolerance, ErrorMessage);\n\n// String\nAssert.ExpectedError(ExpectedMessage);  // With asserterror\n\n// Records\nAssert.RecordIsEmpty(Record);\nAssert.RecordIsNotEmpty(Record);\nAssert.RecordCount(Record, ExpectedCount);\n\n// Tables\nAssert.TableIsEmpty(TableNo);\nAssert.TableIsNotEmpty(TableNo);\n</code></pre>"},{"location":"tasks/writing-tests/#test-pattern","title":"Test Pattern","text":"<p>Use the GIVEN-WHEN-THEN pattern:</p> <pre><code>[Test]\nprocedure TestDiscountCalculation()\nvar\n    Calculator: Codeunit \"Discount Calculator\";\n    Result: Decimal;\nbegin\n    // [SCENARIO] Gold customers get 10% discount\n\n    // [GIVEN] A gold customer with a $200 order\n    // (No setup needed for this simple case)\n\n    // [WHEN] Calculating the discount\n    Result := Calculator.CalculateDiscount(200, 2); // Gold = 2\n\n    // [THEN] The discount should be $20 (10%)\n    Assert.AreEqual(20, Result, 'Gold customers should get 10% discount');\nend;\n</code></pre>"},{"location":"tasks/writing-tests/#testing-different-object-types","title":"Testing Different Object Types","text":""},{"location":"tasks/writing-tests/#testing-tables","title":"Testing Tables","text":"<pre><code>[Test]\nprocedure TestTableFieldDefaults()\nvar\n    ProductCategory: Record \"Product Category\";\nbegin\n    // [SCENARIO] Active field defaults to true\n\n    // [WHEN] Creating a new record\n    ProductCategory.Init();\n    ProductCategory.Code := 'TEST';\n    ProductCategory.Description := 'Test Category';\n    ProductCategory.\"Created Date\" := WorkDate();\n    ProductCategory.Insert(true);\n\n    // [THEN] Active should default to true\n    Clear(ProductCategory);\n    ProductCategory.Get('TEST');\n    Assert.IsTrue(ProductCategory.Active, 'Active should default to true');\n\n    // Cleanup\n    ProductCategory.Delete();\nend;\n\n[Test]\nprocedure TestTableValidation()\nvar\n    ProductCategory: Record \"Product Category\";\nbegin\n    // [SCENARIO] Code field cannot be blank\n\n    // [WHEN] Trying to insert with blank code\n    ProductCategory.Init();\n    ProductCategory.Code := '';\n    ProductCategory.Description := 'Test';\n\n    // [THEN] Error should occur\n    asserterror ProductCategory.Insert(true);\n    Assert.ExpectedError('Code must have a value');\nend;\n</code></pre>"},{"location":"tasks/writing-tests/#testing-codeunits","title":"Testing Codeunits","text":"<pre><code>[Test]\nprocedure TestCalculation()\nvar\n    Calculator: Codeunit \"Tax Calculator\";\n    Result: Decimal;\nbegin\n    // [SCENARIO] US tax for amount &gt;= 1000 is 10%\n\n    // [WHEN] Calculating tax for $1500 in US\n    Result := Calculator.CalculateTax(1500, 'US', \"CG Product Type\"::Standard);\n\n    // [THEN] Tax should be $150\n    Assert.AreEqual(150, Result, 'US amount &gt;= 1000 should have 10% tax');\nend;\n\n[Test]\nprocedure TestEdgeCaseBoundary()\nvar\n    Calculator: Codeunit \"Tax Calculator\";\nbegin\n    // [SCENARIO] Boundary at exactly $1000\n\n    // Amount at boundary\n    Assert.AreEqual(100, Calculator.CalculateTax(1000, 'US', \"CG Product Type\"::Standard),\n        'US amount exactly 1000 should have 10% tax');\n\n    // Amount just below\n    Assert.AreEqual(69.93, Calculator.CalculateTax(999, 'US', \"CG Product Type\"::Standard),\n        'US amount 999 should have 7% tax');\nend;\n</code></pre>"},{"location":"tasks/writing-tests/#testing-interfaces","title":"Testing Interfaces","text":"<p>Interfaces cannot be instantiated directly. Create a mock:</p> <pre><code>// Mock implementation (in helper file)\ncodeunit 70096 \"Mock Payment Processor\" implements \"Payment Processor\"\n{\n    procedure ProcessPayment(Amount: Decimal; PaymentMethod: Text): Boolean\n    begin\n        exit(Amount &gt; 0);\n    end;\n\n    procedure ValidatePayment(PaymentData: Text): Boolean\n    begin\n        exit(PaymentData &lt;&gt; '');\n    end;\n}\n</code></pre> <pre><code>// Test using the mock\n[Test]\nprocedure TestInterfaceContract()\nvar\n    PaymentProcessor: Interface \"Payment Processor\";\n    MockProcessor: Codeunit \"Mock Payment Processor\";\nbegin\n    // [SCENARIO] Interface can be implemented and used\n\n    // [GIVEN] A mock implementation\n    PaymentProcessor := MockProcessor;\n\n    // [WHEN/THEN] Interface methods work correctly\n    Assert.IsTrue(\n        PaymentProcessor.ProcessPayment(100.00, 'Card'),\n        'Should process valid payment'\n    );\n    Assert.IsFalse(\n        PaymentProcessor.ProcessPayment(-50.00, 'Card'),\n        'Should reject negative amount'\n    );\nend;\n</code></pre>"},{"location":"tasks/writing-tests/#testing-pages","title":"Testing Pages","text":"<pre><code>[Test]\nprocedure TestPageOpens()\nvar\n    ProductCategory: Record \"Product Category\";\n    ProductCategoryCard: TestPage \"Product Category Card\";\nbegin\n    // [SCENARIO] Card page opens for existing record\n\n    // [GIVEN] An existing record\n    ProductCategory.Code := 'TEST';\n    ProductCategory.Description := 'Test';\n    ProductCategory.Insert();\n\n    // [WHEN] Opening the card page\n    ProductCategoryCard.OpenEdit();\n    ProductCategoryCard.GoToRecord(ProductCategory);\n\n    // [THEN] Fields should display correctly\n    Assert.AreEqual('TEST', ProductCategoryCard.Code.Value, 'Code should display');\n    Assert.AreEqual('Test', ProductCategoryCard.Description.Value, 'Description should display');\n\n    ProductCategoryCard.Close();\n    ProductCategory.Delete();\nend;\n</code></pre>"},{"location":"tasks/writing-tests/#critical-testing-rules","title":"Critical Testing Rules","text":""},{"location":"tasks/writing-tests/#1-never-use-placeholder-assertions","title":"1. Never Use Placeholder Assertions","text":"<pre><code>// BAD - Always passes\n[Test]\nprocedure BadTest()\nbegin\n    Assert.IsTrue(true, 'This always passes');\nend;\n\n// GOOD - Verifies actual behavior\n[Test]\nprocedure GoodTest()\nvar\n    Result: Decimal;\nbegin\n    Result := Calculator.Add(2, 3);\n    Assert.AreEqual(5, Result, 'Sum should be 5');\nend;\n</code></pre>"},{"location":"tasks/writing-tests/#2-test-all-requirements","title":"2. Test All Requirements","text":"<p>If the task specifies behavior, test it:</p> <pre><code># Task description\ndescription: &gt;-\n  Active field defaults to true.\n  Code field cannot be blank.\n</code></pre> <pre><code>// Test BOTH requirements\n[Test]\nprocedure TestActiveDefault()\nbegin\n    // Test Active defaults to true\nend;\n\n[Test]\nprocedure TestCodeRequired()\nbegin\n    // Test Code cannot be blank\nend;\n</code></pre>"},{"location":"tasks/writing-tests/#3-test-boundary-conditions","title":"3. Test Boundary Conditions","text":"<p>If the task mentions thresholds:</p> <pre><code>description: &gt;-\n  Tax is 7% for amounts &gt;= 100 and &lt; 1000\n</code></pre> <pre><code>[Test]\nprocedure TestJustBelowThreshold()\nbegin\n    // 99.99 should have 0% tax\nend;\n\n[Test]\nprocedure TestExactlyAtThreshold()\nbegin\n    // 100 should have 7% tax\nend;\n\n[Test]\nprocedure TestJustAboveThreshold()\nbegin\n    // 100.01 should have 7% tax\nend;\n</code></pre>"},{"location":"tasks/writing-tests/#4-test-edge-cases","title":"4. Test Edge Cases","text":"<ul> <li>Negative values</li> <li>Zero values</li> <li>Empty strings</li> <li>Maximum length strings</li> <li>Unknown/invalid codes</li> </ul> <pre><code>[Test]\nprocedure TestNegativeAmount()\nvar\n    Result: Decimal;\nbegin\n    Result := Calculator.CalculateDiscount(-100, 2);\n    Assert.AreEqual(0, Result, 'Negative amounts should return 0');\nend;\n\n[Test]\nprocedure TestUnknownCountry()\nvar\n    Result: Decimal;\nbegin\n    Result := Calculator.CalculateTax(1000, 'XX', \"CG Product Type\"::Standard);\n    Assert.AreEqual(0, Result, 'Unknown country should have 0% tax');\nend;\n</code></pre>"},{"location":"tasks/writing-tests/#5-match-exact-error-messages","title":"5. Match Exact Error Messages","text":"<p>If the task specifies error text:</p> <pre><code>description: &gt;-\n  Error message must be exactly: \"Cannot delete active contract\"\n</code></pre> <pre><code>[Test]\nprocedure TestCannotDeleteActive()\nvar\n    Contract: Record \"Service Contract\";\nbegin\n    Contract.Status := Contract.Status::Active;\n    Contract.Insert();\n\n    asserterror Contract.Delete(true);\n    Assert.ExpectedError('Cannot delete active contract');\nend;\n</code></pre>"},{"location":"tasks/writing-tests/#test-libraries","title":"Test Libraries","text":"<p>Use standard BC test libraries:</p> Library Purpose <code>Assert</code> Assertions <code>Library - Random</code> Random test data <code>Library - Sales</code> Sales document helpers <code>Library - Purchase</code> Purchase document helpers <code>Library - Inventory</code> Item/inventory helpers <code>Library - Report Dataset</code> Report testing <pre><code>var\n    Assert: Codeunit Assert;\n    LibraryRandom: Codeunit \"Library - Random\";\n    LibrarySales: Codeunit \"Library - Sales\";\n</code></pre>"},{"location":"tasks/writing-tests/#cleanup","title":"Cleanup","text":"<p>Always clean up test data:</p> <pre><code>[Test]\nprocedure TestWithCleanup()\nvar\n    TestRecord: Record \"My Table\";\nbegin\n    // Setup\n    TestRecord.Code := 'TEST';\n    TestRecord.Insert();\n\n    // Test\n    // ...\n\n    // Cleanup (even on success)\n    TestRecord.Delete();\nend;\n</code></pre> <p>Or use transaction rollback (test records automatically rolled back):</p> <pre><code>codeunit 80001 \"My Tests\"\n{\n    Subtype = Test;\n    TestPermissions = Disabled;\n    TransactionIsolationLevel = Rollback;  // Auto-cleanup\n\n    [Test]\n    procedure TestWithAutoCleanup()\n    begin\n        // Records created here are automatically rolled back\n    end;\n}\n</code></pre>"},{"location":"tasks/writing-tests/#complete-example","title":"Complete Example","text":"<pre><code>codeunit 80020 \"CG-AL-E020 Test\"\n{\n    Subtype = Test;\n    TestPermissions = Disabled;\n\n    var\n        Assert: Codeunit Assert;\n        DiscountCalculator: Codeunit \"Discount Calculator\";\n\n    [Test]\n    procedure TestStandardCustomer_NoDiscount()\n    var\n        Result: Decimal;\n    begin\n        // [SCENARIO] Standard customers get no discount\n        Result := DiscountCalculator.CalculateDiscount(100, 0);\n        Assert.AreEqual(0, Result, 'Standard customers should get 0% discount');\n    end;\n\n    [Test]\n    procedure TestSilverCustomer_5Percent()\n    var\n        Result: Decimal;\n    begin\n        // [SCENARIO] Silver customers get 5% discount\n        Result := DiscountCalculator.CalculateDiscount(100, 1);\n        Assert.AreEqual(5, Result, 'Silver customers should get 5% discount');\n    end;\n\n    [Test]\n    procedure TestGoldCustomer_10Percent()\n    var\n        Result: Decimal;\n    begin\n        // [SCENARIO] Gold customers get 10% discount\n        Result := DiscountCalculator.CalculateDiscount(200, 2);\n        Assert.AreEqual(20, Result, 'Gold customers should get 10% = 20');\n    end;\n\n    [Test]\n    procedure TestNegativeAmount_ReturnsZero()\n    var\n        Result: Decimal;\n    begin\n        // [SCENARIO] Negative amounts return 0\n        Result := DiscountCalculator.CalculateDiscount(-100, 2);\n        Assert.AreEqual(0, Result, 'Negative amounts should return 0');\n    end;\n\n    [Test]\n    procedure TestZeroAmount_ReturnsZero()\n    var\n        Result: Decimal;\n    begin\n        // [SCENARIO] Zero amount returns 0 discount\n        Result := DiscountCalculator.CalculateDiscount(0, 2);\n        Assert.AreEqual(0, Result, 'Zero amount should return 0');\n    end;\n}\n</code></pre>"},{"location":"tasks/writing-tests/#next-steps","title":"Next Steps","text":"<ul> <li>Task Format - YAML structure</li> <li>Task Categories - Difficulty guidelines</li> <li>Running Benchmarks - Execute tests</li> </ul>"}]}